'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/notes/docs/technology/cloud/container/kubernetes/network/flannel/','title':"Flannel",'section':"Kubernetes 网络",'content':"Flannel #  UDP(Tunnel设备) #  TUN 设备是一种工作在三层（Network Layer）的虚拟网络设备。TUN 设备的功能非常简单，即：在操作系统内核和用户应用程序之间传递 IP 包。\n XVLAN #  通信原理 #    帧格式 #  Outer Ethernet Header: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Outer Destination MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Outer Destination MAC Address | Outer Source MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Outer Source MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |OptnlEthtype = C-Tag 802.1Q | Outer.VLAN Tag Information | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Ethertype = 0x0800 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Outer IPv4 Header: #目的ip由flannel维护 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Version| IHL |Type of Service| Total Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Identification |Flags| Fragment Offset | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Time to Live |Protocl=17(UDP)| Header Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Outer Source IPv4 Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Outer Destination IPv4 Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Outer UDP Header: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Dest Port = VXLAN Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | UDP Length | UDP Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ VXLAN Header: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |R|R|R|R|I|R|R|R| Reserved | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | VXLAN Network Identifier (VNI) | Reserved | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Inner Ethernet Header: #目的mac为flannel配置的网关地址的mac，由flannel下放到各个node上 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Inner Destination MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Inner Destination MAC Address | Inner Source MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Inner Source MAC Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |OptnlEthtype = C-Tag 802.1Q | Inner.VLAN Tag Information | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Payload: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Ethertype of Original Payload | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | Original Ethernet Payload | | | |(Note that the original Ethernet Frame's FCS is not included) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Frame Check Sequence: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New FCS (Frame Check Sequence) for Outer Ethernet Frame | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  信息 #  node1 route\n$ route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface ... 10.1.16.0 10.1.16.0 255.255.255.0 UG 0 0 0 flannel.1 mac address\n$ ip neigh show dev flannel.1 10.1.16.0 lladdr 5e:f8:4f:00:e3:37 PERMANENT # 在 Node 1 上，使用“目的 VTEP 设备”的 MAC 地址进行查询 $ bridge fdb show flannel.1 | grep 5e:f8:4f:00:e3:37 5e:f8:4f:00:e3:37 dev flannel.1 dst 10.168.0.3 self permanent  流程 #  #以10.1.15.2 请求 10.1.16.3为例 1. node1的container-1的ip包经过路由从docker0发送至flannel.1(flannel进程维护) 2. flannel开始封装数据包 3. 通过查询网关10.1.16.0的mac地址，加上Inner Ethernet Header 4. 加上VXLAN Header 5. 加上UDP Header(port为flannel监听的port) 6. flannel通过fdp查询到网关mac地址对应的目标node节点的ip，加上IPv4 Header 7. 之后为正常的node之间的网络通信  Host-gw(三层方案) #  Flannel host-gw 模式必须要求集群宿主机之间是二层连通的。\n通过使用静态路由的方式，指定目的网络的下一条地址(node ip)，路由信息由flannel维护\n"});index.add({'id':1,'href':'/notes/docs/technology/program/revision/git/','title':"Git",'section':"版本控制",'content':"Git简介 #  git是一个分布式版本控制软件，最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。最初目的是为更好地管理Linux内核开发而设计。\n  特点\n  速度\n  简单的设计\n  对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n  完全分布式\n  有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）\n    三种状态[工作区域]\n  已提交(commit),[Git仓库]\n  已修改(modified),[工作目录]\n  已暂存(staged),[暂存区域]\n    基本工作流程\n  在工作目录中修改文件\n  暂存文件，将文件的快照放入暂存区域。\n  提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n     Git安装 #  Git操作 #  "});index.add({'id':2,'href':'/notes/docs/technology/program/revision/git/install/','title':"Git安装",'section':"Git",'content':"Git安装 #    yum安装\n $ sudo yum install git    源码安装\n依赖包安装\n $ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc xmlto docbook2x  从 https://www.kernel.org/pub/software/scm/git获取最新的版本包\n编译安装\n $ tar -zxf git-2.0.0.tar.gz $ cd git-2.0.0 $ make configure $ ./configure --prefix=/usr/local/git $ make all doc info $ sudo make install install-doc install-html install-info  升级\n $ git clone git://git.kernel.org/pub/scm/git/git.git     Git初始配置 #  Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n  /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 \u0026ndash;system 选项的 git config 时，它会从此文件读写配置变量。\n  ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 \u0026ndash;global 选项让 Git 读写此文件。\n  当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n  每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n用户信息 #  当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n$ git config --global user.name \u0026quot;CodeCC\u0026quot; $ git config --global user.email CodeCC@example.com  再次强调，如果使用了 \u0026ndash;global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 \u0026ndash;global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n检查配置信息 #  如果想要检查你的配置，可以使用 git config \u0026ndash;list 命令来列出所有 Git 当时能找到的配置。\n$ git config --list user.name=CodeCC user.email=CodeCC@example.com ...  也可以通过输入 git config ： 来检查 Git 的某一项配置\n$ git config user.name CodeCC  "});index.add({'id':3,'href':'/notes/docs/technology/program/revision/git/operation/','title':"Git操作",'section':"Git",'content':"Git操作 #  创建版本库 #    创建一个空目录\n$ cd /usr/local/src\n $ mkdir project    创建版本库\n  初始化\n$ git init Initialized empty Git repository in /usr/local/src/project/.git/\n  克隆现有仓库\n$ git clone [url]\n    添加文件\n$ git add README.md\n $ git commit -m 'first commit'     记录更新 #  记录每次更新到仓库 #    文件状态\n  已跟踪文件\n  未修改\n  已修改\n  已放入暂存区\n    未跟踪文件\n    使用 Git 时文件的生命周期如下：\n  文件状态 #  git status 命令，用于查看哪些文件处于什么状态。\n已跟踪文件未被更改过，且没有处于未跟踪状态的新文件。会看到类似这样的输出：\n$ git status On branch master nothing to commit, working directory clean  存在新的未跟踪文件。会看到类似这样的输出：\n$ echo 'My Project' \u0026gt; README.md $ git status # On branch master # # Initial commit # # Untracked files: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) # # README.md nothing added to commit but untracked files present (use \u0026quot;git add\u0026quot; to track)   跟踪新文件 #  使用命令 git add 开始跟踪一个文件。\n$ git add README.md  存在已跟踪文件，并处于暂存状态。会看到类似这样的输出：\n# On branch master # # Initial commit # # Changes to be committed: # (use \u0026quot;git rm --cached \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # new file: README.md #   暂存已修改文件 #  已跟踪文件的内容发生了变化，但还没有放到暂存区。会看到类似这样的输出：\n$ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # new file: README.md # # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md #  要暂存这次更新，需要运行 git add 命令。这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。\n$ git add CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: CONTRIBUTING.md # new file: README.md #   状态简览 #  使用 git status -s 命令或 git status \u0026ndash;short 命令，获取一种更为紧凑的格式输出。 状态报告输出如下：\n$ git status -s M CONTRIBUTING.md A README.md ?? HELLO.md  状态标记详解\n??：新添加的未跟踪文件 A ：新添加到暂存区中的文件 M ：修改过得文件，并放入暂存区 M：修改过得文件，还未放入暂存区 MM：修改并提交到暂存区后又在工作区被修改   忽略文件 #  创建一个名为 .gitignore 的文件，列出要忽略的文件模式。\n$ cat .gitignore *.[oa] *~  文件 .gitignore 的格式规范如下：\n  所有空行或者以 # 开头的行都会被 Git 忽略。\n  可以使用标准的 glob 模式匹配。\n 星号（*）匹配零个或多个任意字符； [abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）; 问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。    匹配模式可以以（/）开头防止递归。\n  匹配模式可以以（/）结尾指定目录。\n  要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。\n  我们再看一个 .gitignore 文件的例子：\n# no .a files *.a # but do track lib.a, even though you're ignoring .a files above !lib.a # only ignore the TODO file in the current directory, not subdir/TODO /TODO # ignore all files in the build/ directory build/ # ignore doc/notes.txt, but not doc/server/arch.txt doc/*.txt # ignore all .pdf files in the doc/ directory doc/**/*.pdf  TIP GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表，你可以在 https://github.com/github/gitignore 找到它.\n 查看已暂存和未暂存的修改 #  git diff 命令，查看具体修改内容。 git diff 将通过文件补丁的格式显示具体哪些行发生了改变。\n查看尚未暂存的文件更新内容，直接输入 git diff：\n$ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 23509e0..90f904d 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -1,2 +1,3 @@ hello git +add con  此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。\n若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff \u0026ndash;cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff \u0026ndash;staged，效果是相同的，但更好记些。）\n$ git diff --staged diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index ce01362..90f904d 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -1 +1,3 @@ hello +git +add con diff --git a/README.md b/README.md new file mode 100644 index 0000000..de369b6 --- /dev/null +++ b/README.md @@ -0,0 +1,2 @@ +My Project +abc  请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。\n 提交更新 #  现在的暂存区域已经准备妥当可以提交了。 在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit, 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示：\n$ git commit -m 'modify file' [master d19800e] modify file 2 files changed, 4 insertions(+), 0 deletions(-) create mode 100644 README.md  好，现在你已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。\n请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。\n 跳过使用暂存区域 #  尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤：\n$ echo \u0026quot;follow me\u0026quot; \u0026gt;\u0026gt; CONTRIBUTING.md $ git status # On branch master # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md # no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) $ git commit -a -m 'added new benchmarks' [master 3bcc140] added new benchmarks 1 files changed, 1 insertions(+), 0 deletions(-)   移除文件 #  要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。\n如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分（也就是 未暂存清单）看到：\n$ rm project.md $ git status # On branch master # Changed but not updated: # (use \u0026quot;git add/rm \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # deleted: project.md # no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;)  然后再运行 git rm 记录此次移除文件的操作：\n$ git rm project.md rm 'project.md' $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # deleted: project.md #  下一次提交时，该文件就不再纳入版本管理了。 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。\n另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 \u0026ndash;cached 选项：\n$ git rm --cached README  git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说：\n$ git rm log/\\*.log  注意到星号 * 之前的反斜杠 \\， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如：\n$ git rm \\*~  该命令为删除以 ~ 结尾的所有文件。\n 移动文件 #  不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。\n既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做：\n$ git mv file_from file_to 它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明：\n$ git mv README.md README # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # renamed: README.md -\u0026gt; README #  其实，运行 git mv 就相当于运行了下面三条命令：\n$ mv README.md README $ git rm README.md $ git add README  如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而另一种方式需要三条命令，直接用 git mv 轻便得多。 不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。\n 提交历史 #  查看提交历史 #  git log 命令，查看提交历史。\n$ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit  ​ 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。\n git log 常用选项 #  -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交：\n$ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile index a874b73..8f94139 100644 --- a/Rakefile +++ b/Rakefile @@ -5,7 +5,7 @@ require 'rake/gempackagetask' spec = Gem::Specification.new do |s| s.platform = Gem::Platform::RUBY s.name = \u0026quot;simplegit\u0026quot; - s.version = \u0026quot;0.1.0\u0026quot; + s.version = \u0026quot;0.1.1\u0026quot; s.author = \u0026quot;Scott Chacon\u0026quot; s.email = \u0026quot;schacon@gee-mail.com\u0026quot; s.summary = \u0026quot;A simple gem for using Git in Ruby code.\u0026quot; commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test diff --git a/lib/simplegit.rb b/lib/simplegit.rb index a0a60ae..47c6340 100644 --- a/lib/simplegit.rb +++ b/lib/simplegit.rb @@ -18,8 +18,3 @@ class SimpleGit end end - -if $0 == __FILE__ - git = SimpleGit.new - puts git.show -end \\ No newline at end of file  \u0026ndash;stat，查看每次提交的简略的统计信息\n$ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test lib/simplegit.rb | 5 ----- 1 file changed, 5 deletions(-) commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+)  \u0026ndash;pretty。 指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用。\n$ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit  但最有意思的是 format，可以定制要显示的记录格式。 这样的输出对后期提取分析格外有用 — 因为你知道输出的格式不会随着Git的更新而发生改变：\n$ git log --pretty=format:\u0026quot;%h - %an, %ar : %s\u0026quot; ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit  git log \u0026ndash;pretty=format 常用的选项\n   选项 说明     %H 提交对象（commit）的完整哈希字串   %h 提交对象的简短哈希字串   %T 树对象（tree）的完整哈希字串   %t 树对象的简短哈希字串   %P 父对象（parent）的完整哈希字串   %p 父对象的简短哈希字串   %an 作者（author）的名字   %ae 作者的电子邮件地址   %ad 作者修订日期（可以用 \u0026ndash;date= 选项定制格式）   %ar 作者修订日期，按多久以前的方式显示   %cn 提交者(committer)的名字   %ce 提交者的电子邮件地址   %cd 提交日期   %cr 提交日期，按多久以前的方式显示   %s 提交说明    当 oneline 或 format 与另一个 log 选项 \u0026ndash;graph 结合使用时尤其有用。 这个选项添加了一些ASCII字符串来形象地展示你的分支、合并历史：\n$ git log --pretty=format:\u0026quot;%h %s\u0026quot; --graph * 2d3acf9 ignore errors from SIGCHLD on trap * 5e3ee11 Merge branch 'master' of git://github.com/dustin/grit |\\ | * 420eac9 Added a method for getting the current branch. * | 30e367c timeout code and tests * | 5a09431 add timeout protection to grit * | e1193f8 support for heads with slashes in them |/ * d6016bc require time for xmlschema * 11d191e Merge branch 'defunkt' into local  git log 的常用选项\n   选项 说明     -p 按补丁格式显示每个更新之间的差异。   \u0026ndash;stat 显示每次更新的文件修改统计信息。   \u0026ndash;shortstat 只显示 \u0026ndash;stat 中最后的行数修改添加移除统计。   \u0026ndash;name-only 仅在提交信息后显示已修改的文件清单。   \u0026ndash;name-status 显示新增、修改、删除的文件清单。   \u0026ndash;abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。   \u0026ndash;relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。   \u0026ndash;pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。    限制输出长度 除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。\n另外还有按照时间作限制的选项，比如 \u0026ndash;since 和 \u0026ndash;until 也很有用。 例如，下面的命令列出所有最近两周内的提交：\n$ git log --since=2.weeks  这个命令可以在多种格式下工作，比如说具体的某一天 \u0026ldquo;2008-01-15\u0026rdquo;，或者是相对地多久以前 \u0026ldquo;2 years 1 day 3 minutes ago\u0026rdquo;。\n另一个非常有用的筛选选项是 -S，可以列出那些添加或移除了某些字符串的提交。 比如说，你想找出添加或移除了某一个特定函数的引用的提交，你可以这样使用：\n$ git log -Sfunction_name  限制 git log 输出的选项\n   选项 说明     -(n) 仅显示最近的 n 条提交   \u0026ndash;since, \u0026ndash;after 仅显示指定时间之后的提交。   \u0026ndash;until, \u0026ndash;before 仅显示指定时间之前的提交。   \u0026ndash;author 仅显示指定作者相关的提交。   \u0026ndash;committer 仅显示指定提交者相关的提交。   \u0026ndash;grep 仅显示含指定关键字的提交   -S 仅显示添加或移除了某个关键字的提交   \u0026ndash;all-match 显示满足所有匹配条件的提交   \u0026ndash;(path) 仅显示某些文件或者目录的提交（选项最后指定）    例子， 查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试文件，可以用下面的查询命令：\n$ git log --pretty=\u0026quot;%h - %s\u0026quot; --author=Junio Hamano --since=\u0026quot;2008-10-01\u0026quot; \\ --before=\u0026quot;2008-11-01\u0026quot; --no-merges -- t/ 5610e3b - Fix testcase failure when extended attributes are in use acd3b9e - Enhance hold_lock_file_for_{update,append}() API f563754 - demonstrate breakage of detached checkout with symbolic link HEAD d1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths 51a94af - Fix \u0026quot;checkout --track -b newbranch\u0026quot; on detached HEAD b0ad11e - pull: allow \u0026quot;git pull origin $something:$current_branch\u0026quot; into an unborn branch   撤销操作 #  重新提交 #  \u0026ndash;amend 选项的提交命令尝试重新提交：\n$ git commit --amend  这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。 文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。\n例如，你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作：\n$ git commit -m 'initial commit' $ git add forgotten_file $ git commit --amend  最终你只会有一个提交 - 第二次提交将代替第一次提交的结果。\n 取消暂存的文件 #  $ git add * $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: CONTRIBUTING.md # modified: README #  git rest HEAD  取消暂存：\n$ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: README # # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md #   撤消对文件的修改 #  git checkout \u0026ndash;  ， 将它还原成上次提交时的样子：\n$ git checkout -- CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: README #   远程仓库 #  远程仓库是指托管在因特网或其他网络中的你的项目的版本库。 你可以有好几个远程仓库，通常有些仓库对你只读，有些则可以读写。 与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。\n管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。\n 查看远程仓库 #  git remote ： 列出指定的每一个远程服务器的简写。 如果你已经克隆了自己的仓库，那么至少应该能看到 origin\n$ git remote origin  指定选项 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。\n$ git remote -v origin https://github.com/Code-CC/leetcode (fetch) origin https://github.com/Code-CC/leetcode (push)   添加远程仓库 #  运行 git remote add   添加一个新的远程 Git 仓库，同时指定一个你可以轻松引用的简写：\n$ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin\thttps://github.com/schacon/ticgit (fetch) origin\thttps://github.com/schacon/ticgit (push) pb\thttps://github.com/paulboone/ticgit (fetch) pb\thttps://github.com/paulboone/ticgit (push)  现在你可以在命令行中使用字符串 pb 来代替整个 URL。 例如，如果你想拉取 Paul 的仓库中有但你没有的信息，可以运行 git fetch pb：\n$ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43/43), done. From https://github.com/paulboone/ticgit * [new branch] master -\u0026gt; pb/master * [new branch] ticgit -\u0026gt; pb/ticgit   从远程仓库中抓取与拉取 #  从远程仓库中获得数据，可以执行：\n$ git fetch [remote-name]  这个命令会访问远程仓库，从中拉取所有你还没有的数据。（不进行合并分支）\n$ git pull [remote-name] [buranch-name]  这个命令会自动的抓取然后合并远程分支到当前分支。\n 推送到远程仓库 #  当你想分享你的项目时，必须将其推送到上游。可以使用下面的命令：\ngit push [remote-name] [branch-name]  只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。\n 查看远程仓库 #  git remote show [remote-name] ：查看远程仓库信息。\n$ git remote show origin * remote origin Fetch URL: https://github.com/Code-CC/leetcode Push URL: https://github.com/Code-CC/leetcode HEAD branch: master Remote branch: master tracked Local branch configured for 'git pull': master merges with remote master Local ref configured for 'git push': master pushes to master (local out of date)  它同样会列出远程仓库的 URL 与跟踪分支的信息。\n 远程仓库的移除与重命名 #  git remote rename ：修改一个远程仓库的简写名。\n$ git remote rename pb paul $ git remote origin paul  git remote rm ：移除一个远程仓库\n$ git remote rm paul $ git remote origin   标签 #  Git 可以给历史中的某一个提交打上标签，以示重要。 比较有代表性的是人们会使用这个功能来标记发布结点（v1.0 等等）。\n 列出标签 #  git tag：列出已有的标签\n$ git tag v0.1 v1.3  git tag -l ：使用特定的模式查找标签。\n$ git tag -l 'v1.8.5*' v1.8.5 v1.8.5-rc0 v1.8.5-rc1 v1.8.5-rc2 v1.8.5-rc3 v1.8.5.1 v1.8.5.2 v1.8.5.3 v1.8.5.4 v1.8.5.5   创建标签 #  Git 使用两种主要类型的标签：轻量标签（lightweight）与附注标签（annotated）。\n一个轻量标签很像一个不会改变的分支 - 它只是一个特定提交的引用。\n然而，附注标签是存储在 Git 数据库中的一个完整对象。 它们是可以被校验的；其中包含打标签者的名字、电子邮件地址、日期时间；还有一个标签信息；并且可以使用 GNU Privacy Guard （GPG）签名与验证。 通常建议创建附注标签，这样你可以拥有以上所有信息；但是如果你只是想用一个临时的标签，或者因为某些原因不想要保存那些信息，轻量标签也是可用的。\n  附注标签\ngit tag -a ：添加一个附注标签。\n$ git tag -a v1.4 -m \u0026lsquo;my version 1.4\u0026rsquo; $ git tag v0.1 v1.3 v1.4\n-m 选项指定了一条将会存储在标签中的信息。 如果没有为附注标签指定一条信息，Git 会运行编辑器要求你输入信息。\ngit show 命令可以看到标签信息与对应的提交信息：\n$ git show v1.4 tag v1.4 Tagger: Ben Straub ben@straub.cc Date: Sat May 3 20:19:12 2014 -0700\nmy version 1.4\ncommit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon schacon@gee-mail.com Date: Mon Mar 17 21:52:11 2008 -0700\n changed the version number    轻量标签\n$ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5\n这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息：\n$ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon schacon@gee-mail.com Date: Mon Mar 17 21:52:11 2008 -0700\n changed the version number    后期打标签\n你也可以对过去的提交打标签。 假设提交历史是这样的：\n$ git log \u0026ndash;pretty=oneline 15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch \u0026lsquo;experiment\u0026rsquo; a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support 0d52aaab4479697da7686c15f77a3d64d9165190 one more thing 6d52a271eda8725415634dd79daabbc4d9b6008e Merge branch \u0026lsquo;experiment\u0026rsquo; 0b7434d86859cc7b8c3d5e1dddfed66ff742fcbc added a commit function 4682c3261057305bdd616e23b64b0857d832627b added a todo file 166ae0c4d3f420721acbb115cc33848dfcc2121a started write support 9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile 964f16d36dfccde844893cac5b347e7b3d44abbc commit the todo 8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme\n现在，假设在 v1.2 时你忘记给项目打标签，也就是在 “updated rakefile” 提交。 你可以在之后补上标签。 要在那个提交上打标签，你需要在命令的末尾指定提交的校验和（或部分校验和）:\n$ git tag -a v1.2 9fceb02\n$ git tag v0.1 v1.2 v1.3 v1.4 v1.4-lw v1.5\n$ git show v1.2 tag v1.2 Tagger: Scott Chacon schacon@gee-mail.com Date: Mon Feb 9 15:32:16 2009 -0800\nversion 1.2 commit 9fceb02d0ae598e95dc970b74767f19372d61af8 Author: Magnus Chacon mchacon@gee-mail.com Date: Sun Apr 27 20:43:35 2008 -0700\n updated rakefile  \u0026hellip;\n   共享标签 #  默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样 - 你可以运行 git push origin [tagname]。\n$ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -\u0026gt; v1.5  如果想要一次性推送很多标签，也可以使用带有 \u0026ndash;tags 选项的 git push 命令。\n$ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -\u0026gt; v1.4 * [new tag] v1.4-lw -\u0026gt; v1.4-lw   检出标签 #  在 Git 中你并不能真的检出一个标签，因为它们并不能像分支一样来回移动。 如果你想要工作目录与仓库中特定的标签版本完全一样，可以使用 git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支：\n$ git checkout -b version2 v2.0.0 Switched to a new branch 'version2'  当然，如果在这之后又进行了一次提交，version2 分支会因为改动向前移动了，那么 version2 分支就会和 v2.0.0 标签稍微有些不同，这时就应该当心了。\n 别名 #  Git 并不会在你输入部分命令时自动推断出你想要的命令。 如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 这里有一些例子你可以试试：\n$ git config --global alias.co checkout $ git config --global alias.br branch $ git config --global alias.ci commit $ git config --global alias.st status  这意味着，当要输入 git commit 时，只需要输入 git ci。 随着你继续不断地使用 Git，可能也会经常使用其他命令，所以创建别名时不要犹豫。\n在创建你认为应该存在的命令时这个技术会很有用。 例如，为了解决取消暂存文件的易用性问题，可以向 Git 中添加你自己的取消暂存别名：\n$ git config --global alias.unstage 'reset HEAD --'  这会使下面的两个命令等价：\n$ git unstage fileA $ git reset HEAD -- fileA  这样看起来更清楚一些。 通常也会添加一个 last 命令，像这样：\n$ git config --global alias.last 'log -1 HEAD'  这样，可以轻松地看到最后一次提交：\n$ git last commit 66938dae3329c7aebe598c2246a8e6af90d04646 Author: Josh Goebel \u0026lt;dreamer3@example.com\u0026gt; Date: Tue Aug 26 19:48:51 2008 +0800 test for current head Signed-off-by: Scott Chacon \u0026lt;schacon@example.com\u0026gt;  可以看出，Git 只是简单地将别名替换为对应的命令。 然而，你可能想要执行外部命令，而不是一个 Git 子命令。 如果是那样的话，可以在命令前面加入 ! 符号。 如果你自己要写一些与 Git 仓库协作的工具的话，那会很有用。 我们现在演示将 git visual 定义为 gitk 的别名：\n$ git config --global alias.visual '!gitk' "});index.add({'id':4,'href':'/notes/docs/technology/system/linux/programming/io/','title':"IO",'section':"系统编程",'content':"IO #  I/O模型 #  对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：\n 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)  正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。\n 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO）   阻塞I/O #   当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。\n 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。\n  非阻塞I/O #   当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\n 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。\n  信号驱动I/O #    异步I/O #   用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。\n I/O多路复用 #   IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。\n 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。\n所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n 总结 #  blocking和non-blocking的区别 #  调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。\nsynchronous IO和asynchronous IO的区别 #  在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： - A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; - An asynchronous I/O operation does not cause the requesting process to be blocked;\n两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。\n有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。\n各个IO Model的比较如图所示：\n 通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\n I/O 多路复用之select、poll、epoll详解 #  select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）\nselect #  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。\n poll #  int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。\nstruct pollfd { int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */ }; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\n 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\n  epoll #  epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。\n 1. epoll操作过程 #  epoll操作过程需要三个接口，分别如下：\nint epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 1. int epoll_create(int size); 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\n2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。 - epfd：是epoll_create()的返回值。 - op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 - fd：是需要监听的fd（文件描述符） - epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\nstruct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。 参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n 2. 工作模式 #  　epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\n1. LT模式 #  LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\n2. ET模式 #  ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\nET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n3. 总结 #  假如有这样一个例子：\n 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)\u0026hellip;\u0026hellip;  LT模式： 如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。\nET模式： 如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。\n当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后， 读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：\nwhile(rs){ buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen \u0026lt; 0){ // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读  // 在这里就当作是该次事件已处理处.  if(errno == EAGAIN){ break; } else{ return; } } else if(buflen == 0){ // 这里表示对端的socket已正常关闭.  } if(buflen == sizeof(buf){ rs = 1; // 需要再次读取  } else{ rs = 0; } }  Linux中的EAGAIN含义\n Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。\n例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。\n 3. 代码演示 #  下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。\n#define IPADDRESS \u0026#34;127.0.0.1\u0026#34; #define PORT 8787 #define MAXSIZE 1024 #define LISTENQ 5 #define FDSIZE 1000 #define EPOLLEVENTS 100  listenfd = socket_bind(IPADDRESS,PORT); struct epoll_event events[EPOLLEVENTS]; //创建一个描述符 epollfd = epoll_create(FDSIZE); //添加监听描述符事件 add_event(epollfd,listenfd,EPOLLIN); //循环等待 for ( ; ; ){ //该函数返回已经准备好的描述符事件数目  ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接  handle_events(epollfd,events,ret,listenfd,buf); } //事件处理函数 static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf) { int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。  for (i = 0;i \u0026lt; num;i++) { fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理  if ((fd == listenfd) \u0026amp;\u0026amp;(events[i].events \u0026amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events \u0026amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events \u0026amp; EPOLLOUT) do_write(epollfd,fd,buf); } } //添加事件 static void add_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,\u0026amp;ev); } //处理接收到的连接 static void handle_accpet(int epollfd,int listenfd){ int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;cliaddrlen); if (clifd == -1) perror(\u0026#34;accpet error:\u0026#34;); else { printf(\u0026#34;accept a new client: %s:%d\\n\u0026#34;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件  add_event(epollfd,clifd,EPOLLIN); } } //读处理 static void do_read(int epollfd,int fd,char *buf){ int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) { perror(\u0026#34;read error:\u0026#34;); close(fd); //记住close fd  delete_event(epollfd,fd,EPOLLIN); //删除监听  } else if (nread == 0) { fprintf(stderr,\u0026#34;client close.\\n\u0026#34;); close(fd); //记住close fd  delete_event(epollfd,fd,EPOLLIN); //删除监听  } else { printf(\u0026#34;read message is : %s\u0026#34;,buf); //修改描述符对应的事件，由读改为写  modify_event(epollfd,fd,EPOLLOUT); } } //写处理 static void do_write(int epollfd,int fd,char *buf) { int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1){ perror(\u0026#34;write error:\u0026#34;); close(fd); //记住close fd  delete_event(epollfd,fd,EPOLLOUT); //删除监听  }else{ modify_event(epollfd,fd,EPOLLIN); } memset(buf,0,MAXSIZE); } //删除事件 static void delete_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,\u0026amp;ev); } //修改事件 static void modify_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,\u0026amp;ev); } //注：另外一端我就省了  4. epoll总结 #  在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)\nepoll的优点主要是一下几个方面： \\1. 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。\n IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。   如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n  "});index.add({'id':5,'href':'/notes/docs/technology/network/protocol/ip/','title':"IP",'section':"网络协议",'content':"IP #    "});index.add({'id':6,'href':'/notes/docs/technology/bigdata/application/kafka/','title':"Kafka",'section':"应用",'content':"Kafka #  "});index.add({'id':7,'href':'/notes/docs/technology/howto/lvs/','title':"LVS",'section':"How To",'content':"LVS #  基础概念 #  术语 #   IPVS,ipvs,ip_vs：内核模块，在director上提供负载均衡功能 LVS, linux virtual server ：由 director + realservers组成virtual server，对client显示为一台机器 director: 运行ipvs代码的节点，client连接director，director转发数据包到realserver，director只是具有使LVS正常工作的特殊规则的IP路由器 realservers：运行服务的主机，处理来自client的请求 client forwarding method (currently LVS-NAT, LVS-DR, LVS-Tun)：决定director如何发送数据包给realserver scheduling ( ipvsadm and schedulers)：director用于选择realserver以便为来自client的新连接请求提供服务的算法   LVS中IP/网络的名称 #   ________ | | | client | (local or on internet) |________| CIP | -- (router) DGW | outside network | L VIP i ____|_____ n | | (director can have 1 or 2 NICs) u | director | x |__________| DIP (and PIP) V | i | DRIP network r ---------------------------------- t | | | u | | | a RIP1 RIP2 RIP3 l _____________ _____________ _____________ | | | | | | S | realserver1 | | realserver2 | | realserver3 | e |_____________| |_____________| |_____________| r v e r --- client IP = CIP virtual IP = VIP - the IP on the director that the client connects to) director IP = DIP - the IP on the director in the DIP/RIP (DRIP) network (this is the realserver gateway for LVS-NAT) realserver IP = RIP (and RIP1, RIP2...) the IP on the realserver director GW = DGW - the director's gw (only needed for LVS-NAT) (this can be the realserver gateway for LVS-DR and LVS-Tun)  负载均衡模式(转发方式) #  LVS-NAT #  基于网络地址转换(NAT)实现，所有数据包都要经过director转发，realserver的gateway需配置为RIP\n ________ | | | client | (local or on internet) |________| | (router) DIRECTOR_GW | -- | L Virtual IP i ____|_____ n | | (director can have 1 or 2 NICs) u | director | x |__________| DIP V | i | r -----------------+---------------- t | | | u | | | a RIP1 RIP2 RIP3 l ____________ ____________ ____________ | | | | | | S | realserver | | realserver | | realserver | e |____________| |____________| |____________| r v e r Flow Process #  1. client往VIP(director)发起请求 （source ip为cip，destination ip为vip） 2. director接收请求，ipvs模块在input链通过调度算法选择realserver，将数据包的目标IP和端口改为RIP的IP和端口(source ip为cip，destination ip为rip) 3. POSTROUTING链通过路由选路，将数据包发送给realserver 4. realserver处理请求，给director返回数据包(source ip为rip，destination ip为cip) 5. director接收数据包，修改数据包的源ip为vip，响应给client(source ip为vip，destination ip为cip)(iptables -t nat -A POSTROUTING -s RIP -j MASQUERADE)  LVS-DR（direct routing） #  通过更改数据包上的MAC地址并将数据包转发到realserver，realserver需在lo网卡上配置VIP\n ________ | | | client | (local or on internet) |________| | (router)----------- | SERVER_GW | -- | | L VIP | i ____|_____ | n | | (director can have 1 or 2 NICs) u | director | | x |__________| | DIP | V | | i | | r -----------------+---------------- t | | | u | | | a RIP1,VIP RIP2,VIP RIP3,VIP l ____________ ____________ ____________ | | | | | | S | realserver | | realserver | | realserver | e |____________| |____________| |____________| r v e r Flow Process #  1. client请求vip(director) (cip--\u0026gt;vip) 2. director接收请求，ipvs模块在在input链通过调度算法选择realserver，将数据包的目标mac地址改为realserver的mac地址(cip--\u0026gt;vip) 3. realserver解析数据包，发现ip为自己的lo网卡上的ip，处理请求 4. realserver发送数据包经由gateway直接回复给client，(vip --\u0026gt; cip) TCP状态机问题 #  #Director 1、SYN-RECEIVED (收到syn=1) 2、ESTABLISH(收到ack=1) 3、CLOSE_WAIT或者LAST_ACK(收到fin=1,ack=1) 4、超时机制 ARP问题 #  # realserver 1. vip只能设置在lo网卡上，设置在其他网卡会响应arp request，造成arp table混乱 2. 抑制arp帧， echo \u0026#34;1\u0026#34; \u0026gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo \u0026#34;2\u0026#34; \u0026gt;/proc/sys/net/ipv4/conf/all/arp_announce arp_ignore参数（1）含义：只响应目标IP是本地真实网卡上配置的IP arp_announce参数（2）含义：忽略报文的源IP地址，使用主机上能够跟用户通信的真实网卡发送数据 Keepalived集群问题 #  假设主备 director包含rs， 可以这样处理： 经过 director1 的包，如果 mac address 不是 director2 的，用 iptables 给包打 mark=i 经过 director2 的包，如果 mac address 不是 director1 的，用 iptables 给包打 mark=j 同时配置 LVS，不用三元组(ip,port,protocol)来表示 virtual_server，而用 fwmark-service，keepalived 配置 lvs 使用 fwmark-service。 这样，如果是 director 转发过来的包，就不会进入 LVS 进行负载（防止两个 director 互相扔皮球，进入死循环），而是被 RS 服务处理。而客户端进来的包，就会进入 LVS 进行负载。 iptables -t mangle -I PREROUTING -d $VIP -p tcp -m tcp --dport $VPORT -m mac ! --mac-source $MAC_Director2 -j MARK --set-mark 0x3 iptables -t mangle -I PREROUTING -d $VIP -p tcp -m tcp --dport $VPORT -m mac ! --mac-source $MAC_Director1 -j MARK --set-mark 0x4 keealived virtual_server fwmark 3 { # node2 配置 fwmark 4 delay_loop 10 lb_algo rr lb_kind DR protocol TCP real_server RIP1 8080 { weight 1 MISC_CHECK { # some check configuration } } real_server RIP2 8080 { weight 1 MISC_CHECK { # some check configuration } }  LVS-Tun（tunnelling） #  数据包经过IP隧道技术封装并转发到realserver\n 调度算法 #   round robin (rr), weighted round robin (wrr) ：轮询和按权重轮询 least connected (lc), weighted least connection (wlc)：最小连接和按权重的最小连接    persistent connection LBLC: a persistent memory algorythm DH: destination hash SH: source hash  #  "});index.add({'id':8,'href':'/notes/docs/technology/database/sql/mysql/','title':"MySQL",'section':"SQL",'content':"MySQL #     Install guide\n   Cluster\n  "});index.add({'id':9,'href':'/notes/docs/technology/database/sql/mysql/excute/','title':"MySQL执行过程",'section':"MySQL",'content':"MySQL执行过程 #     大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL5.5.5 版本开始成为了默认存储引擎。\n 连接器 #  连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n 查询缓存 #  查询缓存连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个value 就会被直接返回给客户端。\n 分析器 #  如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的\u0026quot;select\u0026quot;这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n 优化器 #  经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n 执行器 #  MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口\n "});index.add({'id':10,'href':'/notes/docs/technology/security/firewall/netfilter/','title':"netfilter",'section':"防火墙",'content':"netfilter #  Netfilter：Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：\n  网络地址转换(Network Address Translate)\n  数据包内容修改\n  数据包过滤\n  Netfilter的配置表：存放设置的规则的文件，存放在内核内存中。iptables程序通过修改这个规则文件来控制网络数据包流动。 该配置表由表tables、链chains、规则rules组成。\n Netfilter配置表 #  表(tables) #  用于实现特定的功能\n  raw表\n主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链 OUTPUT、PREROUTING。\niptables中数据包和4种被跟踪连接的4种不同状态：\n NEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。 ESTABLISHED ：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。    mangle表\n主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。\n  nat表\n主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包 的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。\n表对应的内核模块为 iptable_nat，包含三个链：\n PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址    filter表\n主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链：\n INPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包    链(chains) #  在处理各种数据包时，根据防火墙规则的不同介入时机，iptables供涉及5种默认规则链，从应用时间点的角度理解这些链：\n  INPUT链：当接收到防火墙本机地址的数据包（入站）时，应用此链中的规则。\n  OUTPUT链：当防火墙本机向外发送数据包（出站）时，应用此链中的规则。\n  FORWARD链：当接收到需要通过防火墙发送给其他地址的数据包（转发）时，应用此链中的规则。\n  PREROUTING链：在对数据包作路由选择之前，应用此链中的规则，如DNAT。\n  POSTROUTING链：在对数据包作路由选择之后，应用此链中的规则，如SNAT。\n  规则(rules) #    ACCEPT：允许数据包通过\n  DROP：直接丢弃数据包，不给任何回应信息\n  REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息。\n  SNAT：源地址转换。在进入路由层面的route之前，重新改写源地址，目标地址不变，并在本机建立NAT表项，当数据返回时，根据NAT表将 目的地址数据改写为数据发送出去时候的源地址，并发送给主机。解决内网用户用同一个公网地址上网的问题。 MASQUERADE，是SNAT的一种特殊形式，适用于像adsl这种临时会变的ip上\n  DNAT:目标地址转换。和SNAT相反，IP包经过route之后、出本地的网络栈之前，重新修改目标地址，源地址不变，在本机建立NAT表项，当 数据返回时，根据NAT表将源地址修改为数据发送过来时的目标地址，并发给远程主机。可以隐藏后端服务器的真实地址。 REDIRECT：是DNAT的一种特殊形式，将网络包转发到本地host上（不管IP头部指定的目标地址是啥），方便在本机做端口转发。\n  LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则\n  除去最后一个LOG，前3条规则匹配数据包后，该数据包不会再往下继续匹配了，所以编写的规则顺序极其关键。\n 原理 #      从上图中，我们可以总结出以下规律：\n  一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转发出去。\n  如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经 过OUTPUT链，然后到达POSTROUTING链输出。\n  如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过 FORWARD链，然后到达POSTROUTING链输出。\n   "});index.add({'id':11,'href':'/notes/docs/technology/program/web/oauth/','title':"oauth",'section':"WEB编程",'content':"oauth #   OAuth是一个关于授权（authorization）的开放网络标准，在全世界得到广泛应用，目前的版本是2.0版。参考材料 RFC 6749。\n 名词定义 #  在详细讲解OAuth 2.0之前，需要了解几个专用名词。它们对读懂后面的讲解，尤其是几张图，至关重要。\n （1） Third-party application：第三方应用程序，本文中又称\u0026quot;客户端\u0026rdquo;（client），即上一节例子中的\u0026quot;云冲印\u0026rdquo;。\n（2）HTTP service：HTTP服务提供商，本文中简称\u0026quot;服务提供商\u0026rdquo;，即上一节例子中的Google。\n（3）Resource Owner：资源所有者，本文中又称\u0026quot;用户\u0026rdquo;（user）。\n（4）User Agent：用户代理，本文中就是指浏览器。\n（5）Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器。\n（6）Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。\n 知道了上面这些名词，就不难理解，OAuth的作用就是让\u0026quot;客户端\u0026quot;安全可控地获取\u0026quot;用户\u0026quot;的授权，与\u0026quot;服务商提供商\u0026quot;进行互动。\n 运行流程 #   +--------+ +---------------+ | |--(A)------- Authorization Grant ---------\u0026gt;| | | | | | | |\u0026lt;-(B)----------- Access Token -------------| | | | \u0026amp; Refresh Token | | | | | | | | +----------+ | | | |--(C)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(D)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(E)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(F)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(G)----------- Refresh Token -----------\u0026gt;| | | | | | | |\u0026lt;-(H)----------- Access Token -------------| | +--------+ \u0026amp; Optional Refresh Token +---------------+ （A）用户打开客户端以后，客户端要求用户给予授权。\n（B）用户同意给予客户端授权。\n（C）客户端使用上一步获得的授权，向认证服务器申请令牌。\n（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。\n（E）客户端使用令牌，向资源服务器申请获取资源。\n（F）资源服务器确认令牌无误，同意向客户端开放资源。\n 客户端授权模式 #  客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。\n 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials）   1. Authorization Code Grant #   +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ----\u0026gt;| | | User- | | Authorization | | Agent -+----(B)-- User authenticates ---\u0026gt;| Server | | | | | | -+----(C)-- Authorization Code ---\u0026lt;| | +-|----|---+ +---------------+ | | ^ v (A) (C) | | | | | | ^ v | | +---------+ | | | |\u0026gt;---(D)-- Authorization Code ---------' | | Client | \u0026amp; Redirection URI | | | | | |\u0026lt;---(E)----- Access Token -------------------' +---------+ (w/ Optional Refresh Token) Note: The lines illustrating steps (A), (B), and (C) are broken into two parts as they pass through the user-agent. （A）用户访问客户端，后者将前者导向认证服务器。\n（B）用户选择是否给予客户端授权。\n（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的\u0026quot;重定向URI\u0026rdquo;（redirection URI），同时附上一个授权码。\n（D）客户端收到授权码，附上早先的\u0026quot;重定向URI\u0026rdquo;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。\n（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。\n 下面是上面这些步骤所需要的参数。\nA步骤中，客户端申请认证的URI，包含以下参数：\n response_type：表示授权类型，必选项，此处的值固定为\u0026quot;code\u0026rdquo; client_id：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。  下面是一个例子。\n https://authorization-server.com/oauth/authorize ?client_id=a17c21ed \u0026amp;response_type=code \u0026amp;state=5ca75bd30 \u0026amp;redirect_uri=https%3A%2F%2Fexample-app.com%2Fauth \u0026amp;scope=photos  C步骤中，服务器回应客户端的URI，包含以下参数：\n code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。  下面是一个例子。\n HTTP/1.1 302 Found Location: https://example-app.com/cb?code=Yzk5ZDczMzRlNDEwY\u0026amp;state=5ca75bd30  D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数：\n grant_type：表示使用的授权模式，必选项，此处的值固定为\u0026quot;authorization_code\u0026rdquo;。 code：表示上一步获得的授权码，必选项。 redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。 client_id：表示客户端ID，必选项。  下面是一个例子。\n POST /oauth/token HTTP/1.1 Host: authorization-server.com  grant_type=authorization_code \u0026amp;code=xxxxxxxxxxx \u0026amp;redirect_uri=https://example-app.com/redirect \u0026amp;client_id=xxxxxxxxxx \u0026amp;client_secret=xxxxxxxxxx  E步骤中，认证服务器发送的HTTP回复，包含以下参数：\n access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。  下面是一个例子。\n HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;: \u0026#34;AYjcyMzY3ZDhiNmJkNTY\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;RjY2NjM5NzA2OWJjuE7c\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;expires\u0026#34;: 3600 }   2. Implicit Grant #  +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ---\u0026gt;| | | User- | | Authorization | | Agent -|----(B)-- User authenticates --\u0026gt;| Server | | | | | | |\u0026lt;---(C)--- Redirection URI ----\u0026lt;| | | | with Access Token +---------------+ | | in Fragment | | +---------------+ | |----(D)--- Redirection URI ----\u0026gt;| Web-Hosted | | | without Fragment | Client | | | | Resource | | (F) |\u0026lt;---(E)------- Script ---------\u0026lt;| | | | +---------------+ +-|--------+ | | (A) (G) Access Token | | ^ v +---------+ | | | Client | | | +---------+ Note: The lines illustrating steps (A) and (B) are broken into two parts as they pass through the user-agent. （A）客户端将用户导向认证服务器。\n（B）用户决定是否给于客户端授权。\n（C）假设用户给予授权，认证服务器将用户导向客户端指定的\u0026quot;重定向URI\u0026rdquo;，并在URI的Hash部分包含了访问令牌。\n（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。\n（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。\n（F）浏览器执行上一步获得的脚本，提取出令牌。\n（G）浏览器将令牌发给客户端。\n 下面是上面这些步骤所需要的参数。\nA步骤中，客户端发出的HTTP请求，包含以下参数：\n response_type：表示授权类型，此处的值固定为\u0026quot;token\u0026rdquo;，必选项。 client_id：表示客户端的ID，必选项。 redirect_uri：表示重定向的URI，可选项。 scope：表示权限范围，可选项。 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。  下面是一个例子。\n GET /authorize?response_type=token\u0026amp;client_id=s6BhdRkqt3\u0026amp;state=xyz \u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com  C步骤中，认证服务器回应客户端的URI，包含以下参数：\n access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。  下面是一个例子。\n HTTP/1.1 302 Found Location: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA \u0026amp;state=xyz\u0026amp;token_type=example\u0026amp;expires_in=3600  在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。\n根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的代码，会提取出Hash中的令牌。\n 3. Resource Owner Password Credentials Grant #   +----------+ | Resource | | Owner | | | +----------+ v | Resource Owner (A) Password Credentials | v +---------+ +---------------+ | |\u0026gt;--(B)---- Resource Owner -------\u0026gt;| | | | Password Credentials | Authorization | | Client | | Server | | |\u0026lt;--(C)---- Access Token ---------\u0026lt;| | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ （A）用户向客户端提供用户名和密码。\n（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。\n（C）认证服务器确认无误后，向客户端提供访问令牌。\n B步骤中，客户端发出的HTTP请求，包含以下参数：\n grant_type：表示授权类型，此处的值固定为\u0026quot;password\u0026rdquo;，必选项。 username：表示用户名，必选项。 password：表示用户的密码，必选项。 scope：表示权限范围，可选项。  下面是一个例子。\n POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=password\u0026amp;username=johndoe\u0026amp;password=A3ddj3w  C步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。\n HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;refresh_token\u0026#34;:\u0026#34;tGzv3JOkF0XG5Qx2TlKWIA\u0026#34;, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; }  上面代码中，各个参数的含义参见《授权码模式》一节。\n整个过程中，客户端不得保存用户的密码。\n 4. Client Credentials Grant #   +---------+ +---------------+ | | | | | |\u0026gt;--(A)- Client Authentication ---\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;--(B)---- Access Token ---------\u0026lt;| | | | | | +---------+ +---------------+ （A）客户端向认证服务器进行身份认证，并要求一个访问令牌。\n（B）认证服务器确认无误后，向客户端提供访问令牌。\n A步骤中，客户端发出的HTTP请求，包含以下参数：\n granttype：表示授权类型，此处的值固定为\u0026quot;clientcredentials\u0026rdquo;，必选项。 scope：表示权限范围，可选项。   POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=client_credentials  认证服务器必须以某种方式，验证客户端身份。\nB步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。\n HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; }  上面代码中，各个参数的含义参见《授权码模式》一节。\n 更新Token #  如果用户访问的时候，客户端的\u0026quot;访问令牌\u0026quot;已经过期，则需要使用\u0026quot;更新令牌\u0026quot;申请一个新的访问令牌。\n客户端发出更新令牌的HTTP请求，包含以下参数：\n granttype：表示使用的授权模式，此处的值固定为\u0026quot;refreshtoken\u0026rdquo;，必选项。 refresh_token：表示早前收到的更新令牌，必选项。 scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。  下面是一个例子。\n POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=refresh_token\u0026amp;refresh_token=tGzv3JOkF0XG5Qx2TlKWIA  "});index.add({'id':12,'href':'/notes/docs/technology/cloud/container/kubernetes/object/workload/pod/','title':"Pod",'section':"作业管理",'content':"Pod #  What #  Pod 是 Kubernetes 应用程序的基本执行单元，即它是 Kubernetes 对象模型中创建或部署的最小和最简单的单元。Pod 表示在 集群 上运行的进程。\nPod 封装了应用程序容器（或者在某些情况下封装多个容器）、存储资源、唯一网络 IP 以及控制容器应该如何运行的选项。 Pod 表示部署单元：Kubernetes 中应用程序的单个实例，它可能由单个 容器 或少量紧密耦合并共享资源的容器组成。\n Docker 是 Kubernetes Pod 中最常用的容器运行时，但 Pod 也能支持其他的 容器运行时。\nKubernetes 集群中的 Pod 可被用于以下两个主要用途：\n  运行单个容器的 Pod。\u0026ldquo;每个 Pod 一个容器\u0026quot;模型是最常见的 Kubernetes 用例；在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。\n  运行多个协同工作的容器的 Pod。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众，而另一个单独的“挂斗”（sidecar）容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。 Kubernetes 博客 上有一些其他的 Pod 用例信息。更多信息请参考：\n   分布式系统工具包：容器组合的模式\n   容器设计模式\n  每个 Pod 表示运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例），则应该使用多个 Pod，每个应用实例使用一个 Pod 。在 Kubernetes 中，这通常被称为 副本。通常使用一个称为控制器的抽象来创建和管理一组副本 Pod。更多信息请参见 Pod 和控制器。\n How #  Pod 被设计成支持形成内聚服务单元的多个协作过程（作为容器）。 Pod 中的容器被自动的安排到集群中的同一物理或虚拟机上，并可以一起进行调度。 容器可以共享资源和依赖、彼此通信、协调何时以及何种方式终止它们。\n注意，在单个 Pod 中将多个并置和共同管理的容器分组是一个相对高级的使用方式。 只在容器紧密耦合的特定实例中使用此模式。 例如，您可能有一个充当共享卷中文件的 Web 服务器的容器，以及一个单独的 sidecar 容器，该容器从远端更新这些文件，如下图所示：\n 有些 Pod 具有 初始容器 和 应用容器。初始容器会在启动应用容器之前运行并完成。\nPod 为其组成容器提供了两种共享资源：网络 和 存储。\n网络 #  每个 Pod 分配一个唯一的 IP 地址。 Pod 中的每个容器共享网络命名空间，包括 IP 地址和网络端口。 Pod 内的容器 可以使用 localhost 互相通信。 当 Pod 中的容器与 Pod 之外 的实体通信时，它们必须协调如何使用共享的网络资源（例如端口）。\n存储 #  一个 Pod 可以指定一组共享存储 卷。 Pod 中的所有容器都可以访问共享卷，允许这些容器共享数据。 卷还允许 Pod 中的持久数据保留下来，以防其中的容器需要重新启动。 有关 Kubernetes 如何在 Pod 中实现共享存储的更多信息，请参考 卷。\n Why #  管理 #  Pod 是形成内聚服务单元的多个协作过程模式的模型。它们提供了一个比它们的应用组成集合更高级的抽象，从而简化了应用的部署和管理。Pod 可以用作部署、水平扩展和制作副本的最小单元。在 Pod 中，系统自动处理多个容器的在并置运行（协同调度）、生命期共享（例如，终止），协同复制、资源共享和依赖项管理。\n资源共享和通信 #  Pod 使它的组成容器间能够进行数据共享和通信。\nPod 中的应用都使用相同的网络命名空间（相同 IP 和 端口空间），而且能够互相“发现”并使用 localhost 进行通信。因此，在 Pod 中的应用必须协调它们的端口使用情况。每个 Pod 在扁平的共享网络空间中具有一个 IP 地址，该空间通过网络与其他物理计算机和 Pod 进行全面通信。\nPod 中的容器获取的系统主机名与为 Pod 配置的 name 相同。 网络 部分提供了更多有关此内容的信息。\nPod 除了定义了 Pod 中运行的应用程序容器之外，Pod 还指定了一组共享存储卷。该共享存储卷能使数据在容器重新启动后继续保留，并能在 Pod 内的应用程序之间共享。\n "});index.add({'id':13,'href':'/notes/docs/technology/other/interview/introduction/','title':"Prepare",'section':"面试相关",'content':"Prepare #  介绍 #  目前就职于cf的运维开发岗位，主要工作内容是开发运维自动化相关工具和平台，对公司技术部门提供系统、网络、nginx、云服务相关的技术支持。 入职以来主要做了以下几件事，1、制定运维基础元数据规范，2、开发资源自动化系统，对接不同的云平台，实现资源申请到发布一键化操作。3、搭建和二次开发监控系统，实现基础资源的统一监控、展示和告警。 4、利用ngx_lua实现限源功能，防攻击脚本，对接应用平台，实现项目环境的快速搭建。5、搭建k8s平台，落地k8s监控和日志系统。  可能碰到的问题 #  项目 #  # cmdb怎么做 以应用为维度，分为三部分，第一部分是应用自己的信息，包括代码地址，代码类型、应用端口等信息，第二部分是应用归属，包括owner和部门，第三部分为资源信息，包括资源类型、环境、以及连接信息    应用 语言 git地址              应用 owner 部门              应用 环境 资源类型 资源               资源 资源类型 资源信息           # 项目亮点和难点 目前接入哪些服务,ecs,rds,redis,slb, 1、interface接口规范，接入一个云平台只需要实现对应的方式就行 2、中间逻辑失败怎么处理 分两种情况，一种属于资源未创建成功，提供3次重试，都失败返回错误 一种是资源创建成功，推送各个平台失败 对于无特殊信息(密码之类的)，记录信息，提供推送接口，手动确认报错后，重试，完成后删除信息 有特殊信息，临时文件记录，提供推送接口，手动确认报错后，调用接口推送后，删除特殊信息，密码做记录 # 监控系统 # 数据采集 ecs、rds、redis、lb、cdn # 阈值平台，rule-engine单独出来，定时到gateway拉取告警配置，然后拉取Prometheus接口做计算，告警推送到gateway，对用户不支持自定义指标 # 告警收敛 # ngx_lua # 限源怎么做，利用ngx_shared dict，最小计算单元，10秒，至少两个周期，ip_time(最小计算单元)， ip_time + n个周期的总数，超过就deny，进来的流量先判断是否deny，deny配置过期时间 # 路由怎么做，配置泛域名，解析域名跟url，请求应用平台，取得proxy_pass返回值 # 系统优化 tcp优化 # nginx优化 传输优化, sendfile, tcp_nopush, tcp_nodelay 压缩优化, gzip, level 2, text type buffer优化, buffer_size, header_buffer_size, proxy, temp_file timeout优化, keepalive_timeout, send_timeout,read_timeout 技术问题 #  # TCP三次握手和四次挥手 ### 三次握手 1、server端创建socket，监听某个端口，server端进入listen状态 2、client端创建socket，根据local_port_range随机选择一个未使用的端口，并生成ISN随机序列号，SYN标志位1，往server发送syn包，进入syn-sent状态 3、server端接收到数据包，若该数据包未超过sync_backlog半连接的队列大小，处理数据表，生成自己的ISN，将ack number配置为对方ISN+1，将syn和ack标志位1，发送给client，进入syn-received状态 4、client接收到syn包，回复一个ack number为ISN+1，ack标志位为1的数据包，进入Establish状态 5、server接收到ack包，进入accept队列(somaxconn)，复制一个socket来处理该连接，进入establish状态 ### 四次挥手 1、client发送一个FIN和ACK标志都为1的数据包，进入FIN_WAIT_1状态 2、server接收到该数据包，立即返回一个ACK包，进入CLOSE_WAIT状态，等待程序处理完，关闭连接 3、client接收到ACK包后，进入FIN_WAIT_2的状态，等待对方的FIN数据包 4、server处理完后，发送FIN包给client，进入LAST_ACK状态，等待对方的ACK包 5、client接收到FIN后，发送ACK，进入TIME_WAIT状态，等待超时进入CLOSED 6、server接收到ACK包，关闭socket 7、特殊情况，client和server同时发送FIN，即两个都进入CLOSING状态。即发送FIN后，未收到ACK，确收到对方的FIN包的时候。 # HTTP结构 请求行，method，url，version 请求头，host, content-type,length, cache-control, cors配置，cookie, authrozation 请求体， 响应行， 响应头， 响应体 # HTTP缺点 # HTTP2优势 # DNS解析过程 1、查找本地缓存，/etc/hosts 2、查找本地DNS服务器，/etc/resolv.conf(递归) 3、查找根服务，.， 4、查找一级域名DNS服务器，.com. 5、查找二级域名DNS服务器，.xxx.com. ... # 负载均衡 # LVS+Keepalived原理 # LVS NAT 1、prerouting接收数据包，进入input前，ipvs更改目标地址和端口，forward进入postrouting出去 2、realserver配置的网关为director的ip，将数据包发送给director，director SNAT发送给client # LVS DR 1、prerouting接收数据包，进入input前，ipvs更改目标mac地址，讲数据包转发给realserver 2、realserver将数据包直接返回给client，(arp抑制)，主要是不发送自己的arp信息，以及发包的时候，忽略源ip信息，直接通过发出去的接口的mac地址 3、director状态机，通过标志位判断，syn，进入syn-received,ack，establish， fin+ack， 接入LAST-ACK状态 # keepalived 如何做健康检查，arrp通信 当director和realserver同一台时，需mark mac地址 # Nginx原理 master和worker几点，worker处理真实请求 epoll，异步非阻塞 # 健康检查(被动检查和主动) 被动，3次失败，10秒不可用 # upstream 轮询，权重轮询，最小连接， ip_hash # 怎么查找host ip:port+ server_name是唯一标识 server_name 存储结构 完全匹配，前通配符匹配，后通配符匹配 regex 正则匹配的server default_server # 怎么查找location 1、完全匹配 2、前缀匹配选最长，判断最长匹配前缀是否带^~非正则匹配 3、正则匹配 4、最长前缀匹配 # Golang 并发 进程：分配资源的基本单位，独立的栈空间，独立的堆空间，进程之间调度由os完成 线程：独立运行和独立调度的基本单位，独立的栈空间，共享堆空间，内核线程之间调度由os完成 协程：用户级线程，独立的栈空间，共享堆空间，调度由用户自己控制，协作式调度，主动转让控制权 goroutine：Golang自己实现的协程，不完全协作式调度，由go自己实现的调度器调度。 内存消耗方面 每个 goroutine (协程) 默认占用内存远比 Java 、C 的线程少。 goroutine：2KB 线程：1MB 线程和 goroutine 切换调度开销方面 线程/goroutine 切换开销方面，goroutine 远比线程小 线程：涉及模式切换(从用户态切换到内核态)、16个寄存器、PC、SP...等寄存器的刷新等。 goroutine：只有三个寄存器的值修改 - PC / SP / DX. channel 不通过共享内存来通信，而是通过通信来共享内存 # Golang 垃圾回收 三色标记法+混合写屏障 根对象 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。 1、标记准备，开启写屏障 2、查找根对象，标记为灰色 3、查找灰色对象，将灰色对象标记为黑色，将黑色对象的子节点标记为灰色 4、重复3，直到只剩黑色对象和白色对象 5、标记过程中更改，删除指针时，将自己标记为灰色，新增指针时，将对方标记为灰色 # k8s # pod 与 pod 通信 云平台插件， 1、新增eni(弹性网卡)，每张网卡可以绑定n个辅助ip，给pod使用，增加一张eni的路由表，到网关的走这张网卡出去 2、创建pod，新增veth pair，一端挂载到pod的namesapce，一端挂载到node的namespace 3、新增2条策略路由，所有到pod ip的数据都走默认路由表，所有从pod ip出来的数据都走eni网卡的路由表 4、新增一条路由，所有到pod ip的数据都走veth网卡 5、之后就是VPC处理出来的数据了 flannl 1、新增一条到xxxx/24的路由到flnanel.0的网卡 2、flannel处理，pod增加自己的mac头部和下一跳(flannel.0)的mac地址到数据包，增加vxlan头部，增加udp头部，查找bgf，增加ip头部，正常的网络流量处理 3、解包到pod ip，处理数据 # service通信 iptables prerouting，output链， kube-service链，kube-svc（kube-node）,kube-sep,dnat操作,nf_track ipvs prerouting，ipvs dnat，postrouting， # storageclass 其他 #  #为什么选sdet 1. 测试和运维技术相通，环境不同，但是目的是一致。 2. devops最终的结局可能会只剩下业务开发和平台开发，做开发是技术职业方向 3. 这几年做的都是内部平台内的工作，基本是维护所有环境 "});index.add({'id':14,'href':'/notes/docs/technology/database/nosql/redis/','title':"Redis",'section':"NoSQL",'content':"Redis #    基础\n   集群搭建\n  "});index.add({'id':15,'href':'/notes/docs/technology/database/nosql/redis/cluster/','title':"Redis集群",'section':"Redis",'content':"集群 #  集群搭建 #    Redis安装\nwget http://download.redis.io/releases/redis-4.0.1.tar.gz    基础配置\n#除端口外，配置统一 #common port 6379 pidfile /cache1/redis/6379/redis_6379.pid loglevel notice logfile \u0026quot;/cache1/redis/6379/redis_6379.log\u0026quot; dir /cache1/redis/6379 protected-mode no #rdb save 7200 1000 rdbcompression yes rdbchecksum yes dbfilename dump.rdb #aof appendonly yes appendfilename \u0026quot;appendonly.aof\u0026quot; #cluster cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000    redis集群架构\n192.168.88.1:6379(master) 192.168.88.2:6379(slave) 192.168.88.2:6378(master) 192.168.88.3:6378(slave) 192.168.88.3:6377(master) 192.168.88.1:6377(slave)    启动redis\ncd $PATH redis-server redis-6379.conf \u0026amp;    集群管理器安装\n#安装ruby tar -zxf ruby-2.4.1.tar.gz cd ruby-2.4.1 ./configure make \u0026amp;\u0026amp; make install #安装gem tar -zxf rubygems-2.6.12.tgz cd rubygems-2.6.12/ ruby setup.rb --no-rdoc --no-ri #安装redisgem gem install redis    集群建立\ncd /usr/local/src/redis-4.0.1/ src/redis-trib.rb create --replicas 1 192.168.88.1:6379 192.168..88.2:6378 192.168.88.3:6377 192.168.88.2:6379 192.168.88.3:6378 192.168.88.1:6377    简单测试\nredis-cli -c -h 192.168.88.1 -p 6379 cluster nodes    集群分片\nsrc/redis-trib.rb reshard 192.168.88.1:6379    添加节点\nsrc/redis-trib.rb add-node 192.168.88.1:6376 172.16.88.1:6379 src/redis-trib.rb add-node --slave --master-id xxxx 192.168.88.1:6376 192.168.88.1:6379    从节点更改\nredis-cli -c -p 6377 cluster replicate \u0026lt;master-node-id\u0026gt;     集群优化 #    配置文件优化\n  集群配置密码\n#redis.conf配置文件 requirepass 123456 masterauth 123456 #集群管理客户端 #/usr/local/lib/ruby/gems/2.4.1/gems/redis-3.3.3/lib/redis/client.rb password =\u0026gt; \u0026quot;123456\u0026quot;    "});index.add({'id':16,'href':'/notes/docs/technology/tool/script/','title':"Scripts",'section':"工具",'content':"Scripts #  shell 脚本 #    tomcat系列\n   tomcat服务启动\n   tomcat版本更新\n   tomcat日志分割\n   tomcat应用发布\n   tomcat应用还原\n    zabbix系列\n   server安装\n   agent安装\n     python 脚本 #     PG日志格式更改\n   tcp端口测试\n   ssh登录测试\n   生成随机日志\n  "});index.add({'id':17,'href':'/notes/docs/technology/cloud/container/kubernetes/network/service/','title':"Service通信",'section':"Kubernetes 网络",'content':"Service通信 #  在Kubernetes中，service是一种抽象，定义了Pod的逻辑集和访问它们的策略（有时将此模式称为微服务）。service所针对的Pod集合通常由selector确定。https://kubernetes.io/docs/concepts/services-networking/service/\n Service服务发现 #  如果您可以使用Kubernetes API在应用程序中发现service，则可以查询API服务器以获取endpoint，只要service中的Pod集合发生更改，endpoint就会更新。\n对于非本机应用程序，Kubernetes提供了在应用程序和后端Pod之间放置网络端口或负载平衡器的方法。\n Service资源定义 #  apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376  实现 #  Kubernetes集群中的每个节点都运行一个kube-proxy。 kube-proxy负责为service实现一种VIP(cluster ip)\n目前官方的proxy模式有三种\nuserspace #   此模式下，由kube-proxy随机选取port进行监听，并创建iptables规则，将所有到达cluster ip的数据转发到kube-proxy监听的端口上，由kube-proxy通过SessionAffinity配置来确定发送给哪个pod\n iptables #   此模式下，kube-proxy针对每个service创建iptables规则，所有流量都通过iptables规则和路由表处理流量转发\n# 以aws为例,cluster ip为10.100.254.226，endpoint为172.31.178.122:80,172.31.178.161:80,172.31.179.80:80,nodeport为30028 # pod or node --\u0026gt; cluster ip --\u0026gt; endpoint *nat -A PREROUTING -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES #pod所有流量先进入KUBE-SERVICES检查 -A OUTPUT -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES #node流量通过OUTPUT进入KUBE-SERVICES -A KUBE-SERVICES -d 10.100.254.226/32 -p tcp -m comment --comment \u0026#34;ops-test/nginx-service: cluster IP\u0026#34; -m tcp --dport 80 -j KUBE-SVC-473SUSYUDXM6XRRH #匹配目的ip为10.100.254.226 #随机选择后端 -A KUBE-SVC-473SUSYUDXM6XRRH -m statistic --mode random --probability 0.33333333349 -j KUBE-SEP-WWIE6AZWAXCTMCNN -A KUBE-SVC-473SUSYUDXM6XRRH -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-ZBMAWDEBUXPXQHDH -A KUBE-SVC-473SUSYUDXM6XRRH -j KUBE-SEP-VPHXZB6KBMWRSLML #将目标地址转换为172.31.178.243:9300 -A KUBE-SEP-VPHXZB6KBMWRSLML -s 172.31.179.80/32 -j KUBE-MARK-MASQ -A KUBE-SEP-VPHXZB6KBMWRSLML -p tcp -m tcp -j DNAT --to-destination 172.31.179.80:80 通过路由规则找对应的pod(pod到pod间通信) # endpoint --\u0026gt; cluster ip --\u0026gt; pod or node 回来的包经过conntrack模块直接做SNAT操作 # externel --\u0026gt; nodeport --\u0026gt; endpoint *nat -A PREROUTING -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES #外部所有流量先进入KUBE-SERVICES检查 -A KUBE-SERVICES -m comment --comment \u0026#34;kubernetes service nodeports; NOTE: this must be the last rule in this chain\u0026#34; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS #KUBE-SERVICES最后一条进入KUBE-NODEPORTS -A KUBE-NODEPORTS -p tcp -m comment --comment \u0026#34;ops-test/nginx-service:\u0026#34; -m tcp --dport 30028 -j KUBE-MARK-MASQ #打标 -A KUBE-NODEPORTS -p tcp -m comment --comment \u0026#34;ops-test/nginx-service:\u0026#34; -m tcp --dport 30028 -j KUBE-SVC-473SUSYUDXM6XRRH #后续的DNAT跟cluster ip类似 # endpoint --\u0026gt; nodeport 回来的包经过conntrack模块直接做SNAT操作，转换成nodeport # nodeport --\u0026gt; externel -A KUBE-POSTROUTING -m comment --comment \u0026#34;kubernetes service traffic requiring SNAT\u0026#34; -m mark --mark 0x4000/0x4000 -j MASQUERADE --random-fully #跟外部交互需要做SNAT  ipvs #   在 ipvs 模式下，kube-proxy监视Kubernetes服务和端点，调用 netlink 接口相应地创建 IPVS 规则， 并定期将 IPVS 规则与 Kubernetes 服务和端点同步。 该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS 将流量定向到后端Pod之一。\nIPVS代理模式基于类似于 iptables 模式的 netfilter 挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables 模式下的 kube-proxy 相比，IPVS 模式下的 kube-proxy 重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS 模式还支持更高的网络流量吞吐量。\nIPVS提供了更多选项来平衡后端Pod的流量。 这些是：\n rr: round-robin lc: least connection (smallest number of open connections) dh: destination hashing sh: source hashing sed: shortest expected delay nq: never queue  # pod or node --\u0026gt; cluster ip --\u0026gt; endpoint -A PREROUTING -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES -A OUTPUT -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES -A KUBE-SERVICES -m set --match-set KUBE-CLUSTER-IP dst,dst -j ACCEPT ipvs处理dnat，进入POSTROUTING链 # endpoint --\u0026gt; cluster ip --\u0026gt; pod or node 回来的包经过conntrack模块直接做SNAT操作 # externel --\u0026gt; nodeport --\u0026gt; endpoint *nat -A PREROUTING -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES -A KUBE-SERVICES -m addrtype --dst-type LOCAL -j KUBE-NODE-PORT -A KUBE-NODE-PORT -p tcp -m comment --comment \u0026#34;Kubernetes nodeport TCP port with externalTrafficPolicy=local\u0026#34; -m set --match-set KUBE-NODE-PORT-LOCAL-TCP dst -j RETURN -A KUBE-NODE-PORT -p tcp -m comment --comment \u0026#34;Kubernetes nodeport TCP port for masquerade purpose\u0026#34; -m set --match-set KUBE-NODE-PORT-TCP dst -j KUBE-MARK-MASQ ipvs处理dnat，进入POSTROUTING链 # endpoint --\u0026gt; nodeport 回来的包经过conntrack模块直接做SNAT操作，转换成nodeport -A POSTROUTING -m comment --comment \u0026#34;kubernetes postrouting rules\u0026#34; -j KUBE-POSTROUTING -A POSTROUTING -s 169.254.123.0/24 ! -o docker0 -j MASQUERADE -A KUBE-POSTROUTING -m comment --comment \u0026#34;kubernetes service traffic requiring SNAT\u0026#34; -m mark --mark 0x4000/0x4000 -j MASQUERADE -A KUBE-POSTROUTING -m comment --comment \u0026#34;Kubernetes endpoints dst ip:port, source ip for solving hairpin purpose\u0026#34; -m set --match-set KUBE-LOOP-BACK dst,dst,src -j MASQUERADE ipvs 会使用 iptables 进行包过滤、SNAT、masquared(伪装)。具体来说，ipvs 将使用ipset来存储需要DROP或masquared的流量的源或目标地址，以确保 iptables 规则的数量是恒定的，这样我们就不需要关心我们有多少服务了\n下表就是 ipvs 使用的 ipset 集合：\n   set name members usage     KUBE-CLUSTER-IP All service IP + port Mark-Masq for cases that masquerade-all=true or clusterCIDR specified   KUBE-LOOP-BACK All service IP + port + IP masquerade for solving hairpin purpose   KUBE-EXTERNAL-IP service external IP + port masquerade for packages to external IPs   KUBE-LOAD-BALANCER load balancer ingress IP + port masquerade for packages to load balancer type service   KUBE-LOAD-BALANCER-LOCAL LB ingress IP + port with externalTrafficPolicy=local accept packages to load balancer with externalTrafficPolicy=local   KUBE-LOAD-BALANCER-FW load balancer ingress IP + port with loadBalancerSourceRanges package filter for load balancer with loadBalancerSourceRanges specified   KUBE-LOAD-BALANCER-SOURCE-CIDR load balancer ingress IP + port + source CIDR package filter for load balancer with loadBalancerSourceRanges specified   KUBE-NODE-PORT-TCP nodeport type service TCP port masquerade for packets to nodePort(TCP)   KUBE-NODE-PORT-LOCAL-TCP nodeport type service TCP port with externalTrafficPolicy=local accept packages to nodeport service with externalTrafficPolicy=local   KUBE-NODE-PORT-UDP nodeport type service UDP port masquerade for packets to nodePort(UDP)   KUBE-NODE-PORT-LOCAL-UDP nodeport type service UDP port with externalTrafficPolicy=local accept packages to nodeport service with externalTrafficPolicy=local     ipvs-ebpf #   服务类型 #  对一些应用（如前端）的某些部分，可能希望通过外部 Kubernetes 集群外部 IP 地址暴露 Service。\nKubernetes ServiceTypes 允许指定一个需要的类型的 Service，默认是 ClusterIP 类型。\nType 的取值以及行为如下：\n  ClusterIP：通过集群的内部 IP 暴露服务，选择该值，服务只能够在集群内部可以访问，这也是默认的 ServiceType。\n   NodePort：通过每个 Node 上的 IP 和静态端口（NodePort）暴露服务。 NodePort 服务会路由到 ClusterIP 服务，这个 ClusterIP 服务会自动创建。 通过请求 \u0026lt;NodeIP\u0026gt;:\u0026lt;NodePort\u0026gt;，可以从集群的外部访问一个 NodePort 服务。\n   LoadBalancer：使用云提供商的负载局衡器，可以向外部暴露服务。 外部的负载均衡器可以路由到 NodePort 服务和 ClusterIP 服务。\n   ExternalName：通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容（例如， foo.bar.example.com）。 没有任何类型代理被创建。\n 说明： 您需要 CoreDNS 1.7 或更高版本才能使用 ExternalName 类型。\n   您也可以使用 Ingress 来暴露自己的服务。 Ingress 不是服务类型，但它充当集群的入口点。 它可以将路由规则整合到一个资源中，因为它可以在同一IP地址下公开多个服务。\n"});index.add({'id':18,'href':'/notes/docs/technology/program/language/shell/','title':"Shell",'section':"编程语言",'content':"Shell #  基础语法 #    变量\n  函数\n   进阶 #    代码风格  "});index.add({'id':19,'href':'/notes/docs/technology/security/ids/snort/','title':"Snort",'section':"入侵检测",'content':"Snort #  #  "});index.add({'id':20,'href':'/notes/docs/technology/system/application/ssh/','title':"SSH",'section':"应用",'content':"SSH #  概念 #  安全Shell（SSH）是一种加密网络协议，用于通过无安全网络安全地运行网络服务。\nSSH协议 #    认证\n  加密\n  完整性\n  SSH属性 #    安全远程登录(Secure Remote Login )\n  安全文件传输(Secure File Transfer)\n  安全远程命令执行(Secure Remote Command Execution)\n  密钥和代理(Keys and Agents)\n  访问控制(Access Control)\n  端口转发(Port Forwarding)\n  架构 #    基础操作 #    远程登录\nssh -l USERNAME HOST -p PORT\n  文件传输\nscp SOURCE DESTINATION\n  已知主机(known hosts)\nknown hosts可以用来防止中间人攻击。 每个SSH服务器都有一个秘密的唯一ID，称为主机密钥(host key)，用于向客户端标识自身。当首次连接的时，ssh会记录目标设备的host key到~/.ssh/known_hosts文件，当主机密钥发生改变时，在连接时将会有提示告警。\n  转义字符(The Escape Character)\n转义字符可以用于暂时中断连接，默认符号为\u0026quot;~\u0026rdquo; 也可以自行进行更改，使用-e选项，ssh -e \u0026ldquo;#\u0026rdquo; HOST\n  加密密钥认证(Authentication by Cryptographic Key) #  密码认证方式的缺陷：\n 安全的密码复杂性高，难于记忆。 通过网络传输密码还是会有被捕获的风险。  SSH支持公钥认证的方式，可以解决上述的密码问题。\n 密钥简介  key是一个数字身份，是一个独特的二进制字符串。\nSSH身份使用一对密钥，一个私有密钥和一个公有密钥。私钥由自身保管，公钥保存在需要访问的ssh服务器上。(~/.ssh/authorized_keys)文件。\nclient请求登录server server要求身份认证 client发送自身私钥证明自己身份 server使用公钥对私钥进行匹配，成功则允许登录。   ssh-keygen生成密钥对\n(ssh-keygen -t dsa|rsa) | (ssh-keygen) 会在~/.ssh/目录生成id_rsa和id_rsa.pub两个文件\n  在ssh服务器上安装公钥\n 直接编辑~/.ssh/authorized_keys(权限644),拷贝id_rsa.pub的内容到该文件 使用ssh-copy-id ssh-copy-id -i id_rsa.pub [user@]server_name     SSH深入 #    加密\n  完整性\n  认证\n  授权\n  转发\n  密码学入门 #  "});index.add({'id':21,'href':'/notes/docs/technology/network/protocol/tcp/','title':"TCP",'section':"网络协议",'content':"TCP #    "});index.add({'id':22,'href':'/notes/docs/technology/cloud/infrastructure/','title':"不可变基础设施",'section':"云原生",'content':"不可变基础设施 #  What #  定义 #   不可变基础设施(Immutable.Infrastructure)是由 Chad Fowler 于2013年提出的一个很有前瞻性的构想：在这种模式中，任何基础设施的实例（包括服务器、容 器等各种软硬件）一旦创建之后便成为一种只读状态，不可对其进行任何更改。如果 需要修改或升级某些实例，唯一的方式就是创建一批新的实例以替换。\n  优势 #   基础架构是一致且可靠的，这使测试更加简单 部署更简单，更可预测 每个部署都是版本化和自动化的，因此轻松进行环境回滚 错误，配置偏差和雪花服务器已完全缓解或消除 在所有环境中部署均保持一致 借助云服务，轻松实现自动扩展     阿里云原生课堂 #     "});index.add({'id':23,'href':'/notes/docs/other/life/','title':"人生",'section':"非技术相关",'content':"人生 #  "});index.add({'id':24,'href':'/notes/docs/technology/cloud/container/kubernetes/object/workload/','title':"作业管理",'section':"Kubernetes 对象",'content':"作业管理 #  "});index.add({'id':25,'href':'/notes/docs/technology/system/linux/kernel/opt/','title':"内核参数优化",'section':"内核",'content':"参数优化 #  vm.swappiness = 0 net.ipv4.neigh.default.gc_stale_time=120 # see details in https://help.aliyun.com/knowledge_detail/39428.html net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.rp_filter=0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce=2 net.ipv4.conf.all.arp_announce=2 # see details in https://help.aliyun.com/knowledge_detail/41334.html net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_synack_retries = 2 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.core.rmem_default = 256960 net.core.rmem_max = 513920 net.core.wmem_default = 256960 net.core.wmem_max = 513920 net.core.netdev_max_backlog = 2000 net.core.somaxconn = 2048 net.core.optmem_max = 81920 net.ipv4.tcp_mem = 131072 262144 524288 net.ipv4.tcp_rmem = 8760 256960 4088000 net.ipv4.tcp_wmem = 8760 256960 4088000 net.ipv4.tcp_keepalive_time = 1800 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 3 net.ipv4.tcp_sack =1 net.ipv4.tcp_fack =1 net.ipv4.tcp_timestamps =1 net.ipv4.tcp_window_scaling =1 #net.ipv4.tcp_syncookies =1 net.ipv4.tcp_tw_reuse =1 net.ipv4.tcp_tw_recycle =0 net.ipv4.tcp_fin_timeout = 30 net.ipv4.ip_local_port_range = 1024 65000 net.ipv4.tcp_max_syn_backlog = 2048 kernel.sysrq=1 "});index.add({'id':26,'href':'/notes/docs/technology/system/linux/base/start/','title':"启动过程",'section':"基础",'content':"启动过程 #  整个过程基本可以分为POST–\u0026gt;BIOS–\u0026gt;MBR(GRUB)–\u0026gt;Kernel–\u0026gt;Init–\u0026gt;Runlevel。\n  详解 #    BIOS\nBIOS(Basic Input/Output System)，基本输入输出系统，该系统存储于主板的ROM芯片上。开机时，会最先读取该系统，然后会有一个加电自检过程，若没有异常就开始加载BIOS程序到内存当中。BIOS主要的一个功能就是存储了磁盘的启动顺序，BIOS会按照启动顺序去查找第一个磁盘头的MBR信息，并加载和执行MBR中的Bootloader程序，若第一个磁盘不存在MBR，则会继续查找第二个磁盘，一旦BootLoader程序被检测并加载内存中，BIOS就将控制权交接给了BootLoader程序。\n  MBR\nMBR(Master Boot Record)，主引导记录，MBR存储于磁盘的头部，大小为512bytes，其中，446bytes用于存储BootLoader程序，64bytes用于存储分区表信息，最后2bytes用于MBR的有效性检查。\n  GRUB\nGRUB(Grand Unified Bootloader)，多系统启动程序，其执行过程可分为三个步骤：\n  Stage1\n这个其实就是MBR，它的主要工作就是查找并加载第二段Bootloader程序(stage2)，但系统在没启动时，MBR根本找不到文件系统，也就找不到stage2所存放的位置，因此，就有了stage1_5\n  Stage1_5\n该步骤就是为了识别文件系统\n  Stage2\nGRUB程序会根据/boot/grub/grub.conf文件查找Kernel的信息，然后开始加载Kernel程序，当Kernel程序被检测并在加载到内存中，GRUB就将控制权交接给了Kernel程序。\nPS：实际上这个步骤/boot还没被挂载，GRUB直接识别grub所在磁盘的文件系统，所以实际上应该是/grub/grub.conf文件，该配置文件的信息如下：\ngrub.conf:\n #boot=/dev/sda default=0 #设定默认启动的title的编号，从0开始 timeout=5 #等待用户选择的超时时间 splashimage=(hd0,0)/boot/grub/splash.xpm.gz #GRUB的背景图片 hiddenmenu #隐藏菜单 title CentOS (2.6.18-194.el5PAE) #内核标题 root (hd0,0) #内核文件所在的设备 kernel /vmlinuz-2.6.18-194.el5PAE ro root=LABEL=/ #内核文件路径以及传递给内核的参数 initrd /initrd-2.6.18-194.el5PAE.img #ramdisk文件路径      Kernel\nKernel，内核，Kernel是Linux系统最主要的程序，实际上，Kernel的文件很小，只保留了最基本的模块，并以压缩的文件形式存储在硬盘中，当GRUB将Kernel读进内存，内存开始解压缩内核文件。讲内核启动，应该先讲下initrd这个文件，\ninitrd(Initial RAM Disk)，它在stage2这个步骤就被拷贝到了内存中，这个文件是在安装系统时产生的，是一个临时的根文件系统(rootfs)。因为Kernel为了精简，只保留了最基本的模块，因此，Kernel上并没有各种硬件的驱动程序，也就无法识rootfs所在的设备，故产生了initrd这个文件，该文件装载了必要的驱动模块，当Kernel启动时，可以从initrd文件中装载驱动模块，直到挂载真正的rootfs，然后将initrd从内存中移除。\nKernel会以只读方式挂载根文件系统，当根文件系统被挂载后，开始装载第一个进程(用户空间的进程)，执行/sbin/init，之后就将控制权交接给了init程序。\n  Init\ninit，初始化，顾名思义，该程序就是进行OS初始化操作，实际上是根据/etc/inittab(定义了系统默认运行级别)设定的动作进行脚本的执行，第一个被执行的脚本为/etc/rc.d/rc.sysinit，这个是真正的OS初始化脚本，其任务如下：\n  激活udev和selinux;\n  根据/etc/sysctl.conf文件，来设定内核参数;\n  设定系统时钟;\n  装载硬盘映射;\n  启用交换分区;\n  设置主机名;\n  根文件系统检测，并以读写方式重新挂载根文件系统;\n  激活RAID和LVM设备;\n  启用磁盘配额;\n  根据/etc/fstab，检查并挂载其他文件系统;\n  清理过期的锁和PID文件\n  执行完后，根据配置的启动级别，执行对应目录底下的脚本，最后执行/etc/rc.d/rc.local这个脚本，至此，系统启动完成。   Runlevel\nrunlevel，运行级别，不同的级别会启动的服务不一样，init会根据定义的级别去执行相应目录下的脚本，Linux的启动级别分为以下几种：\n0：关机模式\n1：单一用户模式(直接以管理员身份进入)\n2：多用户模式（无网络）\n3：多用户模式（命令行）\n4：保留\n5：多用户模式（图形界面）\n6：重启\n在不同的运行级别下，/etc/rc.d/rc这个脚本会分别执行不同目录下的脚本：\nRunlevel 0 – /etc/rc.d/rc0.d/\nRunlevel 1 – /etc/rc.d/rc1.d/\nRunlevel 2 – /etc/rc.d/rc2.d/\nRunlevel 3 – /etc/rc.d/rc3.d/\nRunlevel 4 – /etc/rc.d/rc4.d/\nRunlevel 5 – /etc/rc.d/rc5.d/\nRunlevel 6 – /etc/rc.d/rc6.d/\n这些目录下的脚本只有K和S开头的文件，K开头的文件为开机需要执行关闭的服务，S开头的文件为开机需要执行开启的服务。\n  "});index.add({'id':27,'href':'/notes/docs/technology/system/linux/base/','title':"基础",'section':"Linux系统",'content':"基础 #  "});index.add({'id':28,'href':'/notes/docs/technology/bigdata/basic/','title':"大数据基础",'section':"大数据",'content':"大数据基础 #  分布式系统 #  分布式系统是独立计算机的集合，作为单个计算机对系统用户显示。 分布式系统是一种模型，其中位于联网计算机上的组件通过传递消息来通信和协调他们的动作，组件彼此交互以实现共同目标。\n 分布式计算 #  优势 #  劣势 #   分布式系统设计 #  协调服务 #    Name service\n  Locking\n  Synchronization\n  Configuration management\n  Leader election\n   "});index.add({'id':29,'href':'/notes/docs/other/life/reason/','title':"存在的意义",'section':"人生",'content':"存在的意义 #   "});index.add({'id':30,'href':'/notes/docs/technology/leetcode/learn/','title':"学习",'section':"LeetCode",'content':"学习 #    数组  链表  二叉树   对比 #     如果需要经常插入和删除元素，选择链表\n如果需要经常通过index访问元素，选择数组\n  "});index.add({'id':31,'href':'/notes/docs/other/learn/Method/','title':"学习方法",'section':"方法论",'content':"学习方法 #   "});index.add({'id':32,'href':'/notes/docs/technology/security/basic/','title':"安全基础",'section':"安全",'content':"安全基础 #  密码学 #  密码学处理数字和字符串。\n哈希 #  哈希散列是一项密码学技术，它将数据转换成其他形式，并且不可恢复。\n加解密 #  加解密是一个双向过程，当且仅当加密密钥被知道时才能检索原始数据。\n对称加密 #  对称加密使用同一个密钥\n非对称加密 #  非对称加密使用公私钥，私钥自己持有，公钥给所有想加密信息发送给你的人。使用公钥加密，使用私钥解密。\n"});index.add({'id':33,'href':'/notes/docs/other/read/%E5%AE%9E%E8%B7%B5%E8%AE%BA/','title':"实践论",'section':"阅读",'content':"实践论 #  论认识和实践的关系——知和行的关系 #  （一九三七年七月）\n 在中国共产党内，曾经有一部分教条主义的同志长期拒绝中国革命的经验，否认“马克思主义不是教条而是行动的指南”这个真理，而只生吞活剥马克思主义书籍中的只言片语，去吓唬人们。还有另一部分经验主义的同志长期拘守于自身的片断经验，不了解理论对于革命实践的重要性，看不见革命的全局，虽然也是辛苦地——但却是盲目地在工作。这两类同志的错误思想，特别是教条主义思想，曾经在一九三一年至一九三四年使得中国革命受了极大的损失，而教条主义者却是披着马克思主义的外衣迷惑了广大的同志。毛泽东的《实践论》，是为着用马克思主义的认识论观点去揭露党内的教条主义和经验主义——特别是教条主义这些主观主义的错误而写的。因为重点是揭露看轻实践的教条主义这种主观主义，故题为《实践论》。毛泽东曾以这篇论文的观点在延安的抗日军事政治大学作过讲演。\n 　马克思以前的唯物论，离开人的社会性，离开人的历史发展，去观察认识问题，因此不能了解认识对社会实践的依赖关系，即认识对生产和阶级斗争的依赖关系。\n首先，马克思主义者认为人类的生产活动是最基本的实践活动，是决定其他一切活动的东西。人的认识，主要地依赖于物质的生产活动，逐渐地了解自然的现象、自然的性质、自然的规律性、人和自然的关系；而且经过生产活动，也在各种不同程度上逐渐地认识了人和人的一定的相互关系。一切这些知识，离开生产活动是不能得到的。在没有阶级的社会中，每个人以社会一员的资格，同其他社会成员协力，结成一定的生产关系，从事生产活动，以解决人类物质生活问题。在各种阶级的社会中，各阶级的社会成员，则又以各种不同的方式，结成一定的生产关系，从事生产活动，以解决人类物质生活问题。这是人的认识发展的基本来源。\n人的社会实践，不限于生产活动一种形式，还有多种其他的形式，阶级斗争，政治生活，科学和艺术的活动，总之社会实际生活的一切领域都是社会的人所参加的。因此，人的认识，在物质生活以外，还从政治生活文化生活中（与物质生活密切联系），在各种不同程度上，知道人和人的各种关系。其中，尤以各种形式的阶级斗争，给予人的认识发展以深刻的影响。在阶级社会中，每一个人都在一定的阶级地位中生活，各种思想无不打上阶级的烙印。\n马克思主义者认为人类社会的生产活动，是一步又一步地由低级向高级发展，因此，人们的认识，不论对于自然界方面，对于社会方面，也都是一步又一步地由低级向高级发展，即由浅入深，由片面到更多的方面。在很长的历史时期内，大家对于社会的历史只能限于片面的了解，这一方面是由于剥削阶级的偏见经常歪曲社会的历史，另方面，则由于生产规模的狭小，限制了人们的眼界。人们能够对于社会历史的发展作全面的历史的了解，把对于社会的认识变成了科学，这只是到了伴随巨大生产力——大工业而出现近代无产阶级的时候，这就是马克思主义的科学。\n马克思主义者认为，只有人们的社会实践，才是人们对于外界认识的真理性的标准。实际的情形是这样的，只有在社会实践过程中（物质生产过程中，阶级斗争过程中，科学实验过程中），人们达到了思想中所预想的结果时，人们的认识才被证实了。人们要想得到工作的胜利即得到预想的结果，一定要使自己的思想合于客观外界的规律性，如果不合，就会在实践中失败。人们经过失败之后，也就从失败取得教训，改正自己的思想使之适合于外界的规律性，人们就能变失败为胜利，所谓“失败者成功之母”，“吃一堑长一智”，就是这个道理。辩证唯物论的认识论把实践提到第一的地位，认为人的认识一点也不能离开实践，排斥一切否认实践重要性、使认识离开实践的错误理论。列宁这样说过：“实践高于（理论的）认识，因为它不但有普遍性的品格，而且还有直接现实性的品格。”⑴马克思主义的哲学辩证唯物论有两个最显著的特点：一个是它的阶级性，公然申明辩证唯物论是为无产阶级服务的；再一个是它的实践性，强调理论对于实践的依赖关系，理论的基础是实践，又转过来为实践服务。判定认识或理论之是否真理，不是依主观上觉得如何而定，而是依客观上社会实践的结果如何而定。真理的标准只能是社会的实践。实践的观点是辩证唯物论的认识论之第一的和基本的观点⑵。\n然而人的认识究竟怎样从实践发生，而又服务于实践呢？这只要看一看认识的发展过程就会明了的。\n原来人在实践过程中，开始只是看到过程中各个事物的现象方面，看到各个事物的片面，看到各个事物之间的外部联系。例如有些外面的人们到延安来考察，头一二天，他们看到了延安的地形、街道、屋宇，接触了许多的人，参加了宴会、晚会和群众大会，听到了各种说话，看到了各种文件，这些就是事物的现象，事物的各个片面以及这些事物的外部联系。这叫做认识的感性阶段，就是感觉和印象的阶段。也就是延安这些各别的事物作用于考察团先生们的感官，引起了他们的感觉，在他们的脑子中生起了许多的印象，以及这些印象间的大概的外部的联系，这是认识的第一个阶段。在这个阶段中，人们还不能造成深刻的概念，作出合乎论理（即合乎逻辑）的结论。\n社会实践的继续，使人们在实践中引起感觉和印象的东西反复了多次，于是在人们的脑子里生起了一个认识过程中的突变（即飞跃），产生了概念。概念这种东西已经不是事物的现象，不是事物的各个片面，不是它们的外部联系，而是抓着了事物的本质，事物的全体，事物的内部联系了。概念同感觉，不但是数量上的差别，而且有了性质上的差别。循此继进，使用判断和推理的方法，就可产生出合乎论理的结论来。《三国演义》上所谓“眉头一皱计上心来”，我们普通说话所谓“让我想一想”，就是人在脑子中运用概念以作判断和推理的工夫。这是认识的第二个阶段。外来的考察团先生们在他们集合了各种材料，加上他们“想了一想”之后，他们就能够作出“共产党的抗日民族统一战线的政策是彻底的、诚恳的和真实的”这样一个判断了。在他们作出这个判断之后，如果他们对于团结救国也是真实的的话，那末他们就能够进一步作出这样的结论：“抗日民族统一战线是能够成功的。”这个概念、判断和推理的阶段，在人们对于一个事物的整个认识过程中是更重要的阶段，也就是理性认识的阶段。认识的真正任务在于经过感觉而到达于思维，到达于逐步了解客观事物的内部矛盾，了解它的规律性，了解这一过程和那一过程间的内部联系，即到达于论理的认识。重复地说，论理的认识所以和感性的认识不同，是因为感性的认识是属于事物之片面的、现象的、外部联系的东西，论理的认识则推进了一大步，到达了事物的全体的、本质的、内部联系的东西，到达了暴露周围世界的内在的矛盾，因而能在周围世界的总体上，在周围世界一切方面的内部联系上去把握周围世界的发展。\n这种基于实践的由浅入深的辩证唯物论的关于认识发展过程的理论，在马克思主义以前，是没有一个人这样解决过的。马克思主义的唯物论，第一次正确地解决了这个问题，唯物地而且辩证地指出了认识的深化的运动，指出了社会的人在他们的生产和阶级斗争的复杂的、经常反复的实践中，由感性认识到论理认识的推移的运动。列宁说过：“物质的抽象，自然规律的抽象，价值的抽象以及其他等等，一句话，一切科学的（正确的、郑重的、非瞎说的）抽象，都更深刻、更正确、更完全地反映着自然。”⑶马克思列宁主义认为：认识过程中两个阶段的特性，在低级阶段，认识表现为感性的，在高级阶段，认识表现为论理的，但任何阶段，都是统一的认识过程中的阶段。感性和理性二者的性质不同，但又不是互相分离的，它们在实践的基础上统一起来了。我们的实践证明：感觉到了的东西，我们不能立刻理解它，只有理解了的东西才更深刻地感觉它。感觉只解决现象问题，理论才解决本质问题。这些问题的解决，一点也不能离开实践。无论何人要认识什么事物，除了同那个事物接触，即生活于（实践于）那个事物的环境中，是没有法子解决的。不能在封建社会就预先认识资本主义社会的规律，因为资本主义还未出现，还无这种实践。马克思主义只能是资本主义社会的产物。马克思不能在自由资本主义时代就预先具体地认识帝国主义时代的某些特异的规律，因为帝国主义这个资本主义最后阶段还未到来，还无这种实践，只有列宁和斯大林才能担当此项任务。马克思、恩格斯、列宁、斯大林之所以能够作出他们的理论，除了他们的天才条件之外，主要地是他们亲自参加了当时的阶级斗争和科学实验的实践，没有这后一个条件，任何天才也是不能成功的。“秀才不出门，全知天下事”，在技术不发达的古代只是一句空话，在技术发达的现代虽然可以实现这句话，然而真正亲知的是天下实践着的人，那些人在他们的实践中间取得了“知”，经过文字和技术的传达而到达于“秀才”之手，秀才乃能间接地“知天下事”。如果要直接地认识某种或某些事物，便只有亲身参加于变革现实、变革某种或某些事物的实践的斗争中，才能触到那种或那些事物的现象，也只有在亲身参加变革现实的实践的斗争中，才能暴露那种或那些事物的本质而理解它们。这是任何人实际上走着的认识路程，不过有些人故意歪曲地说些反对的话罢了。世上最可笑的是那些“知识里手”⑷，有了道听途说的一知半解，便自封为“天下第一”，适足见其不自量而已。知识的问题是一个科学问题，来不得半点的虚伪和骄傲，决定地需要的倒是其反面——诚实和谦逊的态度。你要有知识，你就得参加变革现实的实践。你要知道梨子的滋味，你就得变革梨子，亲口吃一吃。你要知道原子的组织同性质，你就得实行物理学和化学的实验，变革原子的情况。你要知道革命的理论和方法，你就得参加革命。一切真知都是从直接经验发源的。但人不能事事直接经验，事实上多数的知识都是间接经验的东西，这就是一切古代的和外域的知识。这些知识在古人在外人是直接经验的东西，如果在古人外人直接经验时是符合于列宁所说的条件“科学的抽象”，是科学地反映了客观的事物，那末这些知识是可靠的，否则就是不可靠的。所以，一个人的知识，不外直接经验的和间接经验的两部分。而且在我为间接经验者，在人则仍为直接经验。因此，就知识的总体说来，无论何种知识都是不能离开直接经验的。任何知识的来源，在于人的肉体感官对客观外界的感觉，否认了这个感觉，否认了直接经验，否认亲自参加变革现实的实践，他就不是唯物论者。“知识里手”之所以可笑，原因就是在这个地方。中国人有一句老话：“不入虎穴，焉得虎子。”这句话对于人们的实践是真理，对于认识论也是真理。离开实践的认识是不可能的。\n为了明了基于变革现实的实践而产生的辩证唯物论的认识运动——认识的逐渐深化的运动，下面再举出几个具体的例子。\n无产阶级对于资本主义社会的认识，在其实践的初期——破坏机器和自发斗争时期，他们还只在感性认识的阶段，只认识资本主义各个现象的片面及其外部的联系。这时，他们还是一个所谓“自在的阶级”。但是到了他们实践的第二个时期——有意识有组织的经济斗争和政治斗争的时期，由于实践，由于长期斗争的经验，经过马克思、恩格斯用科学的方法把这种种经验总结起来，产生了马克思主义的理论，用以教育无产阶级，这样就使无产阶级理解了资本主义社会的本质，理解了社会阶级的剥削关系，理解了无产阶级的历史任务，这时他们就变成了一个“自为的阶级”。\n中国人民对于帝国主义的认识也是这样。第一阶段是表面的感性的认识阶段，表现在太平天国运动和义和团运动等笼统的排外主义的斗争上⑸。第二阶段才进到理性的认识阶段，看出了帝国主义内部和外部的各种矛盾，并看出了帝国主义联合中国买办阶级和封建阶级以压榨中国人民大众的实质，这种认识是从一九一九年五四运动⑹前后才开始的。\n我们再来看战争。战争的领导者，如果他们是一些没有战争经验的人，对于一个具体的战争（例如我们过去十年的土地革命战争）的深刻的指导规律，在开始阶段是不了解的。他们在开始阶段只是身历了许多作战的经验，而且败仗是打得很多的。然而由于这些经验（胜仗，特别是败仗的经验），使他们能够理解贯串整个战争的内部的东西，即那个具体战争的规律性，懂得了战略和战术，因而能够有把握地去指导战争。此时，如果改换一个无经验的人去指导，又会要在吃了一些败仗之后（有了经验之后）才能理会战争的正确的规律。\n常常听到一些同志在不能勇敢接受工作任务时说出来的一句话：没有把握。为什么没有把握呢？因为他对于这项工作的内容和环境没有规律性的了解，或者他从来就没有接触过这类工作，或者接触得不多，因而无从谈到这类工作的规律性。及至把工作的情况和环境给以详细分析之后，他就觉得比较地有了把握，愿意去做这项工作。如果这个人在这项工作中经过了一个时期，他有了这项工作的经验了，而他又是一个肯虚心体察情况的人，不是一个主观地、片面地、表面地看问题的人，他就能够自己做出应该怎样进行工作的结论，他的工作勇气也就可以大大地提高了。只有那些主观地、片面地和表面地看问题的人，跑到一个地方，不问环境的情况，不看事情的全体（事情的历史和全部现状），也不触到事情的本质（事情的性质及此一事情和其他事情的内部联系），就自以为是地发号施令起来，这样的人是没有不跌交子的。\n由此看来，认识的过程，第一步，是开始接触外界事情，属于感觉的阶段。第二步，是综合感觉的材料加以整理和改造，属于概念、判断和推理的阶段。只有感觉的材料十分丰富（不是零碎不全）和合于实际（不是错觉），才能根据这样的材料造出正确的概念和论理来。\n这里有两个要点必须着重指明。第一个，在前面已经说过的，这里再重复说一说，就是理性认识依赖于感性认识的问题。如果以为理性认识可以不从感性认识得来，他就是一个唯心论者。哲学史上有所谓“唯理论”一派，就是只承认理性的实在性，不承认经验的实在性，以为只有理性靠得住，而感觉的经验是靠不住的，这一派的错误在于颠倒了事实。理性的东西所以靠得住，正是由于它来源于感性，否则理性的东西就成了无源之水，无本之木，而只是主观自生的靠不住的东西了。从认识过程的秩序说来，感觉经验是第一的东西，我们强调社会实践在认识过程中的意义，就在于只有社会实践才能使人的认识开始发生，开始从客观外界得到感觉经验。一个闭目塞听、同客观外界根本绝缘的人，是无所谓认识的。认识开始于经验——这就是认识论的唯物论。\n第二是认识有待于深化，认识的感性阶段有待于发展到理性阶段——这就是认识论的辩证法⑺。如果以为认识可以停顿在低级的感性阶段，以为只有感性认识可靠，而理性认识是靠不住的，这便是重复了历史上的“经验论”的错误。这种理论的错误，在于不知道感觉材料固然是客观外界某些真实性的反映（我这里不来说经验只是所谓内省体验的那种唯心的经验论），但它们仅是片面的和表面的东西，这种反映是不完全的，是没有反映事物本质的。要完全地反映整个的事物，反映事物的本质，反映事物的内部规律性，就必须经过思考作用，将丰富的感觉材料加以去粗取精、去伪存真、由此及彼、由表及里的改造制作工夫，造成概念和理论的系统，就必须从感性认识跃进到理性认识。这种改造过的认识，不是更空虚了更不可靠了的认识，相反，只要是在认识过程中根据于实践基础而科学地改造过的东西，正如列宁所说乃是更深刻、更正确、更完全地反映客观事物的东西。庸俗的事务主义家不是这样，他们尊重经验而看轻理论，因而不能通观客观过程的全体，缺乏明确的方针，没有远大的前途，沾沾自喜于一得之功和一孔之见。这种人如果指导革命，就会引导革命走上碰壁的地步。\n理性认识依赖于感性认识，感性认识有待于发展到理性认识，这就是辩证唯物论的认识论。哲学上的“唯理论”和“经验论”都不懂得认识的历史性或辩证性，虽然各有片面的真理（对于唯物的唯理论和经验论而言，非指唯心的唯理论和经验论），但在认识论的全体上则都是错误的。由感性到理性之辩证唯物论的认识运动，对于一个小的认识过程（例如对于一个事物或一件工作的认识）是如此，对于一个大的认识过程（例如对于一个社会或一个革命的认识）也是如此。\n然而认识运动至此还没有完结。辩证唯物论的认识运动，如果只到理性认识为止，那末还只说到问题的一半。而且对于马克思主义的哲学说来，还只说到非十分重要的那一半。马克思主义的哲学认为十分重要的问题，不在于懂得了客观世界的规律性，因而能够解释世界，而在于拿了这种对于客观规律性的认识去能动地改造世界。在马克思主义看来，理论是重要的，它的重要性充分地表现在列宁说过的一句话：“没有革命的理论，就不会有革命的运动。”⑻然而马克思主义看重理论，正是，也仅仅是，因为它能够指导行动。如果有了正确的理论，只是把它空谈一阵，束之高阁，并不实行，那末，这种理论再好也是没有意义的。认识从实践始，经过实践得到了理论的认识，还须再回到实践去。认识的能动作用，不但表现于从感性的认识到理性的认识之能动的飞跃，更重要的还须表现于从理性的认识到革命的实践这一个飞跃。抓着了世界的规律性的认识，必须把它再回到改造世界的实践中去，再用到生产的实践、革命的阶级斗争和民族斗争的实践以及科学实验的实践中去。这就是检验理论和发展理论的过程，是整个认识过程的继续。理论的东西之是否符合于客观真理性这个问题，在前面说的由感性到理性之认识运动中是没有完全解决的，也不能完全解决的。要完全地解决这个问题，只有把理性的认识再回到社会实践中去，应用理论于实践，看它是否能够达到预想的目的。许多自然科学理论之所以被称为真理，不但在于自然科学家们创立这些学说的时候，而且在于为尔后的科学实践所证实的时候。马克思列宁主义之所以被称为真理，也不但在于马克思、恩格斯、列宁、斯大林等人科学地构成这些学说的时候，而且在于为尔后革命的阶级斗争和民族斗争的实践所证实的时候。辩证唯物论之所以为普遍真理，在于经过无论什么人的实践都不能逃出它的范围。人类认识的历史告诉我们，许多理论的真理性是不完全的，经过实践的检验而纠正了它们的不完全性。许多理论是错误的，经过实践的检验而纠正其错误。所谓实践是真理的标准，所谓“生活、实践底观点，应该是认识论底首先的和基本的观点”⑼，理由就在这个地方。斯大林说得好：“理论若不和革命实践联系起来，就会变成无对象的理论，同样，实践若不以革命理论为指南，就会变成盲目的实践。”⑽\n说到这里，认识运动就算完成了吗？我们的答复是完成了，又没有完成。社会的人们投身于变革在某一发展阶段内的某一客观过程的实践中（不论是关于变革某一自然过程的实践，或变革某一社会过程的实践），由于客观过程的反映和主观能动性的作用，使得人们的认识由感性的推移到了理性的，造成了大体上相应于该客观过程的法则性的思想、理论、计划或方案，然后再应用这种思想、理论、计划或方案于该同一客观过程的实践，如果能够实现预想的目的，即将预定的思想、理论、计划、方案在该同一过程的实践中变为事实，或者大体上变为事实，那末，对于这一具体过程的认识运动算是完成了。例如，在变革自然的过程中，某一工程计划的实现，某一科学假想的证实，某一器物的制成，某一农产的收获，在变革社会过程中某一罢工的胜利，某一战争的胜利，某一教育计划的实现，都算实现了预想的目的。然而一般地说来，不论在变革自然或变革社会的实践中，人们原定的思想、理论、计划、方案，毫无改变地实现出来的事，是很少的。这是因为从事变革现实的人们，常常受着许多的限制，不但常常受着科学条件和技术条件的限制，而且也受着客观过程的发展及其表现程度的限制（客观过程的方面及本质尚未充分暴露）。在这种情形之下，由于实践中发现前所未料的情况，因而部分地改变思想、理论、计划、方案的事是常有的，全部地改变的事也是有的。即是说，原定的思想、理论、计划、方案，部分地或全部地不合于实际，部分错了或全部错了的事，都是有的。许多时候须反复失败过多次，才能纠正错误的认识，才能到达于和客观过程的规律性相符合，因而才能够变主观的东西为客观的东西，即在实践中得到预想的结果。但是不管怎样，到了这种时候，人们对于在某一发展阶段内的某一客观过程的认识运动，算是完成了。\n然而对于过程的推移而言，人们的认识运动是没有完成的。任何过程，不论是属于自然界的和属于社会的，由于内部的矛盾和斗争，都是向前推移向前发展的，人们的认识运动也应跟着推移和发展。依社会运动来说，真正的革命的指导者，不但在于当自己的思想、理论、计划、方案有错误时须得善于改正，如同上面已经说到的，而且在于当某一客观过程已经从某一发展阶段向另一发展阶段推移转变的时候，须得善于使自己和参加革命的一切人员在主观认识上也跟着推移转变，即是要使新的革命任务和新的工作方案的提出，适合于新的情况的变化。革命时期情况的变化是很急速的，如果革命党人的认识不能随之而急速变化，就不能引导革命走向胜利。\n然而思想落后于实际的事是常有的，这是因为人的认识受了许多社会条件的限制的缘故。我们反对革命队伍中的顽固派，他们的思想不能随变化了的客观情况而前进，在历史上表现为右倾机会主义。这些人看不出矛盾的斗争已将客观过程推向前进了，而他们的认识仍然停止在旧阶段。一切顽固党的思想都有这样的特征。他们的思想离开了社会的实践，他们不能站在社会车轮的前头充任向导的工作，他们只知跟在车子后面怨恨车子走得太快了，企图把它向后拉，开倒车。\n我们也反对“左”翼空谈主义。他们的思想超过客观过程的一定发展阶段，有些把幻想看作真理，有些则把仅在将来有现实可能性的理想，勉强地放在现时来做，离开了当前大多数人的实践，离开了当前的现实性，在行动上表现为冒险主义。\n唯心论和机械唯物论，机会主义和冒险主义，都是以主观和客观相分裂，以认识和实践相脱离为特征的。以科学的社会实践为特征的马克思列宁主义的认识论，不能不坚决反对这些错误思想。马克思主义者承认，在绝对的总的宇宙发展过程中，各个具体过程的发展都是相对的，因而在绝对真理的长河中，人们对于在各个一定发展阶段上的具体过程的认识只具有相对的真理性。无数相对的真理之总和，就是绝对的真理⑾。客观过程的发展是充满着矛盾和斗争的发展，人的认识运动的发展也是充满着矛盾和斗争的发展。一切客观世界的辩证法的运动，都或先或后地能够反映到人的认识中来。社会实践中的发生、发展和消灭的过程是无穷的，人的认识的发生、发展和消灭的过程也是无穷的。根据于一定的思想、理论、计划、方案以从事于变革客观现实的实践，一次又一次地向前，人们对于客观现实的认识也就一次又一次地深化。客观现实世界的变化运动永远没有完结，人们在实践中对于真理的认识也就永远没有完结。马克思列宁主义并没有结束真理，而是在实践中不断地开辟认识真理的道路。我们的结论是主观和客观、理论和实践、知和行的具体的历史的统一，反对一切离开具体历史的“左”的或右的错误思想。\n社会的发展到了今天的时代，正确地认识世界和改造世界的责任，已经历史地落在无产阶级及其政党的肩上。这种根据科学认识而定下来的改造世界的实践过程，在世界、在中国均已到达了一个历史的时节——自有历史以来未曾有过的重大时节，这就是整个儿地推翻世界和中国的黑暗面，把它们转变过来成为前所未有的光明世界。无产阶级和革命人民改造世界的斗争，包括实现下述的任务：改造客观世界，也改造自己的主观世界——改造自己的认识能力，改造主观世界同客观世界的关系。地球上已经有一部分实行了这种改造，这就是苏联。他们还正在促进这种改造过程。中国人民和世界人民也都正在或将要通过这样的改造过程。所谓被改造的客观世界，其中包括了一切反对改造的人们，他们的被改造，须要通过强迫的阶段，然后才能进入自觉的阶段。世界到了全人类都自觉地改造自己和改造世界的时候，那就是世界的共产主义时代。\n通过实践而发现真理，又通过实践而证实真理和发展真理。从感性认识而能动地发展到理性认识，又从理性认识而能动地指导革命实践，改造主观世界和客观世界。实践、认识、再实践、再认识，这种形式，循环往复以至无穷，而实践和认识之每一循环的内容，都比较地进到了高一级的程度。这就是辩证唯物论的全部认识论，这就是辩证唯物论的知行统一观。\n 　注　释\n〔1〕见列宁《黑格尔〈逻辑学〉一书摘要》。新的译文是：“实践高于（理论的）认识，因为它不仅具有普遍性的品格，而且还具有直接现实性的品格。”（《列宁全集》第55卷，人民出版社1990年版，第183页）\n〔2〕参见马克思《关于费尔巴哈的提纲》（《马克思恩格斯选集》第1卷，人民出版社1972年版，第16—19页）和列宁《唯物主义和经验批判主义》第二章第六节（《列宁全集》第18卷，人民出版社1988年版，第144页）。\n〔3〕 见列宁《黑格尔〈逻辑学〉一书摘要》（《列宁全集》第55卷，人民出版社1990年版，第142页）。\n〔4〕里手，湖南方言，内行的意思。\n〔5〕一九五一年三月二十七日，毛泽东在致李达的信中说：“《实践论》中将太平天国放在排外主义一起说不妥，出选集时拟加修改，此处暂仍照原。”\n〔6〕五四运动是一九一九年五月四日发生的反帝反封建的爱国运动。当时，第一次世界大战刚刚结束，英、美、法、日、意等战胜国在巴黎召开对德和会，决定由日本继承德国在中国山东的特权。中国是参加对德宣战的战胜国之一，但北洋军阀政府却准备接受这个决定。五月四日，北京学生游行示威，反对帝国主义的这一无理决定和北洋军阀政府的妥协。这次运动迅速地获得了全国人民的响应，到六月三日以后，发展成为有工人阶级、城市小资产阶级和民族资产阶级参加的广大群众性的反帝反封建的爱国运动。五四运动也是反对封建文化的新文化运动。以一九一五年《青年杂志》（后改名《新青年》）创刊为起点的新文化运动，竖起“民主”和“科学”的旗帜，反对旧道德，提倡新道德，反对旧文学，提倡新文学。五四运动中的先进分子接受了马克思主义，使新文化运动发展成为马克思主义思想运动，他们致力于马克思主义同中国工人运动相结合，在思想上和干部上准备了中国共产党的成立。\n〔7〕参见列宁《黑格尔〈逻辑学〉一书摘要》：“要理解，就必须从经验开始理解、研究，从经验上升到一般。”（《列宁全集》第55卷，人民出版社1990年版，第175页）\n〔8〕见列宁《俄国社会民主党人的任务》（《列宁全集》第2卷，人民出版社1984年版，第443页）；并见列宁《怎么办？》第一章第四节（《列宁全集》第6卷，人民出版社1986年版，第23页）。\n〔9〕 见列宁《唯物主义和经验批判主义》第二章第六节（《列宁全集》第18卷，人民出版社1988年版，第144页）。\n〔10〕见斯大林《论列宁主义基础》第三部分《理论》。新的译文是：“离开革命实践的理论是空洞的理论，而不以革命理论为指南的实践是盲目的实践。”（《斯大林选集》上卷，人民出版社1979年版，第199—200页）\n〔11〕参见列宁《唯物主义和经验批判主义》第二章第五节。原文是：“人类思维按其本性是能够给我们提供并且正在提供由相对真理的总和所构成的绝对真理的。”（《列宁全集》第18卷，人民出版社1988年版，第135页）\n"});index.add({'id':34,'href':'/notes/docs/technology/other/interview/work/','title':"工作总结",'section':"面试相关",'content':"工作总结 #  # 关键字，效率，稳定，成本 1、构建基础元数据（cmdb） 2、自动化 3、成本控制 4、容器化 基础元数据构建 #  资源 --\u0026gt; 应用 --\u0026gt; 部门(人员) 1. 资源和应用的关系(tag)，多对多 2. 应用和归属部门的关系，一对多 3. 应用和负责人的关系，一对多 成本控制和权限自动化 自动化 #  1、工单系统(ecs,rds,redis,domain,slb,account) 2、资源自动化 3、发布系统 4、监控系统 5、项目系统 成本控制 #  1、成本统计 2、低使用率资源统计 3、各部门推进 容器化 #  1、k8s平台 2、发布 3、监控 4、日志 服务 #  SLI SLO SLA "});index.add({'id':35,'href':'/notes/docs/technology/program/language/golang/concurrent/','title':"并发",'section':"Golang",'content':"并发 #  goroutine #  和Thread的区别 #    内存消耗，创建一个 goroutine 的栈内存消耗为 2 KB，。创建一个 thread 则需要消耗 1 MB 栈内存，而且还需要一个被称为 “a guard page” 的区域用于和其他 thread 的栈空间进行隔离。\n  创建与销毀，Thread 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池。而 goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。\n  切换，当 threads 切换时，需要保存各种寄存器，以便将来恢复：\n 16 general purpose registers, PC (Program Counter), SP (Stack Pointer), segment registers, 16 XMM registers, FP coprocessor state, 16 AVX registers, all MSRs etc.\n 而 goroutines 切换只需保存三个寄存器：Program Counter, Stack Pointer and BP。\n   GPM #  "});index.add({'id':36,'href':'/notes/docs/technology/','title':"技术相关",'section':"Docs",'content':"技术相关 #  系统 #  计算机基础 #     计算机组成\n   操作系统\n   文件系统\n  Linux系统 #     内核编译\n   启动\n   Linux目录结构\n   Linux操作指南\n  应用服务 #     SSH\n   Nginx\n   网络 #  网络基础 #  网络协议 #     TCP\n   HTTP\n   DNS\n   编程 #  编程基础 #  版本控制 #    Git  编程语言 #     Shell\n   Golang\n   Python\n  编程进阶 #    数据结构  算法  设计模式   数据库 #    数据库基础\n   PostgreSQL\n   MySQL\n   Redis\n   云原生 #   安全 #     安全基础\n   TLS\n   Firewall\n   IDS\n   Snort\n  Ossec\n  tripware\n     大数据 #     基础概念\n   Zookeeper\n   Kafka\n   智能化 #     Ansible\n   Docker\n   Kubernetes\n   Elk\n   工具 #    TCPCopy  Script   "});index.add({'id':37,'href':'/notes/docs/technology/other/interview/tech/','title':"技术知识点",'section':"面试相关",'content':"技术知识点 #  1. 系统 #  2. 网络 #  3. 数据库 #  4. 云原生 #  5. Golang #   针对性技术 #  1. TCP #  2. HTTP/HTTPS #  3. DNS #  4. Nginx #  5. LVS #  6. Ansible #  7. Kubernetes #  8. DevOps #  9. MySQL #  10. Redis #   "});index.add({'id':38,'href':'/notes/docs/technology/cloud/container/kubernetes/map/','title':"技能图谱",'section':"Kubernetes",'content':"Kubernetes 技能图谱 #  Container basics （容器技术基础） #   Linux Operating System Basic Linux Process Management (Linux进程管理) Cgroups Linux Namespaces Rootfs \u0026amp; Container Image Image Registry  Kubernetes architecture （Kubernetes 架构） #  Node #  Kubelet #   Runtime （容器运行时）  CRI (Container Runtime Interface) Runtime shims （容器运行时插件）  Cri-containerd （containerd） Dockershim （Docker） Cri-o （runC） Rktlet （rkt） Frakti （KataContainers）   RuntimeClass (新特性：容器运行时类)   Networking  CNI (Container Network Interface) Linux Network Namespace Network plugins （网络插件）  Flannel Calico OVS SR-IOV macvlan/ipvlan Opencontrail Weave Cilium （新插件，支持BPF，推荐）     Storage  CSI (Container Storage Interface) Persistent Volume \u0026amp; Persistent Volume Claim Volume plugins （存储插件，仅负责提供PV）  NFS Cinder GlusterFS Ceph Local path   Volume extenstion (存储扩展，负责提供完整的Storage方案)  Rook.io     Kube-proxy  Iptables 转发链与随机模式 IPVS 负载均衡    Master #   API server  Watch \u0026amp; Informer （Watch 和通知框架） Admission Plugin（权限控制插件） RBAC plugin （基于角色的访问控制插件） Custom Resource Definition (新特性，CRD，自定义API对象，重点推荐) APIServer aggregator (新特性，聚合APIServer，推荐)   Controller manager  Reconcile （控制循环与状态协调机制）   Scheduler  Scheduling algorithm （默认调度算法） Scheduler extender （调度器扩展器） Custom algorithm （自定义调度算法） Custom scheduler （自定义调度器） Scheduler Framework （新特性，可扩展调度框架，推荐） Multiple scheduler （多调度器）   Etcd  Etcd operator Etcd performance tuning    Kubernetes workloads （Kubernetes 作业管理） #   Pod ReplicaSet （容器副本） Deployment （常规作业发布）  Rolling update （自动的滚动更新） Pause/resume （可控的更新流程） Canary deploy （金丝雀发布） Rollback （版本回滚）   DaemonSet （Daemon 作业） StatefulSet （有状态任务）  Topology State Storage State   Job （一次性任务） CronJob （定时任务）  Kubernetes applications management （Kubernetes 应用配置） #   Service （服务发现）  Publish service（对外暴露 Service） Nginx/HAproxy service（自定义 Service） External Load Balancer   ConfigMap （应用配置管理） Ingress （7层服务发现） Secret （加密信息管理） Headless Service（DNS 服务发现） External Load Balancer  Kubernetes operations （Kubernetes 安装与运维） #   Installation  Kubeadm （内置部署工具，推荐） Minikube （本地部署工具） Kops （云端部署工具）   Maintenances  Garbage Collection (垃圾回收)  Container GC Image GC     Upgrades Troubleshooting  etcd admin  Key-value CRUD（键值对操作） Metrics monitoring （Metrics 监控） Cluster design（集群规划） Disaster Recovery （灾难恢复，backup 和 restore）   Iptables rules    Kubernetes extensions/add-ons （Kubernetes 扩展和插件） #   Custom Resources Definition （自定义 Kubernetes API 对象）  Customized controller （自定义 API 对象控制器） Workqueue （自定义 API 对象任务队列）   Kube-dns  SkyDNS CoreDNS   Fluentd （日志收集）  Fluent-bit   Heapster (容器集群监控） Istio（微服务治理和负载均衡） Federation v2（新特性：集群联邦v2） Helm (kubernetes application package)  Kubernetes CI/CD #   Spinnaker Skaffold (新项目，推荐)  Kubernetes PaaS #   OpenShift Knative （新项目，推荐）   路径 #   kube-ladder\n"});index.add({'id':39,'href':'/notes/docs/technology/cloud/container/map/','title':"技能图谱",'section':"容器技术",'content':"技能图谱 #  容器化工具 #    Docker  LXC  RunC  Rkt  Systemd-nspawn  Garden  Vagga  VMWare Photon  gVisor  Pouch Container  Kata Containers  监控和数据收集 #    Sysdig Monitor  cAdvisor  Weave Scope  Prometheus  TICK-Stack  Docker-Alertd  Grafana  Cockpit  基础设施集成 #    Magnum  Boot2Docker  MaestroNG  CloudFoundry Containers Service Broker  编排和调度 #    Crane  Mesos  Marathon  Compose  Yarn  Kubernetes  Openshift Origin  Rancher  K3s  Nomad  SwarmKit  Nebula  Dokku  Flynn  商业平台 #    AWS Container Service  Google Container Engine  Azure Container Service  阿里云容器服务  腾讯云容器服务  华为云容器引擎  容器镜像仓库 #    Repository  Nexus  Habor  Portus  Dragonfly  服务发现和容器 #    Consul  Etcd  ZooKeeper  Eureka  Traefik  Registrator  容器日志收集处理 #    Splunk  Elastic Stack  Fluentd  Flume  Graylog  Rsyslog  容器相关的系统发行版 #    Container Linux (CoreOS)  Project Atomic  RancherOS  ClearLinux  VMWare Photon  Talos  k3os  LinuxKit  SmartOS  容器网络 #    Pipework  Flannel  Calico  Weave  Kubenet  Contiv  OpenContrail  MacVlan  Canal  Romana  Submariner  容器安全 #    Anchore Engine  Aqua Microscanner  Clair  Dagda  Twistlock  OpenSCAP  Notary  Twistlock  SELinux  AppArmor  容器数据持久化 #    Ceph  Convoy  REX-Ray  Netshare  OpenStorage  容器相关标准 #    OCI Runtime Spec  OCI Image Spec  OCI Distribution Spec  Container Network Interface  Container Storage Interface   "});index.add({'id':40,'href':'/notes/docs/technology/cloud/devops/map/','title':"技能图谱",'section':"DevOps",'content':"DevOps #   "});index.add({'id':41,'href':'/notes/docs/technology/database/basic/','title':"数据库基础",'section':"数据库",'content':"数据库基础 #  "});index.add({'id':42,'href':'/notes/docs/technology/program/advanced/dataStructure/','title':"数据结构",'section':"编程进阶",'content':"数据结构 #    链表\n  堆栈\n  队列\n  哈希表\n  二叉排序树\n  单词查找树\n  "});index.add({'id':43,'href':'/notes/docs/technology/leetcode/learn/array/','title':"数组",'section':"学习",'content':"数组 #  什么是数组？ #   An Array is a collection of items. The items could be integers, strings, DVDs, games, books—anything really. The items are stored in neighboring (contiguous) memory locations. Because they\u0026rsquo;re stored together, checking through the entire collection of items is straightforward.\n  数组的CRUD #  创建和访问数组 #  //数组，长度不可变 //切片，长度可变 func arraySlice() { //创建数组(声明长度) \tvar array1 = [5]int{1, 2, 3} //创建数组(不声明长度) \tvar array2 = [...]int{6, 7, 8} //创建切片 \tvar array3 = []int{9, 10, 11, 12} //创建数组(声明长度)，并仅初始化其中的部分元素 \tvar array4 = [5]string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;} //创建数组(不声明长度)，并仅初始化其中的部分元素，数组的长度将根据初始化的元素确定 \tvar array5 = [...]string{3: \u0026#34;Tom\u0026#34;, 2: \u0026#34;Alice\u0026#34;} //创建切片，并仅初始化其中的部分元素，数组切片的len将根据初始化的元素确定 \tvar array6 = []string{4: \u0026#34;Smith\u0026#34;, 2: \u0026#34;Alice\u0026#34;} //创建切片  array7 := make([]int, length, capacity) //访问数组，通过index访问  fmt.Println(array7[0]) }  数组插入元素 #  func insert() { var array []int //插入元素到结尾  array = append(array,6) //插入元素到开头,需要先把数组后移，再插入元素  for i:=len(array)-1;i\u0026gt;=0;i-- { array[i+1] = array[i] } array[0] = 10 //插入元素到指定位置，先把指定位置及后面的数据后移，再插入元素  set := 2 for i := len(array)-1;i\u0026gt;=set;i--{ array[i+1] = array[i] } array[set] = 10 }  数组删除元素 #  func delete() { array := []int{1,2,3} //从尾部删除元素  array = array[:len(array)-1] //从开头删除元素，把数据前移，删除最后一位  for i := 1; i \u0026lt; len(array); i++) { array[i-1] = array[i] } array = array[:len(array)-1] //从指定位置删除元素，把指定位置后面的数据前移，再删除最后一位  for i := 2; i \u0026lt; len(array); i++) { array[i-1] = array[i] } array = array[:len(array)-1] }  搜索某个元素 #  func search(num int) bool { //线性搜索  array := []int{1,2,3} for i:=0; i\u0026lt;len(array); i++{ if array[i] == num { return true } } return false }  就地操作数组 #  节省时间和空间\n 删除重复元素 #  func removeDuplicates(nums []int) { if len(nums) == 0 { return } writePointer := 1 for readPointer := 1; readPointer \u0026lt; len(nums); readPointer++ { if nums[readPointer] != nums[readPointer-1] { nums[writePointer] = nums[readPointer] writePointer++ } } fmt.Println(nums[:writePointer]) } "});index.add({'id':44,'href':'/notes/docs/technology/other/myconfig/','title':"环境配置",'section':"其他",'content':"打造开发环境 #  vim #     配置指南\n   基础配置\n   插件配置\n   开发配置\n   tmux #    基础配置   xshell #    颜色配置  "});index.add({'id':45,'href':'/notes/docs/technology/system/','title':"系统",'section':"技术相关",'content':"系统 #  "});index.add({'id':46,'href':'/notes/docs/technology/program/basic/','title':"编程基础",'section':"编程",'content':"编程基础 #  编程语言 #    解释型语言\n 程序由解释器读取并执行 SoucreCode --\u0026gt; Interpreter --\u0026gt; Output    编译型语言\n 程序被编译器翻译成机器语言后再执行 SourceCode --\u0026gt; Compliler --\u0026gt; ObjectCode --\u0026gt; Executor --\u0026gt; Output     什么是程序？ #  程序是指定如何执行计算的指令序列。\n不同的编程语言具有一些共同的基础特性：\n input：从键盘，文件或者其他输入设备中获取数据。 output：在屏幕显示数据，或者将数据发送给文件或者输出设备。 math：执行基本的数学运算，比如加法和乘法。 conditional execution：检查条件并执行相应的代码。 repetition：反复执行一些操作。  编程可以视为将大型的复杂任务打破成更小和更小的子任务，直到子任务简单到足以执行上述的基本操作的过程。\n 调试(debugging) #  编程容易出错。编程错误被称为错误，并且跟踪它们的过程称为调试。\n Syntax errors：语法错误(语法是指程序的结构和关于该结构的规则)。 Runtime errors(exceptions)：运行时错误(异常)。 Semantic errors：语义错误，做的不是你想要让它做的事情。  调试是通过更改程序去发现和解决错误。\n 数据类型(type) #   interger：整数，例如1,2 string: 字符串，例如\u0026rsquo;Hello\u0026rsquo;   变量(variables) #  变量是引用值的名称，编程语言最强大的功能之一就是操纵变量的能力。\n variable：变量名，由字母开头并由字母或数字组成。最好由小写字母开头。 keyword：关键字，用于识别程序的结构，它们不能用作变量名称。例如,if,for,while   运算符(operators)和操作数(operands) #   operators：运算符，表示计算的特殊符号，例如+,-,* operands：操作数   表达式(expressions)和语句(statements) #   expression：表达式，是值、变量和运算符的组合。 statement：语句是可执行的代码单元。   注释(comments) #  在程序中添加笔记，用于解释程序正在做什么\n 流程控制(control flow) #  在程序运行时，控制个别的指令运行的顺序。\n控制结构：控制结构开始时多半都会有特定的关键字，以标明使用哪一种控制结构\n choice：选择结构  if-then-else： switch case   loop：循环结构  for while     函数(functions) #  函数是组织好的，可重复使用的，用于实现单一或相关联功能的代码段。\n function call：函数调用，一些语言一般由很多内置的函数可供调用。例如，type(32) function definition：定义函数，例如，def hello(): print(\u0026lsquo;Hello,World!') flow of execution：执行流程，程序总是从第一行开始按序执行语句，函数内部的语句并不会被执行，直到函数被调用。 parameter：参数，函数中用于供外部传入值的变量名。 why function?：  便于程序阅读 消除重复代码 便于调式功能 便于重用     模块(Modules) #   接口(interface) #   类(classes)和对象(objects) #   "});index.add({'id':47,'href':'/notes/docs/technology/network/basic/','title':"网络基础",'section':"网络",'content':"网络基础 #  "});index.add({'id':48,'href':'/notes/docs/other/financial/stock/','title':"股票",'section':"理财",'content':"股票 #  交易系统 #  1. ETF基金 5% 10% 20% 2. 股票 "});index.add({'id':49,'href':'/notes/docs/technology/system/basic/','title':"计算机基础",'section':"系统",'content':"计算机基础 #  "});index.add({'id':50,'href':'/notes/docs/technology/system/basic/constitute/','title':"计算机组成",'section':"计算机基础",'content':"计算机组成 #  计算机组成 #  计算机(computer)：一种利用电子学原理，根据一系列指令来对数据进行处理的工具。\n 硬件 #    控制器：负责对程序规定的控制信息进行分析,控制并协调输入,输出操作或内存访问。\n  运算器：负责数据的算术运算和逻辑运算即数据的加工处理。\n  存储器：实现记忆功能的部件用来存放计算程序及参与运算的各种数据。\n  输入设备：实现计算程序和原始数据的输入\n  输出设备：实现计算结果输出\n  图示：\n   软件 #    系统软件：负责管理计算机系统中各种独立的硬件，使得它们可以协调工作，提供基本的功能，并为正在运行的应用软件提供平台。\n  应用软件：为了某种特定的用途而被开发的软件。\n   计算机工作过程 #    用户打开程序\n  系统把程序代码段和数据段送入计算机的内存\n  控制器从存储器中取指令\n  控制器分析,执行指令,为取下一条指令做准备\n  取下一条指令,分析执行,如此重复操作,直至执行完程序中全部指令,便可获得全部指令\n  图示：\n  计算机系统结构 #    "});index.add({'id':51,'href':'/notes/docs/technology/cloud/devops/ansible/','title':"Ansible",'section':"DevOps",'content':"Ansible #  安装 #    安装ansible\npip install ansible    测试\necho \u0026quot;127.0.0.1\u0026quot; \u0026gt; ~/ansible_hosts export ANSIBLE_INVENTORY=~/ansible_hosts ansible all -m ping --ask-pass    Inventory #    主机和组\nansible_hosts 文件\n[group1] host1 host2 [group2] host3 host4 ssh选项 ansible_port=5555(默认22) ansible_host=172.16.0.101 ansible_user=root(默认root) ansible_connection=ssh(默认ssh) ansible_ssh_pass= host变量 http_port=80 maxRequestsPerChild=808 group变量 [group1:vars] ansible_port=33 group包含group [group3:children] group1 group2     命令行 #  ansible \u0026lt;server_name\u0026gt; -m \u0026lt;module_name\u0026gt; -a \u0026lt;arguments\u0026gt;   配置文件 #  略\nPlaybook #  Playbook是Ansible的配置，部署和编排语言，他们可以描述您希望远程系统执行的策略，或一般IT流程中的一组步骤。\n一个playbook案例\n--- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running (and enable it at boot) service: name=httpd state=started enabled=yes handlers: - name: restart apache service: name=httpd state=restarted   roles #   案例 #     tomcat\n   tengine\n   zookeeper\n   kafka\n  "});index.add({'id':52,'href':'/notes/docs/technology/cloud/container/kubernetes/api/doc/','title':"API文档",'section':"Kubernetes API",'content':"API文档 #  API Conventions #  This document is oriented at users who want a deeper understanding of the Kubernetes API structure, and developers wanting to extend the Kubernetes API. An introduction to using resources with kubectl can be found in the object management overview.\nTable of Contents\n Types (Kinds)   Resources Objects   Metadata Spec and Status   Typical status properties    References to related objects  Lists of named subobjects preferred over maps  Primitive types  Constants  Unions    Lists and Simple kinds    Differing Representations Verbs on Resources   PATCH operations    Idempotency  Optional vs. Required  Defaulting  Late Initialization  Concurrency Control and Consistency  Serialization Format  Units  Selecting Fields  Object references HTTP Status codes   Success codes  Error codes    Response Status Kind  Events  Naming conventions  Label, selector, and annotation conventions  WebSockets and SPDY  Validation  The conventions of the Kubernetes API (and related APIs in the ecosystem) are intended to ease client development and ensure that configuration mechanisms can be implemented that work across a diverse set of use cases consistently.\nThe general style of the Kubernetes API is RESTful - clients create, update, delete, or retrieve a description of an object via the standard HTTP verbs (POST, PUT, DELETE, and GET) - and those APIs preferentially accept and return JSON. Kubernetes also exposes additional endpoints for non-standard verbs and allows alternative content types. All of the JSON accepted and returned by the server has a schema, identified by the \u0026ldquo;kind\u0026rdquo; and \u0026ldquo;apiVersion\u0026rdquo; fields. Where relevant HTTP header fields exist, they should mirror the content of JSON fields, but the information should not be represented only in the HTTP header.\nThe following terms are defined:\n  Kind the name of a particular object schema (e.g. the \u0026ldquo;Cat\u0026rdquo; and \u0026ldquo;Dog\u0026rdquo; kinds would have different attributes and properties)\n  Resource\na representation of a system entity, sent or retrieved as JSON via HTTP to the server. Resources are exposed via:\n Collections - a list of resources of the same type, which may be queryable Elements - an individual resource, addressable via a URL    API Group a set of resources that are exposed together. Along with the version is exposed in the \u0026ldquo;apiVersion\u0026rdquo; field as \u0026ldquo;GROUP/VERSION\u0026rdquo;, e.g. \u0026ldquo;policy.k8s.io/v1\u0026rdquo;.\n  Each resource typically accepts and returns data of a single kind. A kind may be accepted or returned by multiple resources that reflect specific use cases. For instance, the kind \u0026ldquo;Pod\u0026rdquo; is exposed as a \u0026ldquo;pods\u0026rdquo; resource that allows end users to create, update, and delete pods, while a separate \u0026ldquo;pod status\u0026rdquo; resource (that acts on \u0026ldquo;Pod\u0026rdquo; kind) allows automated processes to update a subset of the fields in that resource.\nResources are bound together in API groups - each group may have one or more versions that evolve independent of other API groups, and each version within the group has one or more resources. Group names are typically in domain name form - the Kubernetes project reserves use of the empty group, all single word names (\u0026ldquo;extensions\u0026rdquo;, \u0026ldquo;apps\u0026rdquo;), and any group name ending in \u0026ldquo;*.k8s.io\u0026rdquo; for its sole use. When choosing a group name, we recommend selecting a subdomain your group or organization owns, such as \u0026ldquo;widget.mycompany.com\u0026rdquo;.\nVersion strings should match DNS_LABEL format.\nResource collections should be all lowercase and plural, whereas kinds are CamelCase and singular. Group names must be lower case and be valid DNS subdomains.\nTypes (Kinds) #  Kinds are grouped into three categories:\n  Objects represent a persistent entity in the system.\nCreating an API object is a record of intent - once created, the system will work to ensure that resource exists. All API objects have common metadata.\nAn object may have multiple resources that clients can use to perform specific actions that create, update, delete, or get.\nExamples: Pod, ReplicationController, Service, Namespace, Node.\n  Lists are collections of resources of one (usually) or more (occasionally) kinds.\nThe name of a list kind must end with \u0026ldquo;List\u0026rdquo;. Lists have a limited set of common metadata. All lists use the required \u0026ldquo;items\u0026rdquo; field to contain the array of objects they return. Any kind that has the \u0026ldquo;items\u0026rdquo; field must be a list kind.\nMost objects defined in the system should have an endpoint that returns the full set of resources, as well as zero or more endpoints that return subsets of the full list. Some objects may be singletons (the current user, the system defaults) and may not have lists.\nIn addition, all lists that return objects with labels should support label filtering (see the labels documentation), and most lists should support filtering by fields.\nExamples: PodLists, ServiceLists, NodeLists.\nTODO: Describe field filtering below or in a separate doc.\n  Simple kinds are used for specific actions on objects and for non-persistent entities.\nGiven their limited scope, they have the same set of limited common metadata as lists.\nFor instance, the \u0026ldquo;Status\u0026rdquo; kind is returned when errors occur and is not persisted in the system.\nMany simple resources are \u0026ldquo;subresources\u0026rdquo;, which are rooted at API paths of specific resources. When resources wish to expose alternative actions or views that are closely coupled to a single resource, they should do so using new sub-resources. Common subresources include:\n /binding: Used to bind a resource representing a user request (e.g., Pod, PersistentVolumeClaim) to a cluster infrastructure resource (e.g., Node, PersistentVolume). /status: Used to write just the status portion of a resource. For example, the /pods endpoint only allows updates to metadata and spec, since those reflect end-user intent. An automated process should be able to modify status for users to see by sending an updated Pod kind to the server to the \u0026ldquo;/pods//status\u0026rdquo; endpoint - the alternate endpoint allows different rules to be applied to the update, and access to be appropriately restricted. /scale: Used to read and write the count of a resource in a manner that is independent of the specific resource schema.  Two additional subresources, proxy and portforward, provide access to cluster resources as described in accessing the cluster.\n  The standard REST verbs (defined below) MUST return singular JSON objects. Some API endpoints may deviate from the strict REST pattern and return resources that are not singular JSON objects, such as streams of JSON objects or unstructured text log data.\nA common set of \u0026ldquo;meta\u0026rdquo; API objects are used across all API groups and are thus considered part of the API group named meta.k8s.io. These types may evolve independent of the API group that uses them and API servers may allow them to be addressed in their generic form. Examples are ListOptions, DeleteOptions, List, Status, WatchEvent, and Scale. For historical reasons these types are part of each existing API group. Generic tools like quota, garbage collection, autoscalers, and generic clients like kubectl leverage these types to define consistent behavior across different resource types, like the interfaces in programming languages.\nThe term \u0026ldquo;kind\u0026rdquo; is reserved for these \u0026ldquo;top-level\u0026rdquo; API types. The term \u0026ldquo;type\u0026rdquo; should be used for distinguishing sub-categories within objects or subobjects.\nResources #  All JSON objects returned by an API MUST have the following fields:\n kind: a string that identifies the schema this object should have apiVersion: a string that identifies the version of the schema the object should have  These fields are required for proper decoding of the object. They may be populated by the server by default from the specified URL path, but the client likely needs to know the values in order to construct the URL path.\nObjects #  Metadata #  Every object kind MUST have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n namespace: a namespace is a DNS compatible label that objects are subdivided into. The default namespace is \u0026lsquo;default\u0026rsquo;. See the namespace docs for more. name: a string that uniquely identifies this object within the current namespace (see the identifiers docs). This value is used in the path when retrieving an individual object. uid: a unique in time and space value (typically an RFC 4122 generated identifier, see the identifiers docs) used to distinguish between objects with the same name that have been deleted and recreated  Every object SHOULD have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n resourceVersion: a string that identifies the internal version of this object that can be used by clients to determine when objects have changed. This value MUST be treated as opaque by clients and passed unmodified back to the server. Clients should not assume that the resource version has meaning across namespaces, different kinds of resources, or different servers. (See concurrency control, below, for more details.) generation: a sequence number representing a specific generation of the desired state. Set by the system and monotonically increasing, per-resource. May be compared, such as for RAW and WAW consistency. creationTimestamp: a string representing an RFC 3339 date of the date and time an object was created deletionTimestamp: a string representing an RFC 3339 date of the date and time after which this resource will be deleted. This field is set by the server when a graceful deletion is requested by the user, and is not directly settable by a client. The resource will be deleted (no longer visible from resource lists, and not reachable by name) after the time in this field except when the object has a finalizer set. In case the finalizer is set the deletion of the object is postponed at least until the finalizer is removed. Once the deletionTimestamp is set, this value may not be unset or be set further into the future, although it may be shortened or the resource may be deleted prior to this time. labels: a map of string keys and values that can be used to organize and categorize objects (see the labels docs) annotations: a map of string keys and values that can be used by external tooling to store and retrieve arbitrary metadata about this object (see the annotations docs)  Labels are intended for organizational purposes by end users (select the pods that match this label query). Annotations enable third-party automation and tooling to decorate objects with additional metadata for their own use.\nSpec and Status #  By convention, the Kubernetes API makes a distinction between the specification of the desired state of an object (a nested object field called \u0026ldquo;spec\u0026rdquo;) and the status of the object at the current time (a nested object field called \u0026ldquo;status\u0026rdquo;). The specification is a complete description of the desired state, including configuration settings provided by the user, default values expanded by the system, and properties initialized or otherwise changed after creation by other ecosystem components (e.g., schedulers, auto-scalers), and is persisted in stable storage with the API object. If the specification is deleted, the object will be purged from the system. The status summarizes the current state of the object in the system, and is usually persisted with the object by automated processes but may be generated on the fly. At some cost and perhaps some temporary degradation in behavior, the status could be reconstructed by observation if it were lost.\nWhen a new version of an object is POSTed or PUT, the \u0026ldquo;spec\u0026rdquo; is updated and available immediately. Over time the system will work to bring the \u0026ldquo;status\u0026rdquo; into line with the \u0026ldquo;spec\u0026rdquo;. The system will drive toward the most recent \u0026ldquo;spec\u0026rdquo; regardless of previous versions of that stanza. In other words, if a value is changed from 2 to 5 in one PUT and then back down to 3 in another PUT the system is not required to \u0026lsquo;touch base\u0026rsquo; at 5 before changing the \u0026ldquo;status\u0026rdquo; to 3. In other words, the system\u0026rsquo;s behavior is level-based rather than edge-based. This enables robust behavior in the presence of missed intermediate state changes.\nThe Kubernetes API also serves as the foundation for the declarative configuration schema for the system. In order to facilitate level-based operation and expression of declarative configuration, fields in the specification should have declarative rather than imperative names and semantics \u0026ndash; they represent the desired state, not actions intended to yield the desired state.\nThe PUT and POST verbs on objects MUST ignore the \u0026ldquo;status\u0026rdquo; values, to avoid accidentally overwriting the status in read-modify-write scenarios. A /status subresource MUST be provided to enable system components to update statuses of resources they manage.\nOtherwise, PUT expects the whole object to be specified. Therefore, if a field is omitted it is assumed that the client wants to clear that field\u0026rsquo;s value. The PUT verb does not accept partial updates. Modification of just part of an object may be achieved by GETting the resource, modifying part of the spec, labels, or annotations, and then PUTting it back. See concurrency control, below, regarding read-modify-write consistency when using this pattern. Some objects may expose alternative resource representations that allow mutation of the status, or performing custom actions on the object.\nAll objects that represent a physical resource whose state may vary from the user\u0026rsquo;s desired intent SHOULD have a \u0026ldquo;spec\u0026rdquo; and a \u0026ldquo;status\u0026rdquo;. Objects whose state cannot vary from the user\u0026rsquo;s desired intent MAY have only \u0026ldquo;spec\u0026rdquo;, and MAY rename \u0026ldquo;spec\u0026rdquo; to a more appropriate name.\nObjects that contain both spec and status should not contain additional top-level fields other than the standard metadata fields.\nSome objects which are not persisted in the system - such as SubjectAccessReview and other webhook style calls - may choose to add spec and status to encapsulate a \u0026ldquo;call and response\u0026rdquo; pattern. The spec is the request (often a request for information) and the status is the response. For these RPC like objects the only operation may be POST, but having a consistent schema between submission and response reduces the complexity of these clients.\nTypical status properties #  Conditions represent the latest available observations of an object\u0026rsquo;s state. They are an extension mechanism intended to be used when the details of an observation are not a priori known or would not apply to all instances of a given Kind. For observations that are well known and apply to all instances, a regular field is preferred. An example of a Condition that probably should have been a regular field is Pod\u0026rsquo;s \u0026ldquo;Ready\u0026rdquo; condition - it is managed by core controllers, it is well understood, and it applies to all Pods.\nObjects may report multiple conditions, and new types of conditions may be added in the future or by 3rd party controllers. Therefore, conditions are represented using a list/slice, where all have similar structure.\nThe FooCondition type for some resource type Foo may include a subset of the following fields, but must contain at least type and status fields:\n Type FooConditionType `json:\u0026quot;type\u0026quot; description:\u0026quot;type of Foo condition\u0026quot;` Status ConditionStatus `json:\u0026quot;status\u0026quot; description:\u0026quot;status of the condition, one of True, False, Unknown\u0026quot;` // +optional Reason *string `json:\u0026quot;reason,omitempty\u0026quot; description:\u0026quot;one-word CamelCase reason for the condition's last transition\u0026quot;` // +optional Message *string `json:\u0026quot;message,omitempty\u0026quot; description:\u0026quot;human-readable message indicating details about last transition\u0026quot;` // +optional LastHeartbeatTime *unversioned.Time `json:\u0026quot;lastHeartbeatTime,omitempty\u0026quot; description:\u0026quot;last time we got an update on a given condition\u0026quot;` // +optional LastTransitionTime *unversioned.Time `json:\u0026quot;lastTransitionTime,omitempty\u0026quot; description:\u0026quot;last time the condition transit from one status to another\u0026quot;` Additional fields may be added in the future.\nDo not use fields that you don\u0026rsquo;t need - simpler is better.\nUse of the Reason field is encouraged.\nUse the LastHeartbeatTime with great caution - frequent changes to this field can cause a large fan-out effect for some resources.\nConditions should be added to explicitly convey properties that users and components care about rather than requiring those properties to be inferred from other observations. Once defined, the meaning of a Condition can not be changed arbitrarily - it becomes part of the API, and has the same backwards- and forwards-compatibility concerns of any other part of the API.\nCondition status values may be True, False, or Unknown. The absence of a condition should be interpreted the same as Unknown. How controllers handle Unknown depends on the Condition in question.\nCondition types should indicate state in the \u0026ldquo;abnormal-true\u0026rdquo; polarity. For example, if the condition indicates when a policy is invalid, the \u0026ldquo;is valid\u0026rdquo; case is probably the norm, so the condition should be called \u0026ldquo;Invalid\u0026rdquo;.\nThe thinking around conditions has evolved over time, so there are several non-normative examples in wide use.\nIn general, condition values may change back and forth, but some condition transitions may be monotonic, depending on the resource and condition type. However, conditions are observations and not, themselves, state machines, nor do we define comprehensive state machines for objects, nor behaviors associated with state transitions. The system is level-based rather than edge-triggered, and should assume an Open World.\nAn example of an oscillating condition type is Ready (despite it running afoul of current guidance), which indicates the object was believed to be fully operational at the time it was last probed. A possible monotonic condition could be Failed. A True status for Failed would imply failure with no retry. An object that was still active would generally not have a Failed condition.\nSome resources in the v1 API contain fields called phase, and associated message, reason, and other status fields. The pattern of using phase is deprecated. Newer API types should use conditions instead. Phase was essentially a state-machine enumeration field, that contradicted system-design principles and hampered evolution, since adding new enum values breaks backward compatibility. Rather than encouraging clients to infer implicit properties from phases, we prefer to explicitly expose the individual conditions that clients need to monitor. Conditions also have the benefit that it is possible to create some conditions with uniform meaning across all resource types, while still exposing others that are unique to specific resource types. See #7856 for more details and discussion.\nIn condition types, and everywhere else they appear in the API, Reason is intended to be a one-word, CamelCase representation of the category of cause of the current status, and Message is intended to be a human-readable phrase or sentence, which may contain specific details of the individual occurrence. Reason is intended to be used in concise output, such as one-line kubectl get output, and in summarizing occurrences of causes, whereas Message is intended to be presented to users in detailed status explanations, such as kubectl describe output.\nHistorical information status (e.g., last transition time, failure counts) is only provided with reasonable effort, and is not guaranteed to not be lost.\nStatus information that may be large (especially proportional in size to collections of other resources, such as lists of references to other objects \u0026ndash; see below) and/or rapidly changing, such as resource usage, should be put into separate objects, with possibly a reference from the original object. This helps to ensure that GETs and watch remain reasonably efficient for the majority of clients, which may not need that data.\nSome resources report the observedGeneration, which is the generation most recently observed by the component responsible for acting upon changes to the desired state of the resource. This can be used, for instance, to ensure that the reported status reflects the most recent desired status.\nReferences to related objects #  References to loosely coupled sets of objects, such as pods overseen by a replication controller, are usually best referred to using a label selector. In order to ensure that GETs of individual objects remain bounded in time and space, these sets may be queried via separate API queries, but will not be expanded in the referring object\u0026rsquo;s status.\nReferences to specific objects, especially specific resource versions and/or specific fields of those objects, are specified using the ObjectReference type (or other types representing strict subsets of it). Unlike partial URLs, the ObjectReference type facilitates flexible defaulting of fields from the referring object or other contextual information.\nReferences in the status of the referee to the referrer may be permitted, when the references are one-to-one and do not need to be frequently updated, particularly in an edge-based manner.\nLists of named subobjects preferred over maps #  Discussed in #2004 and elsewhere. There are no maps of subobjects in any API objects. Instead, the convention is to use a list of subobjects containing name fields.\nFor example:\nports: - name: www containerPort: 80 vs.\nports: www: containerPort: 80 This rule maintains the invariant that all JSON/YAML keys are fields in API objects. The only exceptions are pure maps in the API (currently, labels, selectors, annotations, data), as opposed to sets of subobjects.\nPrimitive types #   Avoid floating-point values as much as possible, and never use them in spec. Floating-point values cannot be reliably round-tripped (encoded and re-decoded) without changing, and have varying precision and representations across languages and architectures. All numbers (e.g., uint32, int64) are converted to float64 by Javascript and some other languages, so any field which is expected to exceed that either in magnitude or in precision (specifically integer values \u0026gt; 53 bits) should be serialized and accepted as strings. Do not use unsigned integers, due to inconsistent support across languages and libraries. Just validate that the integer is non-negative if that\u0026rsquo;s the case. Do not use enums. Use aliases for string instead (e.g., NodeConditionType). Look at similar fields in the API (e.g., ports, durations) and follow the conventions of existing fields. All public integer fields MUST use the Go (u)int32 or Go (u)int64 types, not (u)int (which is ambiguous depending on target platform). Internal types may use (u)int. Think twice about bool fields. Many ideas start as boolean but eventually trend towards a small set of mutually exclusive options. Plan for future expansions by describing the policy options explicitly as a string type alias (e.g. TerminationMessagePolicy).  Constants #  Some fields will have a list of allowed values (enumerations). These values will be strings, and they will be in CamelCase, with an initial uppercase letter. Examples: ClusterFirst, Pending, ClientIP.\nUnions #  Sometimes, at most one of a set of fields can be set. For example, the [volumes] field of a PodSpec has 17 different volume type-specific fields, such as nfs and iscsi. All fields in the set should be Optional.\nSometimes, when a new type is created, the api designer may anticipate that a union will be needed in the future, even if only one field is allowed initially. In this case, be sure to make the field Optional In the validation, you may still return an error if the sole field is unset. Do not set a default value for that field.\nLists and Simple kinds #  Every list or simple kind SHOULD have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n resourceVersion: a string that identifies the common version of the objects returned by in a list. This value MUST be treated as opaque by clients and passed unmodified back to the server. A resource version is only valid within a single namespace on a single kind of resource.  Every simple kind returned by the server, and any simple kind sent to the server that must support idempotency or optimistic concurrency should return this value. Since simple resources are often used as input alternate actions that modify objects, the resource version of the simple resource should correspond to the resource version of the object.\nDiffering Representations #  An API may represent a single entity in different ways for different clients, or transform an object after certain transitions in the system occur. In these cases, one request object may have two representations available as different resources, or different kinds.\nAn example is a Service, which represents the intent of the user to group a set of pods with common behavior on common ports. When Kubernetes detects a pod matches the service selector, the IP address and port of the pod are added to an Endpoints resource for that Service. The Endpoints resource exists only if the Service exists, but exposes only the IPs and ports of the selected pods. The full service is represented by two distinct resources - under the original Service resource the user created, as well as in the Endpoints resource.\nAs another example, a \u0026ldquo;pod status\u0026rdquo; resource may accept a PUT with the \u0026ldquo;pod\u0026rdquo; kind, with different rules about what fields may be changed.\nFuture versions of Kubernetes may allow alternative encodings of objects beyond JSON.\nVerbs on Resources #  API resources should use the traditional REST pattern:\n GET / - Retrieve a list of type , e.g. GET /pods returns a list of Pods. POST / - Create a new resource from the JSON object provided by the client. GET // - Retrieves a single resource with the given name, e.g. GET /pods/first returns a Pod named \u0026lsquo;first\u0026rsquo;. Should be constant time, and the resource should be bounded in size. DELETE // - Delete the single resource with the given name. DeleteOptions may specify gracePeriodSeconds, the optional duration in seconds before the object should be deleted. Individual kinds may declare fields which provide a default grace period, and different kinds may have differing kind-wide default grace periods. A user provided grace period overrides a default grace period, including the zero grace period (\u0026ldquo;now\u0026rdquo;). PUT // - Update or create the resource with the given name with the JSON object provided by the client. PATCH // - Selectively modify the specified fields of the resource. See more information below. GET /\u0026amp;watch=true - Receive a stream of JSON objects corresponding to changes made to any resource of the given kind over time.  PATCH operations #  The API supports three different PATCH operations, determined by their corresponding Content-Type header:\n  JSON Patch,\nContent-Type: application/json-patch+json  As defined in RFC6902, a JSON Patch is a sequence of operations that are executed on the resource, e.g. {\u0026quot;op\u0026quot;: \u0026quot;add\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/a/b/c\u0026quot;, \u0026quot;value\u0026quot;: [ \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot; ]}. For more details on how to use JSON Patch, see the RFC.    Merge Patch,\nContent-Type: application/merge-patch+json  As defined in RFC7386, a Merge Patch is essentially a partial representation of the resource. The submitted JSON is \u0026ldquo;merged\u0026rdquo; with the current resource to create a new one, then the new one is saved. For more details on how to use Merge Patch, see the RFC.    Strategic Merge Patch,\nContent-Type: application/strategic-merge-patch+json  Strategic Merge Patch is a custom implementation of Merge Patch. For a detailed explanation of how it works and why it needed to be introduced, see here.    Idempotency #  All compatible Kubernetes APIs MUST support \u0026ldquo;name idempotency\u0026rdquo; and respond with an HTTP status code 409 when a request is made to POST an object that has the same name as an existing object in the system. See the identifiers docs for details.\nNames generated by the system may be requested using metadata.generateName. GenerateName indicates that the name should be made unique by the server prior to persisting it. A non-empty value for the field indicates the name will be made unique (and the name returned to the client will be different than the name passed). The value of this field will be combined with a unique suffix on the server if the Name field has not been provided. The provided value must be valid within the rules for Name, and may be truncated by the length of the suffix required to make the value unique on the server. If this field is specified, and Name is not present, the server will NOT return a 409 if the generated name exists - instead, it will either return 201 Created or 504 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\nOptional vs. Required #  Fields must be either optional or required.\nOptional fields have the following properties:\n They have the +optional comment tag in Go. They are a pointer type in the Go definition (e.g. AwesomeFlag *SomeFlag) or have a built-in nil value (e.g. maps and slices). The API server should allow POSTing and PUTing a resource with this field unset.  In most cases, optional fields should also have the omitempty struct tag (the omitempty option specifies that the field should be omitted from the json encoding if the field has an empty value). However, If you want to have different logic for an optional field which is not provided vs. provided with empty values, do not use omitempty (e.g. https://github.com/kubernetes/kubernetes/issues/34641).\nNote that for backward compatibility, any field that has the omitempty struct tag will be considered to be optional, but this may change in the future and having the +optional comment tag is highly recommended.\nRequired fields have the opposite properties, namely:\n They do not have an +optional comment tag. They do not have an omitempty struct tag. They are not a pointer type in the Go definition (e.g. AnotherFlag SomeFlag). The API server should not allow POSTing or PUTing a resource with this field unset.  Using the +optional or the omitempty tag causes OpenAPI documentation to reflect that the field is optional.\nUsing a pointer allows distinguishing unset from the zero value for that type. There are some cases where, in principle, a pointer is not needed for an optional field since the zero value is forbidden, and thus implies unset. There are examples of this in the codebase. However:\n it can be difficult for implementors to anticipate all cases where an empty value might need to be distinguished from a zero value structs are not omitted from encoder output even where omitempty is specified, which is messy; having a pointer consistently imply optional is clearer for users of the Go language client, and any other clients that use corresponding types  Therefore, we ask that pointers always be used with optional fields that do not have a built-in nil value.\nDefaulting #  Default resource values are API version-specific, and they are applied during the conversion from API-versioned declarative configuration to internal objects representing the desired state (Spec) of the resource. Subsequent GETs of the resource will include the default values explicitly.\nIncorporating the default values into the Spec ensures that Spec depicts the full desired state so that it is easier for the system to determine how to achieve the state, and for the user to know what to anticipate.\nAPI version-specific default values are set by the API server.\nLate Initialization #  Late initialization is when resource fields are set by a system controller after an object is created/updated.\nFor example, the scheduler sets the pod.spec.nodeName field after the pod is created.\nLate-initializers should only make the following types of modifications:\n Setting previously unset fields Adding keys to maps Adding values to arrays which have mergeable semantics (patchStrategy:\u0026quot;merge\u0026quot; attribute in the type definition).  These conventions:\n allow a user (with sufficient privilege) to override any system-default behaviors by setting the fields that would otherwise have been defaulted. enables updates from users to be merged with changes made during late initialization, using strategic merge patch, as opposed to clobbering the change. allow the component which does the late-initialization to use strategic merge patch, which facilitates composition and concurrency of such components.  Although the apiserver Admission Control stage acts prior to object creation, Admission Control plugins should follow the Late Initialization conventions too, to allow their implementation to be later moved to a \u0026lsquo;controller\u0026rsquo;, or to client libraries.\nConcurrency Control and Consistency #  Kubernetes leverages the concept of resource versions to achieve optimistic concurrency. All Kubernetes resources have a \u0026ldquo;resourceVersion\u0026rdquo; field as part of their metadata. This resourceVersion is a string that identifies the internal version of an object that can be used by clients to determine when objects have changed. When a record is about to be updated, it\u0026rsquo;s version is checked against a pre-saved value, and if it doesn\u0026rsquo;t match, the update fails with a StatusConflict (HTTP status code 409).\nThe resourceVersion is changed by the server every time an object is modified. If resourceVersion is included with the PUT operation the system will verify that there have not been other successful mutations to the resource during a read/modify/write cycle, by verifying that the current value of resourceVersion matches the specified value.\nThe resourceVersion is currently backed by etcd\u0026rsquo;s modifiedIndex. However, it\u0026rsquo;s important to note that the application should not rely on the implementation details of the versioning system maintained by Kubernetes. We may change the implementation of resourceVersion in the future, such as to change it to a timestamp or per-object counter.\nThe only way for a client to know the expected value of resourceVersion is to have received it from the server in response to a prior operation, typically a GET. This value MUST be treated as opaque by clients and passed unmodified back to the server. Clients should not assume that the resource version has meaning across namespaces, different kinds of resources, or different servers. Currently, the value of resourceVersion is set to match etcd\u0026rsquo;s sequencer. You could think of it as a logical clock the API server can use to order requests. However, we expect the implementation of resourceVersion to change in the future, such as in the case we shard the state by kind and/or namespace, or port to another storage system.\nIn the case of a conflict, the correct client action at this point is to GET the resource again, apply the changes afresh, and try submitting again. This mechanism can be used to prevent races like the following:\nClient #1 Client #2 GET Foo GET Foo Set Foo.Bar = \u0026quot;one\u0026quot; Set Foo.Baz = \u0026quot;two\u0026quot; PUT Foo PUT Foo When these sequences occur in parallel, either the change to Foo.Bar or the change to Foo.Baz can be lost.\nOn the other hand, when specifying the resourceVersion, one of the PUTs will fail, since whichever write succeeds changes the resourceVersion for Foo.\nresourceVersion may be used as a precondition for other operations (e.g., GET, DELETE) in the future, such as for read-after-write consistency in the presence of caching.\n\u0026ldquo;Watch\u0026rdquo; operations specify resourceVersion using a query parameter. It is used to specify the point at which to begin watching the specified resources. This may be used to ensure that no mutations are missed between a GET of a resource (or list of resources) and a subsequent Watch, even if the current version of the resource is more recent. This is currently the main reason that list operations (GET on a collection) return resourceVersion.\nSerialization Format #  APIs may return alternative representations of any resource in response to an Accept header or under alternative endpoints, but the default serialization for input and output of API responses MUST be JSON.\nA protobuf encoding is also accepted for built-in resources. As proto is not self-describing, there is an envelope wrapper which describes the type of the contents.\nAll dates should be serialized as RFC3339 strings.\nUnits #  Units must either be explicit in the field name (e.g., timeoutSeconds), or must be specified as part of the value (e.g., resource.Quantity). Which approach is preferred is TBD, though currently we use the fooSeconds convention for durations.\nDuration fields must be represented as integer fields with units being part of the field name (e.g. leaseDurationSeconds). We don\u0026rsquo;t use Duration in the API since that would require clients to implement go-compatible parsing.\nSelecting Fields #  Some APIs may need to identify which field in a JSON object is invalid, or to reference a value to extract from a separate resource. The current recommendation is to use standard JavaScript syntax for accessing that field, assuming the JSON object was transformed into a JavaScript object, without the leading dot, such as metadata.name.\nExamples:\n Find the field \u0026ldquo;current\u0026rdquo; in the object \u0026ldquo;state\u0026rdquo; in the second item in the array \u0026ldquo;fields\u0026rdquo;: fields[1].state.current  Object references #  Object references should either be called fooName if referring to an object of kind Foo by just the name (within the current namespace, if a namespaced resource), or should be called fooRef, and should contain a subset of the fields of the ObjectReference type.\nTODO: Plugins, extensions, nested kinds, headers\nHTTP Status codes #  The server will respond with HTTP status codes that match the HTTP spec. See the section below for a breakdown of the types of status codes the server will send.\nThe following HTTP status codes may be returned by the API.\nSuccess codes #    200 StatusOK  Indicates that the request completed successfully.    201 StatusCreated  Indicates that the request to create kind completed successfully.    204 StatusNoContent  Indicates that the request completed successfully, and the response contains no body. Returned in response to HTTP OPTIONS requests.    Error codes #   307 StatusTemporaryRedirect  Indicates that the address for the requested resource has changed. Suggested client recovery behavior:  Follow the redirect.     400 StatusBadRequest  Indicates the requested is invalid. Suggested client recovery behavior:  Do not retry. Fix the request.     401 StatusUnauthorized  Indicates that the server can be reached and understood the request, but refuses to take any further action, because the client must provide authorization. If the client has provided authorization, the server is indicating the provided authorization is unsuitable or invalid. Suggested client recovery behavior:  If the user has not supplied authorization information, prompt them for the appropriate credentials. If the user has supplied authorization information, inform them their credentials were rejected and optionally prompt them again.     403 StatusForbidden  Indicates that the server can be reached and understood the request, but refuses to take any further action, because it is configured to deny access for some reason to the requested resource by the client. Suggested client recovery behavior:  Do not retry. Fix the request.     404 StatusNotFound  Indicates that the requested resource does not exist. Suggested client recovery behavior:  Do not retry. Fix the request.     405 StatusMethodNotAllowed  Indicates that the action the client attempted to perform on the resource was not supported by the code. Suggested client recovery behavior:  Do not retry. Fix the request.     409 StatusConflict  Indicates that either the resource the client attempted to create already exists or the requested update operation cannot be completed due to a conflict. Suggested client recovery behavior:  If creating a new resource:  Either change the identifier and try again, or GET and compare the fields in the pre-existing object and issue a PUT/update to modify the existing object.   If updating an existing resource:  See Conflict from the status response section below on how to retrieve more information about the nature of the conflict. GET and compare the fields in the pre-existing object, merge changes (if still valid according to preconditions), and retry with the updated request (including ResourceVersion).       410 StatusGone  Indicates that the item is no longer available at the server and no forwarding address is known. Suggested client recovery behavior:  Do not retry. Fix the request.     422 StatusUnprocessableEntity  Indicates that the requested create or update operation cannot be completed due to invalid data provided as part of the request. Suggested client recovery behavior:  Do not retry. Fix the request.     429 StatusTooManyRequests  Indicates that the either the client rate limit has been exceeded or the server has received more requests then it can process. Suggested client recovery behavior:  Read the Retry-After HTTP header from the response, and wait at least that long before retrying.     500 StatusInternalServerError  Indicates that the server can be reached and understood the request, but either an unexpected internal error occurred and the outcome of the call is unknown, or the server cannot complete the action in a reasonable time (this may be due to temporary server load or a transient communication issue with another server). Suggested client recovery behavior:  Retry with exponential backoff.     503 StatusServiceUnavailable  Indicates that required service is unavailable. Suggested client recovery behavior:  Retry with exponential backoff.     504 StatusServerTimeout  Indicates that the request could not be completed within the given time. Clients can get this response ONLY when they specified a timeout param in the request. Suggested client recovery behavior:  Increase the value of the timeout param and retry with exponential backoff.      Response Status Kind #  Kubernetes will always return the Status kind from any API endpoint when an error occurs. Clients SHOULD handle these types of objects when appropriate.\nA Status kind will be returned by the API in two cases:\n When an operation is not successful (i.e. when the server would return a non 2xx HTTP status code). When a HTTP DELETE call is successful.  The status object is encoded as JSON and provided as the body of the response. The status object contains fields for humans and machine consumers of the API to get more detailed information for the cause of the failure. The information in the status object supplements, but does not override, the HTTP status code\u0026rsquo;s meaning. When fields in the status object have the same meaning as generally defined HTTP headers and that header is returned with the response, the header should be considered as having higher priority.\nExample:\n$ curl -v -k -H \u0026quot;Authorization: Bearer WhCDvq4VPpYhrcfmF6ei7V9qlbqTubUc\u0026quot; https://10.240.122.184:443/api/v1/namespaces/default/pods/grafana \u0026gt; GET /api/v1/namespaces/default/pods/grafana HTTP/1.1 \u0026gt; User-Agent: curl/7.26.0 \u0026gt; Host: 10.240.122.184 \u0026gt; Accept: */* \u0026gt; Authorization: Bearer WhCDvq4VPpYhrcfmF6ei7V9qlbqTubUc \u0026gt; \u0026lt; HTTP/1.1 404 Not Found \u0026lt; Content-Type: application/json \u0026lt; Date: Wed, 20 May 2015 18:10:42 GMT \u0026lt; Content-Length: 232 \u0026lt; { \u0026quot;kind\u0026quot;: \u0026quot;Status\u0026quot;, \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;metadata\u0026quot;: {}, \u0026quot;status\u0026quot;: \u0026quot;Failure\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;pods \\\u0026quot;grafana\\\u0026quot; not found\u0026quot;, \u0026quot;reason\u0026quot;: \u0026quot;NotFound\u0026quot;, \u0026quot;details\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;grafana\u0026quot;, \u0026quot;kind\u0026quot;: \u0026quot;pods\u0026quot; }, \u0026quot;code\u0026quot;: 404 } status field contains one of two possible values:\n Success Failure  message may contain human-readable description of the error\nreason may contain a machine-readable, one-word, CamelCase description of why this operation is in the Failure status. If this value is empty there is no information available. The reason clarifies an HTTP status code but does not override it.\ndetails may contain extended data associated with the reason. Each reason may define its own extended details. This field is optional and the data returned is not guaranteed to conform to any schema except that defined by the reason type.\nPossible values for the reason and details fields:\n  BadRequest\n Indicates that the request itself was invalid, because the request doesn\u0026rsquo;t make any sense, for example deleting a read-only object. This is different than status reason Invalid above which indicates that the API call could possibly succeed, but the data was invalid. API calls that return BadRequest can never succeed. Http status code: 400 StatusBadRequest    Unauthorized\n  Indicates that the server can be reached and understood the request, but refuses to take any further action without the client providing appropriate authorization. If the client has provided authorization, this error indicates the provided credentials are insufficient or invalid.\n  Details (optional):\n  kind string  The kind attribute of the unauthorized resource (on some operations may differ from the requested resource).    name string  The identifier of the unauthorized resource.      HTTP status code: 401 StatusUnauthorized\n    Forbidden\n  Indicates that the server can be reached and understood the request, but refuses to take any further action, because it is configured to deny access for some reason to the requested resource by the client.\n  Details (optional):\n  kind string  The kind attribute of the forbidden resource (on some operations may differ from the requested resource).    name string  The identifier of the forbidden resource.      HTTP status code: 403 StatusForbidden\n    NotFound\n  Indicates that one or more resources required for this operation could not be found.\n  Details (optional):\n  kind string  The kind attribute of the missing resource (on some operations may differ from the requested resource).    name string  The identifier of the missing resource.      HTTP status code: 404 StatusNotFound\n    AlreadyExists\n  Indicates that the resource you are creating already exists.\n  Details (optional):\n  kind string  The kind attribute of the conflicting resource.    name string  The identifier of the conflicting resource.      HTTP status code: 409 StatusConflict\n    Conflict\n Indicates that the requested update operation cannot be completed due to a conflict. The client may need to alter the request. Each resource may define custom details that indicate the nature of the conflict. HTTP status code: 409 StatusConflict    Invalid\n  Indicates that the requested create or update operation cannot be completed due to invalid data provided as part of the request.\n  Details (optional):\n  kind string  the kind attribute of the invalid resource    name string  the identifier of the invalid resource    causes  One or more StatusCause entries indicating the data in the provided resource that was invalid. The reason, message, and field attributes will be set.      HTTP status code: 422 StatusUnprocessableEntity\n    Timeout\n Indicates that the request could not be completed within the given time. Clients may receive this response if the server has decided to rate limit the client, or if the server is overloaded and cannot process the request at this time. Http status code: 429 TooManyRequests The server should set the Retry-After HTTP header and return retryAfterSeconds in the details field of the object. A value of 0 is the default.    ServerTimeout\n  Indicates that the server can be reached and understood the request, but cannot complete the action in a reasonable time. This maybe due to temporary server load or a transient communication issue with another server.\n  Details (optional):\n  kind string  The kind attribute of the resource being acted on.    name string  The operation that is being attempted.        The server should set the Retry-After HTTP header and return retryAfterSeconds in the details field of the object. A value of 0 is the default.\n  Http status code: 504 StatusServerTimeout\n    MethodNotAllowed\n Indicates that the action the client attempted to perform on the resource was not supported by the code. For instance, attempting to delete a resource that can only be created. API calls that return MethodNotAllowed can never succeed. Http status code: 405 StatusMethodNotAllowed    InternalError\n  Indicates that an internal error occurred, it is unexpected and the outcome of the call is unknown.\n  Details (optional):\n  causes  The original error.      Http status code: 500 StatusInternalServerError code may contain the suggested HTTP return code for this status.\n    Events #  Events are complementary to status information, since they can provide some historical information about status and occurrences in addition to current or previous status. Generate events for situations users or administrators should be alerted about.\nChoose a unique, specific, short, CamelCase reason for each event category. For example, FreeDiskSpaceInvalid is a good event reason because it is likely to refer to just one situation, but Started is not a good reason because it doesn\u0026rsquo;t sufficiently indicate what started, even when combined with other event fields.\nError creating foo or Error creating foo %s would be appropriate for an event message, with the latter being preferable, since it is more informational.\nAccumulate repeated events in the client, especially for frequent events, to reduce data volume, load on the system, and noise exposed to users.\nNaming conventions #    Go field names must be CamelCase. JSON field names must be camelCase. Other than capitalization of the initial letter, the two should almost always match. No underscores nor dashes in either.\n  Field and resource names should be declarative, not imperative (DoSomething, SomethingDoer, DoneBy, DoneAt).\n  Use Node where referring to the node resource in the context of the cluster. Use Host where referring to properties of the individual physical/virtual system, such as hostname, hostPath, hostNetwork, etc.\n  FooController is a deprecated kind naming convention. Name the kind after the thing being controlled instead (e.g., Job rather than JobController).\n  The name of a field that specifies the time at which something occurs should be called somethingTime. Do not use stamp (e.g., creationTimestamp).\n  We use the\nfooSeconds convention for durations, as discussed in the\nunits subsection\n.\n fooPeriodSeconds is preferred for periodic intervals and other waiting periods (e.g., over fooIntervalSeconds). fooTimeoutSeconds is preferred for inactivity/unresponsiveness deadlines. fooDeadlineSeconds is preferred for activity completion deadlines.    Do not use abbreviations in the API, except where they are extremely commonly used, such as \u0026ldquo;id\u0026rdquo;, \u0026ldquo;args\u0026rdquo;, or \u0026ldquo;stdin\u0026rdquo;.\n  Acronyms should similarly only be used when extremely commonly known. All letters in the acronym should have the same case, using the appropriate case for the situation. For example, at the beginning of a field name, the acronym should be all lowercase, such as \u0026ldquo;httpGet\u0026rdquo;. Where used as a constant, all letters should be uppercase, such as \u0026ldquo;TCP\u0026rdquo; or \u0026ldquo;UDP\u0026rdquo;.\n  The name of a field referring to another resource of kind Foo by name should be called fooName. The name of a field referring to another resource of kind Foo by ObjectReference (or subset thereof) should be called fooRef.\n  More generally, include the units and/or type in the field name if they could be ambiguous and they are not specified by the value or value type.\n  The name of a field expressing a boolean property called \u0026lsquo;fooable\u0026rsquo; should be called Fooable, not IsFooable.\n  Namespace Names #   The name of a namespace must be a DNS_LABEL. The kube- prefix is reserved for Kubernetes system namespaces, e.g. kube-system and kube-public. See the namespace docs for more information.  Label, selector, and annotation conventions #  Labels are the domain of users. They are intended to facilitate organization and management of API resources using attributes that are meaningful to users, as opposed to meaningful to the system. Think of them as user-created mp3 or email inbox labels, as opposed to the directory structure used by a program to store its data. The former enables the user to apply an arbitrary ontology, whereas the latter is implementation-centric and inflexible. Users will use labels to select resources to operate on, display label values in CLI/UI columns, etc. Users should always retain full power and flexibility over the label schemas they apply to labels in their namespaces.\nHowever, we should support conveniences for common cases by default. For example, what we now do in ReplicationController is automatically set the RC\u0026rsquo;s selector and labels to the labels in the pod template by default, if they are not already set. That ensures that the selector will match the template, and that the RC can be managed using the same labels as the pods it creates. Note that once we generalize selectors, it won\u0026rsquo;t necessarily be possible to unambiguously generate labels that match an arbitrary selector.\nIf the user wants to apply additional labels to the pods that it doesn\u0026rsquo;t select upon, such as to facilitate adoption of pods or in the expectation that some label values will change, they can set the selector to a subset of the pod labels. Similarly, the RC\u0026rsquo;s labels could be initialized to a subset of the pod template\u0026rsquo;s labels, or could include additional/different labels.\nFor disciplined users managing resources within their own namespaces, it\u0026rsquo;s not that hard to consistently apply schemas that ensure uniqueness. One just needs to ensure that at least one value of some label key in common differs compared to all other comparable resources. We could/should provide a verification tool to check that. However, development of conventions similar to the examples in Labels make uniqueness straightforward. Furthermore, relatively narrowly used namespaces (e.g., per environment, per application) can be used to reduce the set of resources that could potentially cause overlap.\nIn cases where users could be running misc. examples with inconsistent schemas, or where tooling or components need to programmatically generate new objects to be selected, there needs to be a straightforward way to generate unique label sets. A simple way to ensure uniqueness of the set is to ensure uniqueness of a single label value, such as by using a resource name, uid, resource hash, or generation number.\nProblems with uids and hashes, however, include that they have no semantic meaning to the user, are not memorable nor readily recognizable, and are not predictable. Lack of predictability obstructs use cases such as creation of a replication controller from a pod, such as people want to do when exploring the system, bootstrapping a self-hosted cluster, or deletion and re-creation of a new RC that adopts the pods of the previous one, such as to rename it. Generation numbers are more predictable and much clearer, assuming there is a logical sequence. Fortunately, for deployments that\u0026rsquo;s the case. For jobs, use of creation timestamps is common internally. Users should always be able to turn off auto-generation, in order to permit some of the scenarios described above. Note that auto-generated labels will also become one more field that needs to be stripped out when cloning a resource, within a namespace, in a new namespace, in a new cluster, etc., and will need to be ignored around when updating a resource via patch or read-modify-write sequence.\nInclusion of a system prefix in a label key is fairly hostile to UX. A prefix is only necessary in the case that the user cannot choose the label key, in order to avoid collisions with user-defined labels. However, I firmly believe that the user should always be allowed to select the label keys to use on their resources, so it should always be possible to override default label keys.\nTherefore, resources supporting auto-generation of unique labels should have a uniqueLabelKey field, so that the user could specify the key if they wanted to, but if unspecified, it could be set by default, such as to the resource type, like job, deployment, or replicationController. The value would need to be at least spatially unique, and perhaps temporally unique in the case of job.\nAnnotations have very different intended usage from labels. They are primarily generated and consumed by tooling and system extensions, or are used by end-users to engage non-standard behavior of components. For example, an annotation might be used to indicate that an instance of a resource expects additional handling by non-kubernetes controllers. Annotations may carry arbitrary payloads, including JSON documents. Like labels, annotation keys can be prefixed with a governing domain (e.g. example.com/key-name). Unprefixed keys (e.g. key-name) are reserved for end-users. Third-party components must use prefixed keys. Key prefixes under the \u0026ldquo;kubernetes.io\u0026rdquo; and \u0026ldquo;k8s.io\u0026rdquo; domains are reserved for use by the kubernetes project and must not be used by third-parties.\nIn early versions of Kubernetes, some in-development features represented new API fields as annotations, generally with the form something.alpha.kubernetes.io/name or something.beta.kubernetes.io/name (depending on our confidence in it). This pattern is deprecated. Some such annotations may still exist, but no new annotations may be defined. New API fields are now developed as regular fields.\nOther advice regarding use of labels, annotations, taints, and other generic map keys by Kubernetes components and tools:\n Key names should be all lowercase, with words separated by dashes instead of camelCase  For instance, prefer foo.kubernetes.io/foo-bar over foo.kubernetes.io/fooBar, prefer desired-replicas over DesiredReplicas   Unprefixed keys are reserved for end-users. All other labels and annotations must be prefixed. Key prefixes under \u0026ldquo;kubernetes.io\u0026rdquo; and \u0026ldquo;k8s.io\u0026rdquo; are reserved for the Kubernetes project.  Such keys are effectively part of the kubernetes API and may be subject to deprecation and compatibility policies.   Key names, including prefixes, should be precise enough that a user could plausibly understand where it came from and what it is for. Key prefixes should carry as much context as possible.  For instance, prefer subsystem.kubernetes.io/parameter over kubernetes.io/subsystem-parameter   Use annotations to store API extensions that the controller responsible for the resource doesn\u0026rsquo;t need to know about, experimental fields that aren\u0026rsquo;t intended to be generally used API fields, etc. Beware that annotations aren\u0026rsquo;t automatically handled by the API conversion machinery.  WebSockets and SPDY #  Some of the API operations exposed by Kubernetes involve transfer of binary streams between the client and a container, including attach, exec, portforward, and logging. The API therefore exposes certain operations over upgradeable HTTP connections ( described in RFC 2817) via the WebSocket and SPDY protocols. These actions are exposed as subresources with their associated verbs (exec, log, attach, and portforward) and are requested via a GET (to support JavaScript in a browser) and POST (semantically accurate).\nThere are two primary protocols in use today:\n  Streamed channels\nWhen dealing with multiple independent binary streams of data such as the remote execution of a shell command (writing to STDIN, reading from STDOUT and STDERR) or forwarding multiple ports the streams can be multiplexed onto a single TCP connection. Kubernetes supports a SPDY based framing protocol that leverages SPDY channels and a WebSocket framing protocol that multiplexes multiple channels onto the same stream by prefixing each binary chunk with a byte indicating its channel. The WebSocket protocol supports an optional subprotocol that handles base64-encoded bytes from the client and returns base64-encoded bytes from the server and character based channel prefixes (\u0026lsquo;0\u0026rsquo;, \u0026lsquo;1\u0026rsquo;, \u0026lsquo;2\u0026rsquo;) for ease of use from JavaScript in a browser.\n  Streaming response\nThe default log output for a channel of streaming data is an HTTP Chunked Transfer-Encoding, which can return an arbitrary stream of binary data from the server. Browser-based JavaScript is limited in its ability to access the raw data from a chunked response, especially when very large amounts of logs are returned, and in future API calls it may be desirable to transfer large files. The streaming API endpoints support an optional WebSocket upgrade that provides a unidirectional channel from the server to the client and chunks data as binary WebSocket frames. An optional WebSocket subprotocol is exposed that base64 encodes the stream before returning it to the client.\n  Clients should use the SPDY protocols if their clients have native support, or WebSockets as a fallback. Note that WebSockets is susceptible to Head-of-Line blocking and so clients must read and process each message sequentially. In the future, an HTTP/2 implementation will be exposed that deprecates SPDY.\nValidation #  API objects are validated upon receipt by the apiserver. Validation errors are flagged and returned to the caller in a Failure status with reason set to Invalid. In order to facilitate consistent error messages, we ask that validation logic adheres to the following guidelines whenever possible (though exceptional cases will exist).\n Be as precise as possible. Telling users what they CAN do is more useful than telling them what they CANNOT do. When asserting a requirement in the positive, use \u0026ldquo;must\u0026rdquo;. Examples: \u0026ldquo;must be greater than 0\u0026rdquo;, \u0026ldquo;must match regex \u0026lsquo;[a-z]+\u0026rsquo;\u0026rdquo;. Words like \u0026ldquo;should\u0026rdquo; imply that the assertion is optional, and must be avoided. When asserting a formatting requirement in the negative, use \u0026ldquo;must not\u0026rdquo;. Example: \u0026ldquo;must not contain \u0026lsquo;..'\u0026rdquo;. Words like \u0026ldquo;should not\u0026rdquo; imply that the assertion is optional, and must be avoided. When asserting a behavioral requirement in the negative, use \u0026ldquo;may not\u0026rdquo;. Examples: \u0026ldquo;may not be specified when otherField is empty\u0026rdquo;, \u0026ldquo;only name may be specified\u0026rdquo;. When referencing a literal string value, indicate the literal in single-quotes. Example: \u0026ldquo;must not contain \u0026lsquo;..'\u0026rdquo;. When referencing another field name, indicate the name in back-quotes. Example: \u0026ldquo;must be greater than request\u0026rdquo;. When specifying inequalities, use words rather than symbols. Examples: \u0026ldquo;must be less than 256\u0026rdquo;, \u0026ldquo;must be greater than or equal to 0\u0026rdquo;. Do not use words like \u0026ldquo;larger than\u0026rdquo;, \u0026ldquo;bigger than\u0026rdquo;, \u0026ldquo;more than\u0026rdquo;, \u0026ldquo;higher than\u0026rdquo;, etc. When specifying numeric ranges, use inclusive ranges when possible.  "});index.add({'id':53,'href':'/notes/docs/technology/cloud/container/kubernetes/network/calico/','title':"Calico",'section':"Kubernetes 网络",'content':"Calico #  "});index.add({'id':54,'href':'/notes/docs/technology/cloud/container/kubernetes/object/workload/controller/','title':"controller",'section':"作业管理",'content':"Controller #  控制器可以创建和管理多个 Pod，管理副本和上线，并在集群范围内提供自修复能力。\n ReplicaSet #  ReplicationController #  Deployments #  StatefulSets #  DaemonSet #  Jobs #  Garbage Collection #  TTL Controller for Finished Resources #  CronJob #  "});index.add({'id':55,'href':'/notes/docs/technology/cloud/container/docker/','title':"Docker",'section':"容器技术",'content':"Docker #  What #   Docker是一个用于开发，交付和运行应用程序的开放平台。 Docker使您能够将应用程序与基础架构分开，从而可以快速交付软件。 借助Docker，您可以以与管理应用程序相同的方式来管理基础架构。\n  Docker平台 #  Docker提供了在松散隔离的环境（称为容器）中打包和运行应用程序的功能。隔离和安全性使您可以在给定主机上同时运行多个容器。容器重量轻，因为它们不需要管理程序的额外负担，而是直接在主机的内核中运行。这意味着与使用虚拟机相比，可以在给定的硬件组合上运行更多的容器。您甚至可以在实际上是虚拟机的主机中运行Docker容器！\nDocker提供了工具和平台来管理容器的生命周期：\n 使用容器开发应用程序及其支持组件。 容器成为分发和测试您的应用程序的单元。 准备就绪后，可以将应用程序作为容器或协调服务部署到生产环境中。无论您的生产环境是本地数据中心，云提供商还是二者的混合体，其工作原理都相同。   Docker Engine #  Docker Engine是具有这些主要组件的client-server应用程序：\n Docker daemon是一个长时间运行的守护进程 REST API指定程序可以用来与守护程序进行通信并指示其操作的接口 command line interface (CLI) 客户端  CLI使用Docker REST API通过脚本或直接CLI命令来控制Docker守护程序或与Docker守护程序进行交互。许多其他Docker应用程序都使用基础API和CLI。\nDocker daemon 创建和管理Docker对象，例如映像，容器，网络和卷。\n  How #  架构 #    底层技术 #  Namespaces #  Namespace实现对全局系统资源的一种封装隔离\nControl Groups #  CGroup是为了对一组进程进行统一的资源监控和限制\nUnion file systems #  Union file system 实现将不同分支中的文件和目录重叠以形成单个文件系统。\nContainer format #  Docker Engine将Namespace，CGroup和UnionFS组合到一个称为container format的包装器中。 默认容器格式为libcontainer。 将来，Docker可能会通过与BSD Jails或Solaris Zone等技术集成来支持其他容器格式。\n"});index.add({'id':56,'href':'/notes/docs/technology/program/language/golang/','title':"Golang",'section':"编程语言",'content':"Golang #  "});index.add({'id':57,'href':'/notes/docs/technology/network/protocol/http/','title':"HTTP",'section':"网络协议",'content':"HTTP #  HTTP，HyperText Transfer Protocol，超文本传输协议，是一种应用层协议，被广泛应用于互联网。\n "});index.add({'id':58,'href':'/notes/docs/technology/network/protocol/http/http2/','title':"HTTP/2",'section':"HTTP",'content':"HTTP/2 #  设计和技术目标 #  早期版本的 HTTP 协议的设计初衷主要是实现要简单： HTTP/0.9 只用一行协议就启动了万维网；HTTP/1.0 则是对流行的 HTTP/0.9 扩展的一个正式说明；HTTP 1.1 则是 IETF 的一份官方标准；请参阅 HTTP 简史。 因此，HTTP/0.9-1.x 实现了其目的：HTTP 是应用最广泛、采用最多的一个互联网应用协议。\n然而，实现简单是以牺牲应用性能为代价的： HTTP/1.x 客户端需要使用多个连接才能实现并发和缩短延迟；HTTP/1.x 不会压缩请求和响应标头，从而导致不必要的网络流量；HTTP/1.x 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下；等等。\n这些限制并不是致命的，但是随着网络应用的范围、复杂性以及在我们日常生活中的重要性不断增大，它们对网络开发者和用户都造成了巨大负担，而这正是 HTTP/2 要致力于解决的：\n HTTP/2 通过支持标头字段压缩和在同一连接上 进行多个并发交换，让应用更有效地利用网络资源，减少 感知的延迟时间。具体来说，它可以对同一连接上的请求和响应消息进行交错 发送并为 HTTP 标头字段使用 有效编码。 \u0026gt; HTTP/2 还允许为请求设置优先级，让更重要的请求更快速地完成，从而进一步 提升性能。\n出台的协议更有利于网络，因为与 HTTP/1.x 相比，可以使用更少的 TCP 连接。 \u0026gt; 这意味着与其他流的竞争减小，并且连接的持续时间变长，这些特性反过来提高 了可用网络容量的利用率。 最后，HTTP/2 还可以通过使用二进制消息分帧对消息进行更高效 的处理。 （超文本传输协议版本 2，草案 17）\n 需要注意的是，HTTP/2 仍是对之前 HTTP 标准的扩展，而非替代。 HTTP 的应用语义不变，提供的功能不变，HTTP 方法、状态代码、URI 和标头字段等这些核心概念也不变。 这些方面的变化都不在 HTTP/2 考虑之列。 虽然高级 API 保持不变，仍有必要了解低级变更如何解决了之前协议的性能限制。 我们来简单了解一下二进制分帧层及其功能。\n二进制分帧层 #  HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。\n 这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。\n这样一来，客户端和服务器为了相互理解，都必须使用新的二进制编码机制：HTTP/1.x 客户端无法理解只支持 HTTP/2 的服务器，反之亦然。 不过不要紧，现有的应用不必担心这些变化，因为客户端和服务器会替我们完成必要的分帧工作。\n数据流、消息和帧 #  新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。 为了说明这个过程，我们需要了解 HTTP/2 的三个概念：\n 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。  这些概念的关系总结如下：\n 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。   简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。\n请求与响应复用 #  在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接（请参阅 使用多个 TCP 连接）。 这是 HTTP/1.x 交付模型的直接结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。 更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。\nHTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。\n 快照捕捉了同一个连接内并行的多个数据流。 客户端正在向服务器传输一个 DATA 帧（数据流 5），与此同时，服务器正向客户端交错发送数据流 1 和数据流 3 的一系列帧。因此，一个连接上同时有三个并行数据流。\n将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP 2 最重要的一项增强。事实上，这个机制会在整个网络技术栈中引发一系列连锁反应，从而带来巨大的性能提升，让我们可以：\n 并行交错地发送多个请求，请求之间互不影响。 并行交错地发送多个响应，响应之间互不干扰。 使用一个连接并行发送多个请求和响应。 不必再为绕过 HTTP/1.x 限制而做很多工作（请参阅 针对 HTTP/1.x 进行优化，例如级联文件、image sprites 和域名分片。 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间。 等等…  HTTP/2 中的新二进制分帧层解决了 HTTP/1.x 中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。 结果，应用速度更快、开发更简单、部署成本更低。\n数据流优先级 #  将 HTTP 消息分解为很多独立的帧之后，我们就可以复用多个数据流中的帧，客户端和服务器交错发送和传输这些帧的顺序就成为关键的性能决定因素。 为了做到这一点，HTTP/2 标准允许每个数据流都有一个关联的权重和依赖关系：\n 可以向每个数据流分配一个介于 1 至 256 之间的整数。 每个数据流与其他数据流之间可以存在显式依赖关系。  数据流依赖关系和权重的组合让客户端可以构建和传递“优先级树”，表明它倾向于如何接收响应。 反过来，服务器可以使用此信息通过控制 CPU、内存和其他资源的分配设定数据流处理的优先级，在资源数据可用之后，带宽分配可以确保将高优先级响应以最优方式传输至客户端。\n HTTP/2 内的数据流依赖关系通过将另一个数据流的唯一标识符作为父项引用进行声明；如果忽略标识符，相应数据流将依赖于“根数据流”。 声明数据流依赖关系指出，应尽可能先向父数据流分配资源，然后再向其依赖项分配资源。 换句话说，“请先处理和传输响应 D，然后再处理和传输响应 C”。\n共享相同父项的数据流（即，同级数据流）应按其权重比例分配资源。 例如，如果数据流 A 的权重为 12，其同级数据流 B 的权重为 4，那么要确定每个数据流应接收的资源比例，请执行以下操作：\n 将所有权重求和：4 + 12 = 16 将每个数据流权重除以总权重：A = 12/16, B = 4/16  因此，数据流 A 应获得四分之三的可用资源，数据流 B 应获得四分之一的可用资源；数据流 B 获得的资源是数据流 A 所获资源的三分之一。\n我们来看一下上图中的其他几个操作示例。 从左到右依次为：\n 数据流 A 和数据流 B 都没有指定父依赖项，依赖于隐式“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 依赖于根数据流；C 依赖于 D。 因此，D 应先于 C 获得完整资源分配。 权重不重要，因为 C 的依赖关系拥有更高的优先级。 数据流 D 应先于 C 获得完整资源分配；C 应先于 A 和 B 获得完整资源分配；数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 应先于 E 和 C 获得完整资源分配；E 和 C 应先于 A 和 B 获得相同的资源分配；A 和 B 应基于其权重获得比例分配。  如上面的示例所示，数据流依赖关系和权重的组合明确表达了资源优先级，这是一种用于提升浏览性能的关键功能，网络中拥有多种资源类型，它们的依赖关系和权重各不相同。 不仅如此，HTTP/2 协议还允许客户端随时更新这些优先级，进一步优化了浏览器性能。 换句话说，我们可以根据用户互动和其他信号更改依赖关系和重新分配权重。\n注：数据流依赖关系和权重表示传输优先级，而不是要求，因此不能保证特定的处理或传输顺序。 即，客户端无法强制服务器通过数据流优先级以特定顺序处理数据流。 尽管这看起来违反直觉，但却是一种必要行为。 我们不希望在优先级较高的资源受到阻止时，还阻止服务器处理优先级较低的资源。\n每个来源一个连接 #  有了新的分帧机制后，HTTP/2 不再依赖多个 TCP 连接去并行复用数据流；每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别设定优先级。 因此，所有 HTTP/2 连接都是永久的，而且仅需要每个来源一个连接，随之带来诸多性能优势。\n SPDY 和 HTTP/2 的杀手级功能是，可以在一个拥塞受到良好控制的通道上任意进行复用。 这一功能的重要性和良好运行状况让我吃惊。 我喜欢的一个非常不错的指标是连接拆分，这些拆分仅承载一个 HTTP 事务（并因此让该事务承担所有开销）。 对于 HTTP/1，我们 74% 的活动连接仅承载一个事务 - 永久连接并不如我们所有人希望的那般有用。 但是在 HTTP/2 中，这一比例锐减至 25%。 这是在减少开销方面获得的巨大成效。 （HTTP/2 登陆 Firefox，Patrick McManus）\n 大多数 HTTP 传输都是短暂且急促的，而 TCP 则针对长时间的批量数据传输进行了优化。 通过重用相同的连接，HTTP/2 既可以更有效地利用每个 TCP 连接，也可以显著降低整体协议开销。 不仅如此，使用更少的连接还可以减少占用的内存和处理空间，也可以缩短完整连接路径（即，客户端、可信中介和源服务器之间的路径） 这降低了整体运行成本并提高了网络利用率和容量。 因此，迁移到 HTTP/2 不仅可以减少网络延迟，还有助于提高通量和降低运行成本。\n注：连接数量减少对提升 HTTPS 部署的性能来说是一项特别重要的功能：可以减少开销较大的 TLS 连接数、提升会话重用率，以及从整体上减少所需的客户端和服务器资源。\n流控制 #  流控制是一种阻止发送方向接收方发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常繁忙、处于较高的负载之下，也可能仅仅希望为特定数据流分配固定量的资源。 例如，客户端可能请求了一个具有较高优先级的大型视频流，但是用户已经暂停视频，客户端现在希望暂停或限制从服务器的传输，以免提取和缓冲不必要的数据。 再比如，一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接的速度来控制其资源利用率；等等。\n上述要求会让您想到 TCP 流控制吗？您应当想到这一点；因为问题基本相同（请参阅 流控制）。 不过，由于 HTTP/2 数据流在一个 TCP 连接内复用，TCP 流控制既不够精细，也无法提供必要的应用级 API 来调节各个数据流的传输。 为了解决这一问题，HTTP/2 提供了一组简单的构建块，这些构建块允许客户端和服务器实现其自己的数据流和连接级流控制：\n 流控制具有方向性。 每个接收方都可以根据自身需要选择为每个数据流和整个连接设置任意的窗口大小。 流控制基于信用。 每个接收方都可以公布其初始连接和数据流流控制窗口（以字节为单位），每当发送方发出 DATA 帧时都会减小，在接收方发出 WINDOW_UPDATE 帧时增大。 流控制无法停用。 建立 HTTP/2 连接后，客户端将与服务器交换 SETTINGS 帧，这会在两个方向上设置流控制窗口。 流控制窗口的默认值设为 65,535 字节，但是接收方可以设置一个较大的最大窗口大小（2^31-1 字节），并在接收到任意数据时通过发送 WINDOW_UPDATE 帧来维持这一大小。 流控制为逐跃点控制，而非端到端控制。 即，可信中介可以使用它来控制资源使用，以及基于自身条件和启发式算法实现资源分配机制。  HTTP/2 未指定任何特定算法来实现流控制。 不过，它提供了简单的构建块并推迟了客户端和服务器实现，可以实现自定义策略来调节资源使用和分配，以及实现新传输能力，同时提升网页应用的实际性能和感知性能（请参阅 速度、性能和人类感知）。\n例如，应用层流控制允许浏览器仅提取一部分特定资源，通过将数据流流控制窗口减小为零来暂停提取，稍后再行恢复。 换句话说，它允许浏览器提取图像预览或首次扫描结果，进行显示并允许其他高优先级提取继续，然后在更关键的资源完成加载后恢复提取。\n服务器推送 #  HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源（图 12-5），而无需客户端明确地请求。\n 注：HTTP/2 打破了严格的请求-响应语义，支持一对多和服务器发起的推送工作流，在浏览器内外开启了全新的互动可能性。 这是一项使能功能，对我们思考协议、协议用途和使用方式具有重要的长期影响。\n为什么在浏览器中需要一种此类机制呢？一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。 那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？ 服务器已经知道客户端下一步要请求什么资源，这时候服务器推送即可派上用场。\n事实上，如果您在网页中内联过 CSS、JavaScript，或者通过数据 URI 内联过其他资产（请参阅 资源内联），那么您就已经亲身体验过服务器推送了。 对于将资源手动内联到文档中的过程，我们实际上是在将资源推送给客户端，而不是等待客户端请求。 使用 HTTP/2，我们不仅可以实现相同结果，还会获得其他性能优势。 推送资源可以进行以下处理：\n 由客户端缓存 在不同页面之间重用 与其他资源一起复用 由服务器设定优先级 被客户端拒绝  PUSH_PROMISE 101 #  所有服务器推送数据流都由 PUSH_PROMISE 帧发起，表明了服务器向客户端推送所述资源的意图，并且需要先于请求推送资源的响应数据传输。 这种传输顺序非常重要：客户端需要了解服务器打算推送哪些资源，以免为这些资源创建重复请求。 满足此要求的最简单策略是先于父响应（即，DATA 帧）发送所有 PUSH_PROMISE 帧，其中包含所承诺资源的 HTTP 标头。\n在客户端接收到 PUSH_PROMISE 帧后，它可以根据自身情况选择拒绝数据流（通过 RST_STREAM 帧）。 （例如，如果资源已经位于缓存中，便可能会发生这种情况。） 这是一个相对于 HTTP/1.x 的重要提升。 相比之下，使用资源内联（一种受欢迎的 HTTP/1.x“优化”）等同于“强制推送”：客户端无法选择拒绝、取消或单独处理内联的资源。\n使用 HTTP/2，客户端仍然完全掌控服务器推送的使用方式。 客户端可以限制并行推送的数据流数量；调整初始的流控制窗口以控制在数据流首次打开时推送的数据量；或完全停用服务器推送。 这些优先级在 HTTP/2 连接开始时通过 SETTINGS 帧传输，可能随时更新。\n推送的每个资源都是一个数据流，与内嵌资源不同，客户端可以对推送的资源逐一复用、设定优先级和处理。 浏览器强制执行的唯一安全限制是，推送的资源必须符合原点相同这一政策：服务器对所提供内容必须具有权威性。\n标头压缩 #  每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。 （请参阅 测量和控制协议开销。） 为了减少此开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：\n 这种格式支持通过静态霍夫曼代码对传输的标头字段进行编码，从而减小了各个传输的大小。 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输的值进行有效编码。  利用霍夫曼编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。\n 作为一种进一步优化方式，HPACK 压缩上下文包含一个静态表和一个动态表：静态表在规范中定义，并提供了一个包含所有连接都可能使用的常用 HTTP 标头字段（例如，有效标头名称）的列表；动态表最初为空，将根据在特定连接内交换的值进行更新。 因此，为之前未见过的值采用静态 Huffman 编码，并替换每一侧静态表或动态表中已存在值的索引，可以减小每个请求的大小。\n注：在 HTTP/2 中，请求和响应标头字段的定义保持不变，仅有一些微小的差异：所有标头字段名称均为小写，请求行现在拆分成各个 :method、:scheme、:authority 和 :path 伪标头字段。\nHPACK 的安全性和性能 #  早期版本的 HTTP/2 和 SPDY 使用 zlib（带有一个自定义字典）压缩所有 HTTP 标头。 这种方式可以将所传输标头数据的大小减小 85% - 88%，显著减少了页面加载时间延迟：\n 在带宽较低的 DSL 链路中，上行链路速度仅有 375 Kbps，仅压缩请求标头就显著减少了特定网站（即，发出大量资源请求的网站）的页面加载时间。 我们发现，仅仅由于标头压缩，页面加载时间就减少了 45 - 1142 毫秒。 （SPDY 白皮书， chromium.org）\n 然而，2012 年夏天，出现了针对 TLS 和 SPDY 压缩算法的“犯罪”安全攻击，此攻击会导致会话被劫持。 于是，zlib 压缩算法被 HPACK 替代，后者经过专门设计，可以解决发现的安全问题、实现起来也更高效和简单，当然，可以对 HTTP 标头元数据进行良好压缩。\n如需了解有关 HPACK 压缩算法的完整详情，请参阅 IETF HPACK - HTTP/2 的标头压缩。\n"});index.add({'id':59,'href':'/notes/docs/technology/cloud/container/kubernetes/arch/','title':"Kubernetes 架构",'section':"Kubernetes",'content':"架构 #  组件 #    Control Plane #  控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。\n控制平面组件可以在集群中的任何节点上运行。然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。\nkube-apiserver #  主节点上负责提供 Kubernetes API 服务的组件；它是 Kubernetes 控制面的前端。\nkube-apiserver 在设计上考虑了水平扩缩的需要。 换言之，通过部署多个实例可以实现扩缩。 参见 构造高可用集群。\netcd #  etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。\n您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。要了解 etcd 更深层次的信息，请参考 etcd 文档。\nkube-scheduler #  主节点上的组件，该组件监视那些新创建的未指定运行节点的 Pod，并选择节点让 Pod 在上面运行。\n调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。\nkube-controller-manager #  在主节点上运行 控制器的组件。\n从逻辑上讲，每个 控制器都是一个单独的进程，但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。\n这些控制器包括:\n 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。 副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)。 服务帐户和令牌控制器（Service Account \u0026amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌.  云控制器管理器-(cloud-controller-manager) #   cloud-controller-manager 运行与基础云提供商交互的控制器。cloud-controller-manager 二进制文件是 Kubernetes 1.6 版本中引入的 alpha 功能。\ncloud-controller-manager 仅运行云提供商特定的控制器循环。您必须在 kube-controller-manager 中禁用这些控制器循环，您可以通过在启动 kube-controller-manager 时将 --cloud-provider 参数设置为 external 来禁用控制器循环。\ncloud-controller-manager 允许云供应商的代码和 Kubernetes 代码彼此独立地发展。在以前的版本中，核心的 Kubernetes 代码依赖于特定云提供商的代码来实现功能。在将来的版本中，云供应商专有的代码应由云供应商自己维护，并与运行 Kubernetes 的云控制器管理器相关联。\n以下控制器具有云提供商依赖性:\n 节点控制器（Node Controller）: 用于检查云提供商以确定节点是否在云中停止响应后被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 数据卷控制器（Volume Controller）: 用于创建、附加和装载卷、并与云提供商进行交互以编排卷   Node #  节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。\nkubelet #  一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器。\nkube-proxy #   kube-proxy 是集群中每个节点上运行的网络代理,实现 Kubernetes Service 概念的一部分。\nkube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。\n如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则，kube-proxy 仅转发流量本身。\n容器运行环境(Container Runtime) #  容器运行环境是负责运行容器的软件。\nKubernetes 支持多个容器运行环境: Docker、 containerd、 cri-o、 rktlet 以及任何实现 Kubernetes CRI (容器运行环境接口)。\n 插件(Addons) #  插件使用 Kubernetes 资源 ( DaemonSet, Deployment等) 实现集群功能。因为这些提供集群级别的功能，所以插件的命名空间资源属于 kube-system 命名空间。\n所选的插件如下所述：有关可用插件的扩展列表，请参见 插件 (Addons)。\nDNS #  尽管并非严格要求其他附加组件，但所有示例都依赖 集群 DNS，因此所有 Kubernetes 集群都应具有 DNS。\n除了您环境中的其他 DNS 服务器之外，集群 DNS 还是一个 DNS 服务器，它为 Kubernetes 服务提供 DNS 记录。\nCluster DNS 是一个 DNS 服务器，和您部署环境中的其他 DNS 服务器一起工作，为 Kubernetes 服务提供DNS记录。\nKubernetes 启动的容器自动将 DNS 服务器包含在 DNS 搜索中。\n用户界面(Dashboard) #   Dashboard 是 Kubernetes 集群的通用基于 Web 的 UI。它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。\n容器资源监控 #   容器资源监控将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。\n集群层面日志 #   集群层面日志 机制负责将容器的日志数据保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。\n 工作流程 #    "});index.add({'id':60,'href':'/notes/docs/technology/system/linux/','title':"Linux系统",'section':"系统",'content':"Linux系统 #  "});index.add({'id':61,'href':'/notes/docs/technology/system/application/nginx/','title':"Nginx",'section':"应用",'content':"Nginx #  概念 #  Nginx是一个开源免费的web服务器，同时可以作为反向代理、负载均衡和HTTP缓存的软件。\nNginx架构 #   "});index.add({'id':62,'href':'/notes/docs/technology/database/sql/postgres/','title':"PostgreSQL",'section':"SQL",'content':"PostgreSQL #  "});index.add({'id':63,'href':'/notes/docs/technology/database/sql/','title':"SQL",'section':"数据库",'content':"SQL #  "});index.add({'id':64,'href':'/notes/docs/technology/tool/tcp_copy/','title':"TcpCopy",'section':"工具",'content':"TCPCopy #  TCPCopy是一个流量复制工具。\n 使用场景 #    压力测试\n  模拟实际场景\n  回归测试\n  性能对照\n   架构 #    TCPCopy包含两部分：\n  tcpcopy\n安装在线上服务器上，用于抓取线上的请求包\n  intercept\n安装在辅助服务器上，做一些辅助作业\n   安装使用 #  设备：\nonline server：线上机器(流量导出的机器)\ntarget server：测试机器(流量导入的机器)\nassistant server：辅助机器\n  在target server上添加路由\n $ route add -net CLINET_NET gw ASSISTANG_IP    在assistant server上安装intercept服务\n下载地址： https://github.com/session-replay-tools/intercept/releases\n安装：\n $ cd intercept $ ./configure --prefix=/usr/local/intercept $ make \u0026amp;\u0026amp; make insall  启动：\n $ /usr/local/intercept/sbin/intercept -i eth0 -F tcp and src host TARGET_IP and src port TARGET_PORT -d    在online server安装tcpcopy服务\n下载地址： https://github.com/session-replay-tools/tcpcopy/releases\n安装：\n $ cd tcpcopy $ ./configure --prefix=/usr/local/tcpcopy $ make \u0026amp;\u0026amp; make install  启动\n $ /usr/local/tcpcopy/sbin/tcpcopy -x ONLINE_IP:PORT-TARGET_IP:PORT -s ASSISTAND_IP -c CLIENT_IP -d     "});index.add({'id':65,'href':'/notes/docs/technology/bigdata/application/zookeeper/','title':"Zookeeper",'section':"应用",'content':"Zookeeper #  ZooKeeper是用于维护配置信息，命名，提供分布式同步和提供组服务的集中式服务。\n    架构\n   部署\n   优化\n   "});index.add({'id':66,'href':'/notes/docs/technology/program/language/golang/garbage/','title':"垃圾回收",'section':"Golang",'content':"垃圾回收 #  GC算法 #  1. 引用计数（reference counting） #  每个单元维护一个域，保存其它单元指向它的引用数量（类似有向图的入度）。当引用数量为 0 时，将其回收。 2. 标记-清扫（mark \u0026amp; sweep） #  标记-清扫算法是第一种自动内存管理，基于追踪的垃圾收集算法。算法思想在 70 年代就提出了，是一种非常古老的算法。内存单元并不会在变成垃圾立刻回收，而是保持不可达状态，直到到达某个阈值或者固定时间长度。这个时候系统会挂起用户程序，也就是 STW，转而执行垃圾回收程序。垃圾回收程序对所有的存活单元进行一次全局遍历确定哪些单元可以回收。算法分两个部分：标记（mark）和清扫（sweep）。标记阶段表明所有的存活单元，清扫阶段将垃圾单元回收。 ### 三色标记法 1. 起初所有对象都是白色。 2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。 3. 节点复制（Copying Garbage Collection） #  4. 分代收集（Generational Garbage Collection） #   Golang GC #  1. 何时触发GC #  被动GC，在堆上分配大于 32K byte 对象的时候进行检测此时是否满足垃圾回收条件，如果满足则进行垃圾回收。\n主动GC，调用 runtime.GC()，这是阻塞式的\n2. GC 触发条件 #  //初始化的时候设置 GC 的触发阈值 func gcinit() { _ = setGCPercent(readgogc()) memstats.gc_trigger = heapminimum ... } // 启动的时候通过 GOGC 传递百分比 x // 触发阈值等于 x * defaultHeapMinimum (defaultHeapMinimum 默认是 4M) func readgogc() int32 { p := gogetenv(\u0026quot;GOGC\u0026quot;) if p == \u0026quot;off\u0026quot; { return -1 } if n, ok := atoi32(p); ok { return n } return 100 } 3. 垃圾回收流程 #    首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。 mark 有两个过程。  从 root 开始遍历，标记为灰色。遍历灰色队列。 re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。   Stop The World 有两个过程。  第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。    另外针对上图各个阶段对应 GCPhase 如下：\n Off: _GCoff Stack scan ~ Mark: _GCmark Mark termination: _GCmarktermination   GC #  什么是GC #  GC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。\n当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而负责垃圾回收的程序组件，即为垃圾回收器。\n通常，垃圾回收器的执行过程被划分为两个半独立的组件：\n 赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。 回收器（Collector）：负责执行垃圾回收的代码。   什么是根对象 #  根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。   三色标记法 #  理解三色标记法的关键是理解对象的三色抽象以及波面（wavefront）推进这两个概念。三色抽象只是一种描述追踪式回收器的方法，在实践中并没有实际含义，它的重要作用在于从逻辑上严密推导标记清理这种垃圾回收方法的正确性。也就是说，当我们谈及三色标记法时，通常指标记清扫的垃圾回收。\n从垃圾回收器的视角来看，三色抽象规定了三种不同类型的对象，并用不同的颜色相称：\n 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。  这样三种不变性所定义的回收过程其实是一个波面不断前进的过程，这个波面同时也是黑色对象和白色对象的边界，灰色对象就是这个波面。\n当垃圾回收开始时，只有白色对象。随着标记过程开始进行时，灰色对象开始出现（着色），这时候波面便开始扩大。当一个对象的所有子节点均完成扫描时，会被着色为黑色。当整个堆遍历完成时，只剩下黑色和白色对象，这时的黑色对象为可达对象，即存活；而白色对象为不可达对象，即死亡。这个过程可以视为以灰色对象为波面，将黑色对象和白色对象分离，使波面不断向前推进，直到所有可达的灰色对象都变为黑色对象为止的过程。如下图所示：\n 图中展示了根对象、可达对象、不可达对象，黑、灰、白对象以及波面之间的关系。\n 扫描根对象，将根对象标记为灰色 扫描灰色对象，将灰色对象标记为黑色，将黑色对象的子节点标志位灰色 重复2，直到不存在灰色对象   什么是STW #  STW 可以是 Stop the World 的缩写，也可以是 Start the World 的缩写。通常意义上指指代从 Stop the World 这一动作发生时到 Start the World 这一动作发生时这一段时间间隔，即万物静止。STW 在垃圾回收过程中为了保证实现的正确性、防止无止境的内存增长等问题而不可避免的需要停止赋值器进一步操作对象图的一段过程。\n在这个过程中整个用户代码被停止或者放缓执行， STW 越长，对用户代码造成的影响（例如延迟）就越大。\n 写屏障 #  要讲清楚写屏障，就需要理解三色标记清除算法中的强弱不变性以及赋值器的颜色，理解他们需要一定的抽象思维。写屏障是一个在并发垃圾回收器中才会出现的概念，垃圾回收器的正确性体现在：不应出现对象的丢失，也不应错误的回收还不需要回收的对象。\n可以证明，当以下两个条件同时满足时会破坏垃圾回收器的正确性：\n 条件 1: 赋值器修改对象图，导致某一黑色对象引用白色对象； 条件 2: 从灰色对象出发，到达白色对象的、未经访问过的路径被赋值器破坏。  只要能够避免其中任何一个条件，则不会出现对象丢失的情况，因为：\n 如果条件 1 被避免，则所有白色对象均被灰色对象引用，没有白色对象会被遗漏； 如果条件 2 被避免，即便白色对象的指针被写入到黑色对象中，但从灰色对象出发，总存在一条没有访问过的路径，从而找到到达白色对象的路径，白色对象最终不会被遗漏。  我们不妨将三色不变性所定义的波面根据这两个条件进行削弱：\n 当满足原有的三色不变性定义（或上面的两个条件都不满足时）的情况称为强三色不变性（strong tricolor invariant） 当赋值器令黑色对象引用白色对象时（满足条件 1 时）的情况称为弱三色不变性（weak tricolor invariant）  当赋值器进一步破坏灰色对象到达白色对象的路径时（进一步满足条件 2 时），即打破弱三色不变性， 也就破坏了回收器的正确性；或者说，在破坏强弱三色不变性时必须引入额外的辅助操作。 弱三色不变形的好处在于：只要存在未访问的能够到达白色对象的路径，就可以将黑色对象指向白色对象。\n如果我们考虑并发的用户态代码，回收器不允许同时停止所有赋值器，就是涉及了存在的多个不同状态的赋值器。为了对概念加以明确，还需要换一个角度，把回收器视为对象，把赋值器视为影响回收器这一对象的实际行为（即影响 GC 周期的长短），从而引入赋值器的颜色：\n 黑色赋值器：已经由回收器扫描过，不会再次对其进行扫描。 灰色赋值器：尚未被回收器扫描过，或尽管已经扫描过但仍需要重新扫描。  赋值器的颜色对回收周期的结束产生影响：\n 如果某种并发回收器允许灰色赋值器的存在，则必须在回收结束之前重新扫描对象图。 如果重新扫描过程中发现了新的灰色或白色对象，回收器还需要对新发现的对象进行追踪，但是在新追踪的过程中，赋值器仍然可能在其根中插入新的非黑色的引用，如此往复，直到重新扫描过程中没有发现新的白色或灰色对象。  于是，在允许灰色赋值器存在的算法，最坏的情况下，回收器只能将所有赋值器线程停止才能完成其跟对象的完整扫描，也就是我们所说的 STW。\n为了确保强弱三色不变性的并发指针更新操作，需要通过赋值器屏障技术来保证指针的读写操作一致。因此我们所说的 Go 中的写屏障、混合写屏障，其实是指赋值器的写屏障，赋值器的写屏障作为一种同步机制，使赋值器在进行指针写操作时，能够“通知”回收器，进而不会破坏弱三色不变性。\n有两种非常经典的写屏障：Dijkstra 插入屏障和 Yuasa 删除屏障。\n灰色赋值器的 Dijkstra 插入屏障的基本思想是避免满足条件 1：\n// 灰色赋值器 Dijkstra 插入屏障func DijkstraWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) { shade(ptr) *slot = ptr} 为了防止黑色对象指向白色对象，应该假设 *slot 可能会变为黑色，为了确保 ptr 不会在被赋值到 *slot 前变为白色，shade(ptr) 会先将指针 ptr 标记为灰色，进而避免了条件 1。如图所示：\n Dijkstra 插入屏障的好处在于可以立刻开始并发标记。但存在两个缺点：\n 由于 Dijkstra 插入屏障的“保守”，在一次回收过程中可能会残留一部分对象没有回收成功，只有在下一个回收过程中才会被回收； 在标记阶段中，每次进行指针赋值操作时，都需要引入写屏障，这无疑会增加大量性能开销；为了避免造成性能问题，Go 团队在最终实现时，没有为所有栈上的指针写操作，启用写屏障，而是当发生栈上的写操作时，将栈标记为灰色，但此举产生了灰色赋值器，将会需要标记终止阶段 STW 时对这些栈进行重新扫描。  另一种比较经典的写屏障是黑色赋值器的 Yuasa 删除屏障。其基本思想是避免满足条件 2：\n// 黑色赋值器 Yuasa 屏障func YuasaWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) { shade(*slot) *slot = ptr} 为了防止丢失从灰色对象到白色对象的路径，应该假设 *slot 可能会变为黑色，为了确保 ptr 不会在被赋值到 *slot 前变为白色，shade(*slot) 会先将 *slot 标记为灰色，进而该写操作总是创造了一条灰色到灰色或者灰色到白色对象的路径，进而避免了条件 2。\nYuasa 删除屏障的优势则在于不需要标记结束阶段的重新扫描，结束时候能够准确的回收所有需要回收的白色对象。缺陷是 Yuasa 删除屏障会拦截写操作，进而导致波面的退后，产生“冗余”的扫描：\n Go 在 1.8 的时候为了简化 GC 的流程，同时减少标记终止阶段的重扫成本，将 Dijkstra 插入屏障和 Yuasa 删除屏障进行混合，形成混合写屏障。该屏障提出时的基本思想是：对正在被覆盖的对象进行着色，且如果当前栈未扫描完成，则同样对指针进行着色。\n但在最终实现时原提案[4]中对 ptr 的着色还额外包含对执行栈的着色检查，但由于时间有限，并未完整实现过，所以混合写屏障在目前的实现伪代码是：\n// 混合写屏障func HybridWritePointerSimple(slot *unsafe.Pointer, ptr unsafe.Pointer) { shade(*slot) shade(ptr) *slot = ptr} 在这个实现中，如果无条件对引用双方进行着色，自然结合了 Dijkstra 和 Yuasa 写屏障的优势，但缺点也非常明显，因为着色成本是双倍的，而且编译器需要插入的代码也成倍增加，随之带来的结果就是编译后的二进制文件大小也进一步增加。为了针对写屏障的性能进行优化，Go 1.10 前后，Go 团队随后实现了批量写屏障机制。其基本想法是将需要着色的指针统一写入一个缓存，每当缓存满时统一对缓存中的所有 ptr 指针进行着色。\n golang gc流程 #  当前版本的 Go 以 STW 为界限，可以将 GC 划分为五个阶段：\n   阶段 说明 赋值器状态     SweepTermination 清扫终止阶段，为下一个阶段的并发标记做准备工作，启动写屏障 STW   Mark 扫描标记阶段，与赋值器并发执行，写屏障开启 并发   MarkTermination 标记终止阶段，保证一个周期内标记任务完成，停止写屏障 STW   GCoff 内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭 并发   GCoff 内存归还阶段，将过多的内存归还给操作系统，写屏障关闭 并发    具体而言，各个阶段的触发函数分别为：\n  "});index.add({'id':67,'href':'/notes/docs/technology/cloud/container/','title':"容器技术",'section':"云原生",'content':"容器技术 #  What #  定义 #   容器提供了一种逻辑打包机制，以这种机制打包的应用可以脱离其实际运行的环境。利用这种脱离，不管目标环境是私有数据中心、公有云，还是开发者的个人笔记本电脑，您都可以轻松、一致地部署基于容器的应用。容器化使开发者和 IT 运营团队的关注点泾渭分明 - 开发者专注于应用逻辑和依赖项，而 IT 运营团队可以专注于部署和管理，不必为应用细节分心，例如具体的软件版本和应用特有的配置。\n  VM vs Container #    Why #  与虚拟机的硬件堆栈虚拟化不同，容器在操作系统级别进行虚拟化，且可以直接在操作系统内核上运行多个容器。也就是说，容器更轻巧：它们共享操作系统内核，启动速度更快，且与启动整个操作系统相比其占用的内存微乎其微。\n  一致的环境\n  在任何地方运行\n  隔离\n容器会在操作系统级别虚拟化 CPU、内存、存储和网络资源，为开发者提供在逻辑上与其他应用相隔离的沙盒化操作系统接口。\n   How #  基础 #  Namespaces #  Namespace是对全局系统资源的一种封装隔离，使得处于不同namespace的进程拥有独立的全局系统资源，改变一个namespace中的系统资源只会影响当前namespace里的进程，对其他namespace中的进程没有影响。\n目前，Linux内核里面实现了7种不同类型的namespace。\n名称 宏定义 隔离内容 Cgroup CLONE_NEWCGROUP Cgroup root directory (since Linux 4.6) IPC CLONE_NEWIPC System V IPC, POSIX message queues (since Linux 2.6.19) Network CLONE_NEWNET Network devices, stacks, ports, etc. (since Linux 2.6.24) Mount CLONE_NEWNS Mount points (since Linux 2.4.19) PID CLONE_NEWPID Process IDs (since Linux 2.6.24) User CLONE_NEWUSER User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8) UTS CLONE_NEWUTS Hostname and NIS domain name (since Linux 2.6.19) Control groups #  cgroup和namespace类似，也是将进程进行分组，但它的目的和namespace不一样，namespace是为了隔离进程组之间的资源，而cgroup是为了对一组进程进行统一的资源监控和限制。\ncgroup主要包括下面两部分：\n  subsystem\n一个subsystem就是一个内核模块，他被关联到一颗cgroup树之后，就会在树的每个节点（进程组）上做具体的操作。subsystem经常被称作\u0026quot;resource controller\u0026rdquo;，因为它主要被用来调度或者限制每个进程组的资源，但是这个说法不完全准确，因为有时我们将进程分组只是为了做一些监控，观察一下他们的状态，比如perf_event subsystem。到目前为止，Linux支持12种subsystem，比如限制CPU的使用时间，限制使用的内存，统计CPU的使用情况，冻结和恢复一组进程等。\n  hierarchy\n一个hierarchy可以理解为一棵cgroup树，树的每个节点就是一个进程组，每棵树都会与零到多个subsystem关联。在一颗树里面，会包含Linux系统中的所有进程，但每个进程只能属于一个节点（进程组）。系统中可以有很多颗cgroup树，每棵树都和不同的subsystem关联，一个进程可以属于多颗树，即一个进程可以属于多个进程组，只是这些进程组和不同的subsystem关联。目前Linux支持12种subsystem，如果不考虑不与任何subsystem关联的情况（systemd就属于这种情况），Linux里面最多可以建12颗cgroup树，每棵树关联一个subsystem，当然也可以只建一棵树，然后让这棵树关联所有的subsystem。当一颗cgroup树不和任何subsystem关联的时候，意味着这棵树只是将进程进行分组，至于要在分组的基础上做些什么，将由应用程序自己决定，systemd就是一个这样的例子。\n  Union file systems #  容器中使用的文件系统是可堆叠的，这意味着可以将不同分支中的文件和目录重叠以形成单个文件系统。该系统有助于避免在每次部署新容器时重复数据。Docker使用此技术实现镜像的功能 文档\n overlay2 aufs   案例 #  容器技术实现 #    Docker   容器编排与调度 #    Kubernetes  "});index.add({'id':68,'href':'/notes/docs/technology/bigdata/application/','title':"应用",'section':"大数据",'content':"应用 #  "});index.add({'id':69,'href':'/notes/docs/technology/cloud/container/kubernetes/object/application/','title':"应用配置",'section':"Kubernetes 对象",'content':"应用配置 #  "});index.add({'id':70,'href':'/notes/docs/technology/system/linux/guideBook/','title':"操作指南",'section':"Linux系统",'content':"玩转Linux #  CPU相关 #  内存相关 #  磁盘相关 #  系统相关 #  网络相关 #  权限相关 #  文件相关 #  文本相关 #  IPMI #  RAID #    "});index.add({'id':71,'href':'/notes/docs/technology/system/basic/fs/','title':"文件系统",'section':"计算机基础",'content':"文件系统 #  文件系统是一套实现了数据的存储、分级组织、访问和获取等操作的抽象数据类型（Abstract data type）。\n概念 #  文件系统是一种用于向用户提供底层数据访问的机制。它将设备中的空间划分为特定大小的块（或者称为簇），一般每块512字节。数据存储在这些块中，大小被修正为占用整数个块。由文件系统软件来负责将这些块组织为文件和目录，并记录哪些块被分配给了哪个文件，以及哪些块没有被使用。\n EXT2文件系统 #  EXT2文件系统是Linux底下最常用的文件系统。其结构如下：\n  Boot Sector\n启动扇区，这个启动扇区可以安装启动管理程序， 这是个非常重要的设计，因为如此一来我们就能够将不同的启动管理程序安装到个别的文件系统最前端，而不用覆盖整颗硬盘唯一的MBR.\n  Block Group\n  Super Block\n记录整个filesystem相关信息\n  Group Descriptions\n描述每个 block group 的开始与结束的 block 号码，以及说明每个区段 (superblock, bitmap, inodemap, data block) 分别介于哪一个 block 号码之间\n  Block Bitmap\n记录使用和未使用的block号码\n  Inode Bitmap\n记录使用和未使用的inode号码\n  Inode Table\n  Data Blocks\n数据块，实际存储数据的地方\n      Inode Table #  inode是ext2文件系统的基本构建块，每个文件和目录都有唯一一个inode。其机构如下：\n  Mode\n存取模式信息(read/write/excute)\n  Owner info\n拥有者与群组信息\n  Size\n文件的容量\n  Timestamps\n  创建或状态改变的时间(ctime)\n  最近一次的读取时间(atime)\n  最近修改的时间(mtime)\n    Direct Blocks\n12个直接指向block号码\n  Indirect Blocks\n间接指向，记录block号码的记录区\n  Double Indirect\n双间接指向\n  Triple Indirect\n三间接指向\n    Super Block #  Super Block是记录整个filesystem相关信息的地方，包括以下：\n  Magic Number\n  Revision Level\n  Mount Count and Maximum Mount Count\n  Block Group Number\n  Block Size\n  Blocks per Group\n  Free Blocks\n  Free Inodes\n  First Inode\n   目录和文件 #    目录\n当我们在 Linux 下的 ext2 文件系统创建一个目录时， ext2 会分配一个 inode 与至少一块 block 给该目录。其中，inode 记录该目录的相关权限与属性，并可记录分配到的那块 block 号码； 而 block 则是记录在这个目录下的文件名与该文件名占用的 inode 号码数据。\n  文件\n我们在 Linux 下的 ext2 创建一个一般文件时， ext2 会分配一个 inode 与相对于该文件大小的 block 数量给该文件。\n  "});index.add({'id':72,'href':'/notes/docs/other/learn/','title':"方法论",'section':"非技术相关",'content':"方法论 #  "});index.add({'id':73,'href':'/notes/docs/technology/cloud/container/docker/arch/','title':"架构",'section':"Docker",'content':"架构 #  组件 #    Docker daemon #  Docker daemon (dockerd) 监听Docker API请求并管理Docker对象，例如图像，容器，网络和卷。 守护程序还可以与其他守护程序通信以管理Docker服务。\nDocker client #  Docker client (docker) 是许多Docker用户与Docker交互的主要方式。 当您使用诸如docker run之类的命令时，客户端会将这些命令发送至dockerd，后者将其执行。 docker命令使用Docker API。 Docker客户端可以与多个守护程序通信。\nDocker registries #  Docker registry存储Docker映像。 Docker Hub是任何人都可以使用的公共注册表，并且Docker配置为默认在Docker Hub上查找映像。 您甚至可以运行自己的私人注册表。\n当使用 docker pull or docker run 命令时, 将从配置的registry中拉去镜像，当使用 docker push 命令时，镜像将被推送到配置的registry中 。\nDocker objects #  使用Docker时，您正在创建和使用映像，容器，网络，卷，插件和其他对象。 本节是其中一些对象的简要概述。\nIMAGES #  Image是一个只读模板，其中包含创建Docker容器的说明。 通常，一个图像基于另一个图像，并带有一些附加的自定义。 例如，您可以基于“ ubuntu”映像构建映像，但安装Apache Web服务器和您的应用程序以及运行应用程序所需的配置详细信息。\n您可以创建自己的图像，也可以仅使用其他人创建并在注册表中发布的图像。 要构建自己的映像，您可以使用简单的语法创建Dockerfile，以定义创建映像和运行映像所需的步骤。 Dockerfile中的每条指令都会在映像中创建一个层。 当您更改Dockerfile并重建映像时，仅重建那些已更改的层。 与其他虚拟化技术相比，这是使映像如此轻巧，小型和快速的部分原因。\nCONTAINERS #  Container是image的可运行实例。 您可以使用Docker API或CLI创建，启动，停止，移动或删除容器。 您可以将容器连接到一个或多个网络，将存储连接到它，甚至根据其当前状态创建一个新映像。\n默认情况下，容器与其他容器及其主机之间的隔离度相对较高。 您可以控制容器的网络，存储或其他基础子系统与其他容器或主机之间的隔离程度。\n容器由其映像以及在创建或启动时为其提供的任何配置选项定义。 删除容器后，未存储在永久性存储中的状态更改将消失。\nSERVICES #  Service使您可以在多个Docker守护程序之间扩展容器，这些守护程序都可以与多个managers和workers 一起作为swarm协同工作。 群的每个成员都是Docker守护程序，所有守护程序都使用Docker API进行通信。 服务允许您定义所需的状态，例如在任何给定时间必须可用的服务副本数。 默认情况下，该服务在所有工作节点之间是负载平衡的。 对于消费者而言，Docker服务似乎是一个单独的应用程序。 Docker Engine在Docker 1.12及更高版本中支持集群模式。\n "});index.add({'id':74,'href':'/notes/docs/technology/program/revision/','title':"版本控制",'section':"编程",'content':"版本控制 #  什么是“版本控制”？ #  版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n如果你是位图形或网页设计师，可能会需要保存某一幅图片或页面布局文件的所有修订版本（这或许是你非常渴望拥有的功能），采用版本控制系统（VCS）是个明智的选择。 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子。 但额外增加的工作量却微乎其微。\n 分类 #    本地版本控制系统\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n 其中最流行的一种叫做 RCS，现今许多计算机系统上都还看得到它的踪影。 甚至在流行的 Mac OS X 系统上安装了开发者工具包之后，也可以使用 rcs 命令。 它的工作原理是在硬盘上保存补丁集（补丁是指文件修订前后的变化）；通过应用所有的补丁，可以重新计算出各个版本的文件内容。\n  集中化的版本控制系统\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。 这类系统，诸如 CVS、 Subversion 以及 Perforce 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 多年以来，这已成为版本控制系统的标准做法。\n 这种做法带来了许多好处，特别是相较于老式的本地 VCS 来说。 现在，每个人都可以在一定程度上看到项目中的其他人正在做些什么。 而管理员也可以轻松掌控每个开发者的权限，并且管理一个 CVCS 要远比在各个客户端上维护本地数据库来得轻松容易。\n事分两面，有好有坏。 这么做最显而易见的缺点是中央服务器的单点故障。 如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。 如果中心数据库所在的磁盘发生损坏，又没有做恰当备份，毫无疑问你将丢失所有数据——包括项目的整个变更历史，只剩下人们在各自机器上保留的单独快照。 本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n  分布式版本控制系统\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 在这类系统中，像 Git、Mercurial、Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n 更进一步，许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。 你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。\n  "});index.add({'id':75,'href':'/notes/docs/technology/system/linux/base/directory/','title':"目录结构",'section':"基础",'content':"Linux目录结构 #    /boot\n系统启动相关的文件，如内核、initrd，以及grub(bootloader)\n  /dev\n设备文件\n块设备：随机访问，数据块\n字符设备：线性访问，按字符为单位\n设备号：主设备号(major)和次设备号(minor)\n  /etc\n配置文件\n  /home\n用户的家目录，每一个用户的家目录通常默认为/home/USERNAME\n  /root\n管理员的家目录\n  /lib\n库文件\n静态库，.a\n动态库，.dll，.so（shared object）\n  /lib/modules\n内核模块文件\n  /media\n挂载点目录，移动设备\n  /mnt\n挂载点目录，额外的临时文件系统\n  /opt\n可选目录，第三方程序的安装目录\n  /proc\n伪文件系统，内核映射文件\n  /sys\n伪文件系统，跟硬件设备相关的属性映射文件\n  /tmp\n临时文件，/var/tmp\n  /var\n可变化的文件\n  /bin\n可执行文件，用户命令\n  /sbin\n可执行文件，管理命令\n  /usr\nshared，read-only\n/usr/bin\n/usr/sbin\n/usr/lib\n  /usr/local\n第三方软件\n/usr/local/bin\n/usr/local/sbin\n/usr/local/lib\n   "});index.add({'id':76,'href':'/notes/docs/other/read/%E7%9F%9B%E7%9B%BE%E8%AE%BA/','title':"矛盾论",'section':"阅读",'content':"矛盾论 #  （一九三七年八月）\n 这篇哲学论文，是毛泽东继《实践论》之后，为了同一的目的，即为了克服存在于中国共产党内的严重的教条主义思想而写的，曾在延安的抗日军事政治大学作过讲演。在收入本书第一版的时候，作者作了部分的补充、删节和修改。\n 　事物的矛盾法则，即对立统一的法则，是唯物辩证法的最根本的法则。列宁说：“就本来的意义讲，辩证法是研究对象的本质自身中的矛盾。”⑴列宁常称这个法则为辩证法的本质，又称之为辩证法的核心⑵。因此，我们在研究这个法则时，不得不涉及广泛的方面，不得不涉及许多的哲学问题。如果我们将这些问题都弄清楚了，我们就在根本上懂得了唯物辩证法。这些问题是：两种宇宙观；矛盾的普遍性；矛盾的特殊性；主要的矛盾和主要的矛盾方面；矛盾诸方面的同一性和斗争性；对抗在矛盾中的地位。\n苏联哲学界在最近数年中批判了德波林学派⑶的唯心论，这件事引起了我们的极大的兴趣。德波林的唯心论在中国共产党内发生了极坏的影响，我们党内的教条主义思想不能说和这个学派的作风没有关系。因此，我们现在的哲学研究工作，应当以扫除教条主义思想为主要的目标。\n一　两种宇宙观 #  　在人类的认识史中，从来就有关于宇宙发展法则的两种见解，一种是形而上学的见解，一种是辩证法的见解，形成了互相对立的两种宇宙观。列宁说：“对于发展（进化）所持的两种基本的（或两种可能的？或两种在历史上常见的？）观点是：（一）认为发展是减少和增加，是重复；（二）认为发展是对立的统一（统一物分成为两个互相排斥的对立，而两个对立又互相关联着）。”⑷列宁说的就是这两种不同的宇宙观。\n形而上学，亦称玄学。这种思想，无论在中国，在欧洲，在一个很长的历史时间内，是属于唯心论的宇宙观，并在人们的思想中占了统治的地位。在欧洲，资产阶级初期的唯物论，也是形而上学的。由于欧洲许多国家的社会经济情况进到了资本主义高度发展的阶段，生产力、阶级斗争和科学均发展到了历史上未有过的水平，工业无产阶级成为历史发展的最伟大的动力，因而产生了马克思主义的唯物辩证法的宇宙观。于是，在资产阶级那里，除了公开的极端露骨的反动的唯心论之外，还出现了庸俗的进化论，出来对抗唯物辩证法。\n所谓形而上学的或庸俗进化论的宇宙观，就是用孤立的、静止的和片面的观点去看世界。这种宇宙观把世界一切事物，一切事物的形态和种类，都看成是永远彼此孤立和永远不变化的。如果说有变化，也只是数量的增减和场所的变更。而这种增减和变更的原因，不在事物的内部而在事物的外部，即是由于外力的推动。形而上学家认为，世界上各种不同事物和事物的特性，从它们一开始存在的时候就是如此。后来的变化，不过是数量上的扩大或缩小。他们认为一种事物永远只能反复地产生为同样的事物，而不能变化为另一种不同的事物。在形而上学家看来，资本主义的剥削，资本主义的竞争，资本主义社会的个人主义思想等，就是在古代的奴隶社会里，甚至在原始社会里，都可以找得出来，而且会要永远不变地存在下去。说到社会发展的原因，他们就用社会外部的地理、气候等条件去说明。他们简单地从事物外部去找发展的原因，否认唯物辩证法所主张的事物因内部矛盾引起发展的学说。因此，他们不能解释事物的质的多样性，不能解释一种质变为他种质的现象。这种思想，在欧洲，在十七世纪和十八世纪是机械唯物论，在十九世纪末和二十世纪初则有庸俗进化论。在中国，则有所谓“天不变，道亦不变”⑸的形而上学的思想，曾经长期地为腐朽了的封建统治阶级所拥护。近百年来输入了欧洲的机械唯物论和庸俗进化论，则为资产阶级所拥护。\n和形而上学的宇宙观相反，唯物辩证法的宇宙观主张从事物的内部、从一事物对他事物的关系去研究事物的发展，即把事物的发展看做是事物内部的必然的自己的运动，而每一事物的运动都和它的周围其他事物互相联系着和互相影响着。事物发展的根本原因，不是在事物的外部而是在事物的内部，在于事物内部的矛盾性。任何事物内部都有这种矛盾性，因此引起了事物的运动和发展。事物内部的这种矛盾性是事物发展的根本原因，一事物和他事物的互相联系和互相影响则是事物发展的第二位的原因。这样，唯物辩证法就有力地反对了形而上学的机械唯物论和庸俗进化论的外因论或被动论。这是清楚的，单纯的外部原因只能引起事物的机械的运动，即范围的大小，数量的增减，不能说明事物何以有性质上的千差万别及其互相变化。事实上，即使是外力推动的机械运动，也要通过事物内部的矛盾性。植物和动物的单纯的增长，数量的发展，主要地也是由于内部矛盾所引起的。同样，社会的发展，主要地不是由于外因而是由于内因。许多国家在差不多一样的地理和气候的条件下，它们发展的差异性和不平衡性，非常之大。同一个国家吧，在地理和气候并没有变化的情形下，社会的变化却是很大的。帝国主义的俄国变为社会主义的苏联，封建的闭关锁国的日本变为帝国主义的日本，这些国家的地理和气候并没有变化。长期地被封建制度统治的中国，近百年来发生了很大的变化，现在正在变化到一个自由解放的新中国的方向去，中国的地理和气候并没有变化。整个地球及地球各部分的地理和气候也是变化着的，但以它们的变化和社会的变化相比较，则显得很微小，前者是以若干万年为单位而显现其变化的，后者则在几千年、几百年、几十年、甚至几年或几个月（在革命时期）内就显现其变化了。按照唯物辩证法的观点，自然界的变化，主要地是由于自然界内部矛盾的发展。社会的变化，主要地是由于社会内部矛盾的发展，即生产力和生产关系的矛盾，阶级之间的矛盾，新旧之间的矛盾，由于这些矛盾的发展，推动了社会的前进，推动了新旧社会的代谢。唯物辩证法是否排除外部的原因呢？并不排除。唯物辩证法认为外因是变化的条件，内因是变化的根据，外因通过内因而起作用。鸡蛋因得适当的温度而变化为鸡子，但温度不能使石头变为鸡子，因为二者的根据是不同的。各国人民之间的互相影响是时常存在的。在资本主义时代，特别是在帝国主义和无产阶级革命的时代，各国在政治上、经济上和文化上的互相影响和互相激动，是极其巨大的。十月社会主义革命不只是开创了俄国历史的新纪元，而且开创了世界历史的新纪元，影响到世界各国内部的变化，同样地而且还特别深刻地影响到中国内部的变化，但是这种变化是通过了各国内部和中国内部自己的规律性而起的。两军相争，一胜一败，所以胜败，皆决于内因。胜者或因其强，或因其指挥无误，败者或因其弱，或因其指挥失宜，外因通过内因而引起作用。一九二七年中国大资产阶级战败了无产阶级，是通过中国无产阶级内部的（中国共产党内部的）机会主义而起作用的。当着我们清算了这种机会主义的时候，中国革命就重新发展了。后来，中国革命又受了敌人的严重的打击，是因为我们党内产生了冒险主义。当着我们清算了这种冒险主义的时候，我们的事业就又重新发展了。由此看来，一个政党要引导革命到胜利，必须依靠自己政治路线的正确和组织上的巩固。\n辩证法的宇宙观，不论在中国，在欧洲，在古代就产生了。但是古代的辩证法带着自发的朴素的性质，根据当时的社会历史条件，还不可能有完备的理论，因而不能完全解释宇宙，后来就被形而上学所代替。生活在十八世纪末和十九世纪初期的德国著名哲学家黑格尔，对于辩证法曾经给了很重要的贡献，但是他的辩证法却是唯心的辩证法。直到无产阶级运动的伟大的活动家马克思和恩格斯综合了人类认识史的积极的成果，特别是批判地吸取了黑格尔的辩证法的合理的部分，创造了辩证唯物论和历史唯物论这个伟大的理论，才在人类认识史上起了一个空前的大革命。后来，经过列宁和斯大林，又发展了这个伟大的理论。这个理论一经传到中国来，就在中国思想界引起了极大的变化。\n这个辩证法的宇宙观，主要地就是教导人们要善于去观察和分析各种事物的矛盾的运动，并根据这种分析，指出解决矛盾的方法。因此，具体地了解事物矛盾这一个法则，对于我们是非常重要的。\n二　矛盾的普遍性 #  　为了叙述的便利起见，我在这里先说矛盾的普遍性，再说矛盾的特殊性。这是因为马克思主义的伟大的创造者和继承者马克思、恩格斯、列宁、斯大林他们发现了唯物辩证法的宇宙观，已经把唯物辩证法应用在人类历史的分析和自然历史的分析的许多方面，应用在社会的变革和自然的变革（例如在苏联）的许多方面，获得了极其伟大的成功，矛盾的普遍性已经被很多人所承认，因此，关于这个问题只需要很少的话就可以说明白；而关于矛盾的特殊性的问题，则还有很多的同志，特别是教条主义者，弄不清楚。他们不了解矛盾的普遍性即寓于矛盾的特殊性之中。他们也不了解研究当前具体事物的矛盾的特殊性，对于我们指导革命实践的发展有何等重要的意义。因此，关于矛盾的特殊性的问题应当着重地加以研究，并用足够的篇幅加以说明。为了这个缘故，当着我们分析事物矛盾的法则的时候，我们就先来分析矛盾的普遍性的问题，然后再着重地分析矛盾的特殊性的问题，最后仍归到矛盾的普遍性的问题。\n矛盾的普遍性或绝对性这个问题有两方面的意义。其一是说，矛盾存在于一切事物的发展过程中；其二是说，每一事物的发展过程中存在着自始至终的矛盾运动。\n恩格斯说：“运动本身就是矛盾。”⑹列宁对于对立统一法则所下的定义，说它就是“承认（发现）自然界（精神和社会两者也在内）的一切现象和过程都含有互相矛盾、互相排斥、互相对立的趋向”⑺。这些意见是对的吗？是对的。一切事物中包含的矛盾方面的相互依赖和相互斗争，决定一切事物的生命，推动一切事物的发展。没有什么事物是不包含矛盾的，没有矛盾就没有世界。\n矛盾是简单的运动形式（例如机械性的运动）的基础，更是复杂的运动形式的基础。\n恩格斯这样说明过矛盾的普遍性：“如果简单的机械的移动本身包含着矛盾，那末，物质的更高的运动形式，特别是有机生命及其发展，就更加包含着矛盾。……生命首先就在于：生物在每一个瞬间是它自身，但却又是别的什么。所以，生命也是存在于物体和过程本身中的不断地自行产生并自行解决的矛盾；这一矛盾一停止，生命亦即停止，于是死就来到。同样，我们看到了，在思维的范围以内我们也不能避免矛盾，并且我们看到了，例如，人的内部无限的认识能力与此种认识能力仅在外部被局限的而且认识上也被局限的个别人们身上的实际的实现二者之间的矛盾，是在人类世代的无穷的——至少对于我们，实际上是无穷的——连续系列之中，是在无穷的前进运动之中解决的。”\n“高等数学的主要基础之一，就是矛盾……”\n“就是初等数学，也充满着矛盾。……”⑻\n列宁也这样说明过矛盾的普遍性：“在数学中，正和负，微分和积分。\n在力学中，作用和反作用。\n在物理学中，阳电和阴电。\n在化学中，原子的化合和分解。\n在社会科学中，阶级斗争。”⑼\n战争中的攻守，进退，胜败，都是矛盾着的现象。失去一方，他方就不存在。双方斗争而又联结，组成了战争的总体，推动了战争的发展，解决了战争的问题。\n人的概念的每一差异，都应把它看作是客观矛盾的反映。客观矛盾反映入主观的思想，组成了概念的矛盾运动，推动了思想的发展，不断地解决了人们的思想问题。\n党内不同思想的对立和斗争是经常发生的，这是社会的阶级矛盾和新旧事物的矛盾在党内的反映。党内如果没有矛盾和解决矛盾的思想斗争，党的生命也就停止了。\n由此看来，不论是简单的运动形式，或复杂的运动形式，不论是客观现象，或思想现象，矛盾是普遍地存在着，矛盾存在于一切过程中，这一点已经弄清楚了。但是每一过程的开始阶段，是否也有矛盾存在呢？是否每一事物的发展过程具有自始至终的矛盾运动呢？\n从苏联哲学界批判德波林学派的文章中看出，德波林学派有这样一种见解，他们认为矛盾不是一开始就在过程中出现，须待过程发展到一定的阶段才出现。那末，在那一时间以前，过程发展的原因不是由于内部的原因，而是由于外部的原因了。这样，德波林回到形而上学的外因论和机械论去了。拿这种见解去分析具体的问题，他们就看见在苏联条件下富农和一般农民之间只有差异，并无矛盾，完全同意了布哈林的意见。在分析法国革命时，他们就认为在革命前，工农资产阶级合组的第三等级中，也只有差异，并无矛盾。德波林学派这类见解是反马克思主义的。他们不知道世界上的每一差异中就已经包含着矛盾，差异就是矛盾。劳资之间，从两阶级发生的时候起，就是互相矛盾的，仅仅还没有激化而已。工农之间，即使在苏联的社会条件下，也有差异，它们的差异就是矛盾，仅仅不会激化成为对抗，不取阶级斗争的形态，不同于劳资间的矛盾；它们在社会主义建设中形成巩固的联盟，并在由社会主义走向共产主义的发展过程中逐渐地解决这个矛盾。这是矛盾的差别性的问题，不是矛盾的有无的问题。矛盾是普遍的、绝对的，存在于事物发展的一切过程中，又贯串于一切过程的始终。\n新过程的发生是什么呢？这是旧的统一和组成此统一的对立成分让位于新的统一和组成此统一的对立成分，于是新过程就代替旧过程而发生。旧过程完结了，新过程发生了。新过程又包含着新矛盾，开始它自己的矛盾发展史。\n事物发展过程的自始至终的矛盾运动，列宁指出马克思在《资本论》中模范地作了这样的分析。这是研究任何事物发展过程所必须应用的方法。列宁自己也正确地应用了它，贯彻于他的全部著作中。\n“马克思在《资本论》中，首先分析的是资产阶级社会（商品社会）里最简单的、最普通的、最基本的、最常见的、最平常的、碰到亿万次的关系——商品交换。这一分析在这个最简单的现象之中（资产阶级社会的这个‘细胞’之中）暴露了现代社会的一切矛盾（以及一切矛盾的胚芽）。往后的叙述又向我们表明了这些矛盾和这个社会各个部分总和的自始至终的发展（增长与运动两者）。”\n列宁说了上面的话之后，接着说道：“这应该是一般辩证法的……叙述（以及研究）方法。”⑽\n中国共产党人必须学会这个方法，才能正确地分析中国革命的历史和现状，并推断革命的将来。\n三　矛盾的特殊性 #  　矛盾存在于一切事物发展的过程中，矛盾贯串于每一事物发展过程的始终，这是矛盾的普遍性和绝对性，前面已经说过了。现在来说矛盾的特殊性和相对性。\n这个问题，应从几种情形中去研究。\n首先是各种物质运动形式中的矛盾，都带特殊性。人的认识物质，就是认识物质的运动形式，因为除了运动的物质以外，世界上什么也没有，而物质的运动则必取一定的形式。对于物质的每一种运动形式，必须注意它和其他各种运动形式的共同点。但是，尤其重要的，成为我们认识事物的基础的东西，则是必须注意它的特殊点，就是说，注意它和其他运动形式的质的区别。只有注意了这一点，才有可能区别事物。任何运动形式，其内部都包含着本身特殊的矛盾。这种特殊的矛盾，就构成一事物区别于他事物的特殊的本质。这就是世界上诸种事物所以有千差万别的内在的原因，或者叫做根据。自然界存在着许多的运动形式，机械运动、发声、发光、发热、电流、化分、化合等等都是。所有这些物质的运动形式，都是互相依存的，又是本质上互相区别的。每一物质的运动形式所具有的特殊的本质，为它自己的特殊的矛盾所规定。这种情形，不但在自然界中存在着，在社会现象和思想现象中也是同样地存在着。每一种社会形式和思想形式，都有它的特殊的矛盾和特殊的本质。\n科学研究的区分，就是根据科学对象所具有的特殊的矛盾性。因此，对于某一现象的领域所特有的某一种矛盾的研究，就构成某一门科学的对象。例如，数学中的正数和负数，机械学中的作用和反作用，物理学中的阴电和阳电，化学中的化分和化合，社会科学中的生产力和生产关系、阶级和阶级的互相斗争，军事学中的攻击和防御，哲学中的唯心论和唯物论、形而上学观和辩证法观等等，都是因为具有特殊的矛盾和特殊的本质，才构成了不同的科学研究的对象。固然，如果不认识矛盾的普遍性，就无从发现事物运动发展的普遍的原因或普遍的根据；但是，如果不研究矛盾的特殊性，就无从确定一事物不同于他事物的特殊的本质，就无从发现事物运动发展的特殊的原因，或特殊的根据，也就无从辨别事物，无从区分科学研究的领域。\n就人类认识运动的秩序说来，总是由认识个别的和特殊的事物，逐步地扩大到认识一般的事物。人们总是首先认识了许多不同事物的特殊的本质，然后才有可能更进一步地进行概括工作，认识诸种事物的共同的本质。当着人们已经认识了这种共同的本质以后，就以这种共同的认识为指导，继续地向着尚未研究过的或者尚未深入地研究过的各种具体的事物进行研究，找出其特殊的本质，这样才可以补充、丰富和发展这种共同的本质的认识，而使这种共同的本质的认识不致变成枯槁的和僵死的东西。这是两个认识的过程：一个是由特殊到一般，一个是由一般到特殊。人类的认识总是这样循环往复地进行的，而每一次的循环（只要是严格地按照科学的方法）都可能使人类的认识提高一步，使人类的认识不断地深化。我们的教条主义者在这个问题上的错误，就是，一方面，不懂得必须研究矛盾的特殊性，认识各别事物的特殊的本质，才有可能充分地认识矛盾的普遍性，充分地认识诸种事物的共同的本质；另一方面，不懂得在我们认识了事物的共同的本质以后，还必须继续研究那些尚未深入地研究过的或者新冒出来的具体的事物。我们的教条主义者是懒汉，他们拒绝对于具体事物做任何艰苦的研究工作，他们把一般真理看成是凭空出现的东西，把它变成为人们所不能够捉摸的纯粹抽象的公式，完全否认了并且颠倒了这个人类认识真理的正常秩序。他们也不懂得人类认识的两个过程的互相联结——由特殊到一般，又由一般到特殊，他们完全不懂得马克思主义的认识论。\n不但要研究每一个大系统的物质运动形式的特殊的矛盾性及其所规定的本质，而且要研究每一个物质运动形式在其发展长途中的每一个过程的特殊的矛盾及其本质。一切运动形式的每一个实在的非臆造的发展过程内，都是不同质的。我们的研究工作必须着重这一点，而且必须从这一点开始。\n不同质的矛盾，只有用不同质的方法才能解决。例如，无产阶级和资产阶级的矛盾，用社会主义革命的方法去解决；人民大众和封建制度的矛盾，用民主革命的方法去解决；殖民地和帝国主义的矛盾，用民族革命战争的方法去解决；在社会主义社会中工人阶级和农民阶级的矛盾，用农业集体化和农业机械化的方法去解决；共产党内的矛盾，用批评和自我批评的方法去解决；社会和自然的矛盾，用发展生产力的方法去解决。过程变化，旧过程和旧矛盾消灭，新过程和新矛盾发生，解决矛盾的方法也因之而不同。俄国的二月革命和十月革命所解决的矛盾及其所用以解决矛盾的方法是根本上不相同的。用不同的方法去解决不同的矛盾，这是马克思列宁主义者必须严格地遵守的一个原则。教条主义者不遵守这个原则，他们不了解诸种革命情况的区别，因而也不了解应当用不同的方法去解决不同的矛盾，而只是千篇一律地使用一种自以为不可改变的公式到处硬套，这就只能使革命遭受挫折，或者将本来做得好的事情弄得很坏。\n为要暴露事物发展过程中的矛盾在其总体上、在其相互联结上的特殊性，就是说暴露事物发展过程的本质，就必须暴露过程中矛盾各方面的特殊性，否则暴露过程的本质成为不可能，这也是我们作研究工作时必须十分注意的。\n一个大的事物，在其发展过程中，包含着许多的矛盾。例如，在中国资产阶级民主革命过程中，有中国社会各被压迫阶级和帝国主义的矛盾，有人民大众和封建制度的矛盾，有无产阶级和资产阶级的矛盾，有农民及城市小资产阶级和资产阶级的矛盾，有各个反动的统治集团之间的矛盾等等，情形是非常复杂的。这些矛盾，不但各各有其特殊性，不能一律看待，而且每一矛盾的两方面，又各各有其特点，也是不能一律看待的。我们从事中国革命的人，不但要在各个矛盾的总体上，即矛盾的相互联结上，了解其特殊性，而且只有从矛盾的各个方面着手研究，才有可能了解其总体。所谓了解矛盾的各个方面，就是了解它们每一方面各占何等特定的地位，各用何种具体形式和对方发生互相依存又互相矛盾的关系，在互相依存又互相矛盾中，以及依存破裂后，又各用何种具体的方法和对方作斗争。研究这些问题，是十分重要的事情。列宁说：马克思主义的最本质的东西，马克思主义的活的灵魂，就在于具体地分析具体的情况⑾。就是说的这个意思。我们的教条主义者违背列宁的指示，从来不用脑筋具体地分析任何事物，做起文章或演说来，总是空洞无物的八股调，在我们党内造成了一种极坏的作风。\n研究问题，忌带主观性、片面性和表面性。所谓主观性，就是不知道客观地看问题，也就是不知道用唯物的观点去看问题。这一点，我在《实践论》一文中已经说过了。所谓片面性，就是不知道全面地看问题。例如：只了解中国一方、不了解日本一方，只了解共产党一方、不了解国民党一方，只了解无产阶级一方、不了解资产阶级一方，只了解农民一方、不了解地主一方，只了解顺利情形一方、不了解困难情形一方，只了解过去一方、不了解将来一方，只了解个体一方、不了解总体一方，只了解缺点一方、不了解成绩一方，只了解原告一方、不了解被告一方，只了解革命的秘密工作一方、不了解革命的公开工作一方，如此等等。一句话，不了解矛盾各方的特点。这就叫做片面地看问题。或者叫做只看见局部，不看见全体，只看见树木，不看见森林。这样，是不能找出解决矛盾的方法的，是不能完成革命任务的，是不能做好所任工作的，是不能正确地发展党内的思想斗争的。孙子论军事说：“知彼知己，百战不殆。”⑿他说的是作战的双方。唐朝人魏徵说过：“兼听则明，偏信则暗。”⒀也懂得片面性不对。可是我们的同志看问题，往往带片面性，这样的人就往往碰钉子。《水浒传》上宋江三打祝家庄⒁，两次都因情况不明，方法不对，打了败仗。后来改变方法，从调查情形入手，于是熟悉了盘陀路，拆散了李家庄、扈家庄和祝家庄的联盟，并且布置了藏在敌人营盘里的伏兵，用了和外国故事中所说木马计⒂相像的方法，第三次就打了胜仗。《水浒传》上有很多唯物辩证法的事例，这个三打祝家庄，算是最好的一个。列宁说：“要真正地认识对象，就必须把握和研究它的一切方面、一切联系和‘媒介’。我们决不会完全地作到这一点，可是要求全面性，将使我们防止错误，防止僵化。”⒃我们应该记得他的话。表面性，是对矛盾总体和矛盾各方的特点都不去看，否认深入事物里面精细地研究矛盾特点的必要，仅仅站在那里远远地望一望，粗枝大叶地看到一点矛盾的形相，就想动手去解决矛盾（答复问题、解决纠纷、处理工作、指挥战争）。这样的做法，没有不出乱子的。中国的教条主义和经验主义的同志们所以犯错误，就是因为他们看事物的方法是主观的、片面的和表面的。片面性、表面性也是主观性，因为一切客观事物本来是互相联系的和具有内部规律的，人们不去如实地反映这些情况，而只是片面地或表面地去看它们，不认识事物的互相联系，不认识事物的内部规律，所以这种方法是主观主义的。\n不但事物发展的全过程中的矛盾运动，在其相互联结上，在其各方情况上，我们必须注意其特点，而且在过程发展的各个阶段中，也有其特点，也必须注意。\n事物发展过程的根本矛盾及为此根本矛盾所规定的过程的本质，非到过程完结之日，是不会消灭的；但是事物发展的长过程中的各个发展的阶段，情形又往往互相区别。这是因为事物发展过程的根本矛盾的性质和过程的本质虽然没有变化，但是根本矛盾在长过程中的各个发展阶段上采取了逐渐激化的形式。并且，被根本矛盾所规定或影响的许多大小矛盾中，有些是激化了，有些是暂时地或局部地解决了，或者缓和了，又有些是发生了，因此，过程就显出阶段性来。如果人们不去注意事物发展过程中的阶段性，人们就不能适当地处理事物的矛盾。\n例如，自由竞争时代的资本主义发展为帝国主义，这时，无产阶级和资产阶级这两个根本矛盾着的阶级的性质和这个社会的资本主义的本质，并没有变化；但是，两阶级的矛盾激化了，独占资本和自由资本之间的矛盾发生了，宗主国和殖民地的矛盾激化了，各资本主义国家间的矛盾即由各国发展不平衡的状态而引起的矛盾特别尖锐地表现出来了，因此形成了资本主义的特殊阶段，形成了帝国主义阶段。列宁主义之所以成为帝国主义和无产阶级革命时代的马克思主义，就是因为列宁和斯大林正确地说明了这些矛盾，并正确地作出了解决这些矛盾的无产阶级革命的理论和策略。\n拿从辛亥革命⒄开始的中国资产阶级民主革命过程的情形来看，也有了若干特殊阶段。特别是在资产阶级领导时期的革命和在无产阶级领导时期的革命，区别为两个很大不同的历史阶段。这就是：由于无产阶级的领导，根本地改变了革命的面貌，引出了阶级关系的新调度，农民革命的大发动，反帝国主义和反封建主义的革命彻底性，由民主革命转变到社会主义革命的可能性，等等。所有这些，都是在资产阶级领导革命时期不可能出现的。虽然整个过程中根本矛盾的性质，过程之反帝反封建的民主革命的性质（其反面是半殖民地半封建的性质），并没有变化，但是，在这长时间中，经过了辛亥革命失败和北洋军阀统治，第一次民族统一战线的建立和一九二四年至一九二七年的革命，统一战线破裂和资产阶级转入反革命，新的军阀战争，土地革命战争，第二次民族统一战线建立和抗日战争等等大事变，二十多年间经过了几个发展阶段。在这些阶段中，包含着有些矛盾激化了（例如土地革命战争和日本侵入东北四省⒅），有些矛盾部分地或暂时地解决了（例如北洋军阀的被消灭，我们没收了地主的土地），有些矛盾重新发生了（例如新军阀之间的斗争，南方各革命根据地丧失后地主又重新收回土地）等等特殊的情形。\n研究事物发展过程中的各个发展阶段上的矛盾的特殊性，不但必须在其联结上、在其总体上去看，而且必须从各个阶段中矛盾的各个方面去看。\n例如国共两党。国民党方面，在第一次统一战线时期，因为它实行了孙中山的联俄、联共、援助工农的三大政策，所以它是革命的、有朝气的，它是各阶级的民主革命的联盟。一九二七年以后，国民党变到了与此相反的方面，成了地主和大资产阶级的反动集团。一九三六年十二月西安事变⒆后又开始向停止内战、联合共产党共同反对日本帝国主义这个方面转变。这就是国民党在三个阶段上的特点。形成这些特点，当然有种种的原因。中国共产党方面，在第一次统一战线时期，它是幼年的党，它英勇地领导了一九二四年至一九二七年的革命；但在对于革命的性质、任务和方法的认识方面，却表现了它的幼年性，因此在这次革命的后期所发生的陈独秀主义⒇能够起作用，使这次革命遭受了失败。一九二七年以后，它又英勇地领导了土地革命战争，创立了革命的军队和革命的根据地，但是它也犯过冒险主义的错误，使军队和根据地都受了很大的损失。一九三五年以后，它又纠正了冒险主义的错误，领导了新的抗日的统一战线，这个伟大的斗争现在正在发展。在这个阶段上，共产党是一个经过了两次革命的考验、有了丰富的经验的党。这些就是中国共产党在三个阶段上的特点。形成这些特点也有种种的原因。不研究这些特点，就不能了解两党在各个发展阶段上的特殊的相互关系：统一战线的建立，统一战线的破裂，再一个统一战线的建立。而要研究两党的种种特点，更根本的就必须研究这两党的阶级基础以及因此在各个时期所形成的它们和其他方面的矛盾的对立。例如，国民党在它第一次联合共产党的时期，一方面有和国外帝国主义的矛盾，因而它反对帝国主义；另一方面有和国内人民大众的矛盾，它在口头上虽然允许给予劳动人民以许多的利益，但在实际上则只给予很少的利益，或者简直什么也不给。在它进行反共战争的时期，则和帝国主义、封建主义合作反对人民大众，一笔勾销了人民大众原来在革命中所争得的一切利益，激化了它和人民大众的矛盾。现在抗日时期，国民党和日本帝国主义有矛盾，它一面要联合共产党，同时它对共产党和国内人民并不放松其斗争和压迫。共产党则无论在哪一时期，均和人民大众站在一道，反对帝国主义和封建主义；但在现在的抗日时期，由于国民党表示抗日，它对国民党和国内封建势力，也就采取了缓和的政策。由于这些情况，所以或者造成了两党的联合，或者造成了两党的斗争，而且即使在两党联合的时期也有又联合又斗争的复杂的情况。如果我们不去研究这些矛盾方面的特点，我们就不但不能了解这两个党各各和其他方面的关系，也不能了解两党之间的相互关系。\n由此看来，不论研究何种矛盾的特性——各个物质运动形式的矛盾，各个运动形式在各个发展过程中的矛盾，各个发展过程的矛盾的各方面，各个发展过程在其各个发展阶段上的矛盾以及各个发展阶段上的矛盾的各方面，研究所有这些矛盾的特性，都不能带主观随意性，必须对它们实行具体的分析。离开具体的分析，就不能认识任何矛盾的特性。我们必须时刻记得列宁的话：对于具体的事物作具体的分析。\n这种具体的分析，马克思、恩格斯首先给了我们以很好的模范。\n当马克思、恩格斯把这事物矛盾的法则应用到社会历史过程的研究的时候，他们看出生产力和生产关系之间的矛盾，看出剥削阶级和被剥削阶级之间的矛盾以及由于这些矛盾所产生的经济基础和政治及思想等上层建筑之间的矛盾，而这些矛盾如何不可避免地会在各种不同的阶级社会中，引出各种不同的社会革命。\n马克思把这一法则应用到资本主义社会经济结构的研究的时候，他看出这一社会的基本矛盾在于生产的社会性和占有制的私人性之间的矛盾。这个矛盾表现于在各别企业中的生产的有组织性和在全社会中的生产的无组织性之间的矛盾。这个矛盾的阶级表现则是资产阶级和无产阶级之间的矛盾。\n由于事物范围的极其广大，发展的无限性，所以，在一定场合为普遍性的东西，而在另一一定场合则变为特殊性。反之，在一定场合为特殊性的东西，而在另一一定场合则变为普遍性。资本主义制度所包含的生产社会化和生产资料私人占有制的矛盾，是所有有资本主义的存在和发展的各国所共有的东西，对于资本主义说来，这是矛盾的普遍性。但是资本主义的这种矛盾，乃是一般阶级社会发展在一定历史阶段上的东西，对于一般阶级社会中的生产力和生产关系的矛盾说来，这是矛盾的特殊性。然而，当着马克思把资本主义社会这一切矛盾的特殊性解剖出来之后，同时也就更进一步地、更充分地、更完全地把一般阶级社会中这个生产力和生产关系的矛盾的普遍性阐发出来了。\n由于特殊的事物是和普遍的事物联结的，由于每一个事物内部不但包含了矛盾的特殊性，而且包含了矛盾的普遍性，普遍性即存在于特殊性之中，所以，当着我们研究一定事物的时候，就应当去发现这两方面及其互相联结，发现一事物内部的特殊性和普遍性的两方面及其互相联结，发现一事物和它以外的许多事物的互相联结。斯大林在他的名著《论列宁主义基础》一书中说明列宁主义的历史根源的时候，他分析了列宁主义所由产生的国际环境，分析了在帝国主义条件下已经发展到极点的资本主义的诸矛盾，以及这些矛盾使无产阶级革命成为直接实践的问题，并造成了直接冲击资本主义的良好的条件。不但如此，他又分析了为什么俄国成为列宁主义的策源地，分析了沙皇俄国当时是帝国主义一切矛盾的集合点以及俄国无产阶级所以能够成为国际的革命无产阶级的先锋队的原因。这样，斯大林分析了帝国主义的矛盾的普遍性，说明列宁主义是帝国主义和无产阶级革命时代的马克思主义；又分析了沙俄帝国主义在这一般矛盾中所具有的特殊性，说明俄国成了无产阶级革命理论和策略的故乡，而在这种特殊性中间就包含了矛盾的普遍性。斯大林的这种分析，给我们提供了认识矛盾的特殊性和普遍性及其互相联结的模范。\n马克思和恩格斯，同样地列宁和斯大林，他们对于应用辩证法到客观现象的研究的时候，总是指导人们不要带上任何的主观随意性，而必须从客观的实际运动所包含的具体的条件，去看出这些现象中的具体的矛盾、矛盾各方面的具体的地位以及矛盾的具体的相互关系。我们的教条主义者因为没有这种研究态度，所以弄得一无是处。我们必须以教条主义的失败为鉴戒，学会这种研究态度，舍此没有第二种研究法。\n矛盾的普遍性和矛盾的特殊性的关系，就是矛盾的共性和个性的关系。其共性是矛盾存在于一切过程中，并贯串于一切过程的始终，矛盾即是运动，即是事物，即是过程，也即是思想。否认事物的矛盾就是否认了一切。这是共通的道理，古今中外，概莫能外。所以它是共性，是绝对性。然而这种共性，即包含于一切个性之中，无个性即无共性。假如除去一切个性，还有什么共性呢？因为矛盾的各各特殊，所以造成了个性。一切个性都是有条件地暂时地存在的，所以是相对的。\n这一共性个性、绝对相对的道理，是关于事物矛盾的问题的精髓，不懂得它，就等于抛弃了辩证法。\n四　主要的矛盾和主要的矛盾方面 #  　在矛盾特殊性的问题中，还有两种情形必须特别地提出来加以分析，这就是主要的矛盾和主要的矛盾方面。\n在复杂的事物的发展过程中，有许多的矛盾存在，其中必有一种是主要的矛盾，由于它的存在和发展规定或影响着其他矛盾的存在和发展。\n例如在资本主义社会中，无产阶级和资产阶级这两个矛盾着的力量是主要的矛盾；其他的矛盾力量，例如，残存的封建阶级和资产阶级的矛盾，农民小资产者和资产阶级的矛盾，无产阶级和农民小资产者的矛盾，自由资产阶级和垄断资产阶级的矛盾，资产阶级的民主主义和资产阶级的法西斯主义的矛盾，资本主义国家相互间的矛盾，帝国主义和殖民地的矛盾，以及其他的矛盾，都为这个主要的矛盾力量所规定、所影响。\n半殖民地的国家如中国，其主要矛盾和非主要矛盾的关系呈现着复杂的情况。\n当着帝国主义向这种国家举行侵略战争的时候，这种国家的内部各阶级，除开一些叛国分子以外，能够暂时地团结起来举行民族战争去反对帝国主义。这时，帝国主义和这种国家之间的矛盾成为主要的矛盾，而这种国家内部各阶级的一切矛盾（包括封建制度和人民大众之间这个主要矛盾在内），便都暂时地降到次要和服从的地位。中国一八四○年的鸦片战争（21），一八九四年的中日战争（22），一九○○年的义和团战争（23）和目前的中日战争，都有这种情形。\n然而在另一种情形之下，则矛盾的地位起了变化。当着帝国主义不是用战争压迫而是用政治、经济、文化等比较温和的形式进行压迫的时候，半殖民地国家的统治阶级就会向帝国主义投降，二者结成同盟，共同压迫人民大众。这种时候，人民大众往往采取国内战争的形式，去反对帝国主义和封建阶级的同盟，而帝国主义则往往采取间接的方式去援助半殖民地国家的反动派压迫人民，而不采取直接行动，显出了内部矛盾的特别尖锐性。中国的辛亥革命战争，一九二四年至一九二七年的革命战争，一九二七年以后的十年土地革命战争，都有这种情形。还有半殖民地国家各个反动的统治集团之间的内战，例如在中国的军阀战争，也属于这一类。\n当着国内革命战争发展到从根本上威胁帝国主义及其走狗国内反动派的存在的时候，帝国主义就往往采取上述方法以外的方法，企图维持其统治：或者分化革命阵线的内部，或者直接出兵援助国内反动派。这时，外国帝国主义和国内反动派完全公开地站在一个极端，人民大众则站在另一极端，成为一个主要矛盾，而规定或影响其他矛盾的发展状态。十月革命后各资本主义国家援助俄国反动派，是武装干涉的例子。一九二七年的蒋介石的叛变，是分化革命阵线的例子。\n然而不管怎样，过程发展的各个阶段中，只有一种主要的矛盾起着领导的作用，是完全没有疑义的。\n由此可知，任何过程如果有多数矛盾存在的话，其中必定有一种是主要的，起着领导的、决定的作用，其他则处于次要和服从的地位。因此，研究任何过程，如果是存在着两个以上矛盾的复杂过程的话，就要用全力找出它的主要矛盾。捉住了这个主要矛盾，一切问题就迎刃而解了。这是马克思研究资本主义社会告诉我们的方法。列宁和斯大林研究帝国主义和资本主义总危机的时候，列宁和斯大林研究苏联经济的时候，也告诉了这种方法。万千的学问家和实行家，不懂得这种方法，结果如堕烟海，找不到中心，也就找不到解决矛盾的方法。\n不能把过程中所有的矛盾平均看待，必须把它们区别为主要的和次要的两类，着重于捉住主要的矛盾，已如上述。但是在各种矛盾之中，不论是主要的或次要的，矛盾着的两个方面，又是否可以平均看待呢？也是不可以的。无论什么矛盾，矛盾的诸方面，其发展是不平衡的。有时候似乎势均力敌，然而这只是暂时的和相对的情形，基本的形态则是不平衡。矛盾着的两方面中，必有一方面是主要的，他方面是次要的。其主要的方面，即所谓矛盾起主导作用的方面。事物的性质，主要地是由取得支配地位的矛盾的主要方面所规定的。\n然而这种情形不是固定的，矛盾的主要和非主要的方面互相转化着，事物的性质也就随着起变化。在矛盾发展的一定过程或一定阶段上，主要方面属于甲方，非主要方面属于乙方；到了另一发展阶段或另一发展过程时，就互易其位置，这是依靠事物发展中矛盾双方斗争的力量的增减程度来决定的。\n我们常常说“新陈代谢”这句话。新陈代谢是宇宙间普遍的永远不可抵抗的规律。依事物本身的性质和条件，经过不同的飞跃形式，一事物转化为他事物，就是新陈代谢的过程。任何事物的内部都有其新旧两个方面的矛盾，形成为一系列的曲折的斗争。斗争的结果，新的方面由小变大，上升为支配的东西；旧的方面则由大变小，变成逐步归于灭亡的东西。而一当新的方面对于旧的方面取得支配地位的时候，旧事物的性质就变化为新事物的性质。由此可见，事物的性质主要地是由取得支配地位的矛盾的主要方面所规定的。取得支配地位的矛盾的主要方面起了变化，事物的性质也就随着起变化。\n在资本主义社会中，资本主义已从旧的封建主义社会时代的附庸地位，转化成了取得支配地位的力量，社会的性质也就由封建主义的变为资本主义的。在新的资本主义社会时代，封建势力则由原来处在支配地位的力量转化为附庸的力量，随着也就逐步地归于消灭了，例如英法诸国就是如此。随着生产力的发展，资产阶级由新的起进步作用的阶级，转化为旧的起反动作用的阶级，以至于最后被无产阶级所推翻，而转化为私有的生产资料被剥夺和失去权力的阶级，这个阶级也就要逐步归于消灭了。人数比资产阶级多得多、并和资产阶级同时生长、但被资产阶级统治着的无产阶级，是一个新的力量，它由初期的附属于资产阶级的地位，逐步地壮大起来，成为独立的和在历史上起主导作用的阶级，以至最后夺取政权成为统治阶级。这时，社会的性质，就由旧的资本主义的社会转化成了新的社会主义的社会。这就是苏联已经走过和一切其他国家必然要走的道路。\n就中国的情形来说，帝国主义处在形成半殖民地这种矛盾的主要地位，压迫中国人民，中国则由独立国变为半殖民地。然而事情必然会变化，在双方斗争的局势中，中国人民在无产阶级领导之下所生长起来的力量必然会把中国由半殖民地变为独立国，而帝国主义则将被打倒，旧中国必然要变为新中国。\n旧中国变为新中国，还包含着国内旧的封建势力和新的人民势力之间的情况的变化。旧的封建地主阶级将被打倒，由统治者变为被统治者，这个阶级也就会要逐步归于消灭。人民则将在无产阶级领导之下，由被统治者变为统治者。这时，中国社会的性质就会起变化，由旧的半殖民地和半封建的社会变为新的民主的社会。\n这种互相转化的事情，过去已有经验。统治中国将近三百年的清朝帝国，曾在辛亥革命时期被打倒；而孙中山领导的革命同盟会，则曾经一度取得了胜利。在一九二四年至一九二七年的革命战争中，共产党和国民党联合的南方革命势力，曾经由弱小的力量变得强大起来，取得了北伐的胜利；而称雄一时的北洋军阀则被打倒了。一九二七年，共产党领导的人民力量，受了国民党反动势力的打击，变得很小了；但因肃清了自己内部的机会主义，就又逐步地壮大起来。在共产党领导的革命根据地内，农民由被统治者转化为统治者，地主则作了相反的转化。世界上总是这样以新的代替旧的，总是这样新陈代谢、除旧布新或推陈出新的。\n革命斗争中的某些时候，困难条件超过顺利条件，在这种时候，困难是矛盾的主要方面，顺利是其次要方面。然而由于革命党人的努力，能够逐步地克服困难，开展顺利的新局面，困难的局面让位于顺利的局面。一九二七年中国革命失败后的情形，中国红军在长征（24）中的情形，都是如此。现在的中日战争，中国又处在困难地位，但是我们能够改变这种情况，使中日双方的情况发生根本的变化。在相反的情形之下，顺利也能转化为困难，如果是革命党人犯了错误的话。一九二四年至一九二七年的革命的胜利，变为失败了。一九二七年以后在南方各省发展起来的革命根据地，至一九三四年都失败了。\n研究学问的时候，由不知到知的矛盾也是如此。当着我们刚才开始研究马克思主义的时候，对于马克思主义的无知或知之不多的情况，和马克思主义的知识之间，互相矛盾着。然而由于努力学习，可以由无知转化为有知，由知之不多转化为知之甚多，由对于马克思主义的盲目性改变为能够自由运用马克思主义。\n有人觉得有些矛盾并不是这样。例如，生产力和生产关系的矛盾，生产力是主要的；理论和实践的矛盾，实践是主要的；经济基础和上层建筑的矛盾，经济基础是主要的：它们的地位并不互相转化。这是机械唯物论的见解，不是辩证唯物论的见解。诚然，生产力、实践、经济基础，一般地表现为主要的决定的作用，谁不承认这一点，谁就不是唯物论者。然而，生产关系、理论、上层建筑这些方面，在一定条件之下，又转过来表现其为主要的决定的作用，这也是必须承认的。当着不变更生产关系，生产力就不能发展的时候，生产关系的变更就起了主要的决定的作用。当着如同列宁所说“没有革命的理论，就不会有革命的运动”（25）的时候，革命理论的创立和提倡就起了主要的决定的作用。当着某一件事情（任何事情都是一样）要做，但是还没有方针、方法、计划或政策的时候，确定方针、方法、计划或政策，也就是主要的决定的东西。当着政治文化等等上层建筑阻碍着经济基础的发展的时候，对于政治上和文化上的革新就成为主要的决定的东西了。我们这样说，是否违反了唯物论呢？没有。因为我们承认总的历史发展中是物质的东西决定精神的东西，是社会的存在决定社会的意识；但是同时又承认而且必须承认精神的东西的反作用，社会意识对于社会存在的反作用，上层建筑对于经济基础的反作用。这不是违反唯物论，正是避免了机械唯物论，坚持了辩证唯物论。\n在研究矛盾特殊性的问题中，如果不研究过程中主要的矛盾和非主要的矛盾以及矛盾之主要的方面和非主要的方面这两种情形，也就是说不研究这两种矛盾情况的差别性，那就将陷入抽象的研究，不能具体地懂得矛盾的情况，因而也就不能找出解决矛盾的正确的方法。这两种矛盾情况的差别性或特殊性，都是矛盾力量的不平衡性。世界上没有绝对地平衡发展的东西，我们必须反对平衡论，或均衡论。同时，这种具体的矛盾状况，以及矛盾的主要方面和非主要方面在发展过程中的变化，正是表现出新事物代替旧事物的力量。对于矛盾的各种不平衡情况的研究，对于主要的矛盾和非主要的矛盾、主要的矛盾方面和非主要的矛盾方面的研究，成为革命政党正确地决定其政治上和军事上的战略战术方针的重要方法之一，是一切共产党人都应当注意的。\n五　矛盾诸方面的同一性和斗争性 #  　在懂得了矛盾的普遍性和特殊性的问题之后，我们必须进而研究矛盾诸方面的同一性和斗争性的问题。\n同一性、统一性、一致性、互相渗透、互相贯通、互相依赖（或依存）、互相联结或互相合作，这些不同的名词都是一个意思，说的是如下两种情形：第一、事物发展过程中的每一种矛盾的两个方面，各以和它对立着的方面为自己存在的前提，双方共处于一个统一体中；第二、矛盾着的双方，依据一定的条件，各向着其相反的方面转化。这些就是所谓同一性。\n列宁说：“辩证法是这样的一种学说：它研究对立怎样能够是同一的，又怎样成为同一的（怎样变成同一的），——在怎样的条件之下它们互相转化，成为同一的，——为什么人的头脑不应当把这些对立看作死的、凝固的东西，而应当看作生动的、有条件的、可变动的、互相转化的东西。”（26）\n列宁这段话是什么意思呢？\n一切过程中矛盾着的各方面，本来是互相排斥、互相斗争、互相对立的。世界上一切事物的过程里和人们的思想里，都包含着这样带矛盾性的方面，无一例外。单纯的过程只有一对矛盾，复杂的过程则有一对以上的矛盾。各对矛盾之间，又互相成为矛盾。这样地组成客观世界的一切事物和人们的思想，并推使它们发生运动。\n如此说来，只是极不同一，极不统一，怎样又说是同一或统一呢？\n原来矛盾着的各方面，不能孤立地存在。假如没有和它作对的矛盾的一方，它自己这一方就失去了存在的条件。试想一切矛盾着的事物或人们心中矛盾着的概念，任何一方面能够独立地存在吗？没有生，死就不见；没有死，生也不见。没有上，无所谓下；没有下，也无所谓上。没有祸，无所谓福；没有福，也无所谓祸。没有顺利，无所谓困难；没有困难，也无所谓顺利。没有地主，就没有佃农；没有佃农，也就没有地主。没有资产阶级，就没有无产阶级；没有无产阶级，也就没有资产阶级。没有帝国主义的民族压迫，就没有殖民地和半殖民地；没有殖民地和半殖民地，也就没有帝国主义的民族压迫。一切对立的成分都是这样，因一定的条件，一面互相对立，一面又互相联结、互相贯通、互相渗透、互相依赖，这种性质，叫做同一性。一切矛盾着的方面都因一定条件具备着不同一性，所以称为矛盾。然而又具备着同一性，所以互相联结。列宁所谓辩证法研究“对立怎样能够是同一的”，就是说的这种情形。怎样能够呢？因为互为存在的条件。这是同一性的第一种意义。\n然而单说了矛盾双方互为存在的条件，双方之间有同一性，因而能够共处于一个统一体中，这样就够了吗？还不够。事情不是矛盾双方互相依存就完了，更重要的，还在于矛盾着的事物的互相转化。这就是说，事物内部矛盾着的两方面，因为一定的条件而各向着和自己相反的方面转化了去，向着它的对立方面所处的地位转化了去。这就是矛盾的同一性的第二种意义。\n为什么这里也有同一性呢？你们看，被统治的无产阶级经过革命转化为统治者，原来是统治者的资产阶级却转化为被统治者，转化到对方原来所占的地位。苏联已经是这样做了，全世界也将要这样做。试问其间没有在一定条件之下的联系和同一性，如何能够发生这样的变化呢？\n曾在中国近代历史的一定阶段上起过某种积极作用的国民党，因为它的固有的阶级性和帝国主义的引诱（这些就是条件），在一九二七年以后转化为反革命，又由于中日矛盾的尖锐化和共产党的统一战线政策（这些就是条件），而被迫着赞成抗日。矛盾着的东西这一个变到那一个，其间包含了一定的同一性。\n我们实行过的土地革命，已经是并且还将是这样的过程，拥有土地的地主阶级转化为失掉土地的阶级，而曾经是失掉土地的农民却转化为取得土地的小私有者。有无、得失之间，因一定条件而互相联结，二者具有同一性。在社会主义条件之下，农民的私有制又将转化为社会主义农业的公有制，苏联已经这样做了，全世界将来也会这样做。私产和公产之间有一条由此达彼的桥梁，哲学上名之曰同一性，或互相转化、互相渗透。\n巩固无产阶级的专政或人民的专政，正是准备着取消这种专政，走到消灭任何国家制度的更高阶段去的条件。建立和发展共产党，正是准备着消灭共产党和一切政党制度的条件。建立共产党领导的革命军，进行革命战争，正是准备着永远消灭战争的条件。这许多相反的东西，同时却是相成的东西。\n大家知道，战争与和平是互相转化的。战争转化为和平，例如第一次世界大战转化为战后的和平，中国的内战现在也停止了，出现了国内的和平。和平转化为战争，例如一九二七年的国共合作转化为战争，现在的世界和平局面也可能转化为第二次世界大战。为什么是这样？因为在阶级社会中战争与和平这样矛盾着的事物，在一定条件下具备着同一性。\n一切矛盾着的东西，互相联系着，不但在一定条件之下共处于一个统一体中，而且在一定条件之下互相转化，这就是矛盾的同一性的全部意义。列宁所谓“怎样成为同一的（怎样变成同一的），——在怎样的条件之下它们互相转化，成为同一的”，就是这个意思。\n“为什么人的头脑不应当把这些对立看作死的、凝固的东西，而应当看作生动的、有条件的、可变动的、互相转化的东西”呢？因为客观事物本来是如此的。客观事物中矛盾着的诸方面的统一或同一性，本来不是死的、凝固的，而是生动的、有条件的、可变动的、暂时的、相对的东西，一切矛盾都依一定条件向它们的反面转化着。这种情况，反映在人们的思想里，就成了马克思主义的唯物辩证法的宇宙观。只有现在的和历史上的反动的统治阶级以及为他们服务的形而上学，不是把对立的事物当作生动的、有条件的、可变动的、互相转化的东西去看，而是当作死的、凝固的东西去看，并且把这种错误的看法到处宣传，迷惑人民群众，以达其继续统治的目的。共产党人的任务就在于揭露反动派和形而上学的错误思想，宣传事物的本来的辩证法，促成事物的转化，达到革命的目的。\n所谓矛盾在一定条件下的同一性，就是说，我们所说的矛盾乃是现实的矛盾，具体的矛盾，而矛盾的互相转化也是现实的、具体的。神话中的许多变化，例如《山海经》中所说的“夸父追日”（27），《淮南子》中所说的“羿射九日”（28），《西游记》中所说的孙悟空七十二变（29）和《聊斋志异》（30）中的许多鬼狐变人的故事等等，这种神话中所说的矛盾的互相变化，乃是无数复杂的现实矛盾的互相变化对于人们所引起的一种幼稚的、想象的、主观幻想的变化，并不是具体的矛盾所表现出来的具体的变化。马克思说：“任何神话都是用想象和借助想象以征服自然力，支配自然力，把自然力加以形象化；因而，随着这些自然力之实际上被支配，神话也就消失了。”（31）这种神话中的（还有童话中的）千变万化的故事，虽然因为它们想象出人们征服自然力等等，而能够吸引人们的喜欢，并且最好的神话具有“永久的魅力”（32）（马克思），但神话并不是根据具体的矛盾之一定的条件而构成的，所以它们并不是现实之科学的反映。这就是说，神话或童话中矛盾构成的诸方面，并不是具体的同一性，只是幻想的同一性。科学地反映现实变化的同一性的，就是马克思主义的辩证法。\n为什么鸡蛋能够转化为鸡子，而石头不能够转化为鸡子呢？为什么战争与和平有同一性，而战争与石头却没有同一性呢？为什么人能生人不能生出其他的东西呢？没有别的，就是因为矛盾的同一性要在一定的必要的条件之下。缺乏一定的必要的条件，就没有任何的同一性。\n为什么俄国在一九一七年二月的资产阶级民主革命和同年十月的无产阶级社会主义革命直接地联系着，而法国资产阶级革命没有直接地联系于社会主义的革命，一八七一年的巴黎公社终于失败了呢？为什么蒙古和中亚细亚的游牧制度又直接地和社会主义联系了呢？为什么中国的革命可以避免资本主义的前途，可以和社会主义直接联系起来，不要再走西方国家的历史老路，不要经过一个资产阶级专政的时期呢？没有别的，都是由于当时的具体条件。一定的必要的条件具备了，事物发展的过程就发生一定的矛盾，而且这种或这些矛盾互相依存，又互相转化，否则，一切都不可能。\n同一性的问题如此。那末，什么是斗争性呢？同一性和斗争性的关系是怎样的呢？\n列宁说：“对立的统一（一致、同一、合一），是有条件的、一时的、暂存的、相对的。互相排斥的对立的斗争则是绝对的，正如发展、运动是绝对的一样。”（33）\n列宁这段话是什么意思呢？\n一切过程都有始有终，一切过程都转化为它们的对立物。一切过程的常住性是相对的，但是一种过程转化为他种过程的这种变动性则是绝对的。\n无论什么事物的运动都采取两种状态，相对地静止的状态和显著地变动的状态。两种状态的运动都是由事物内部包含的两个矛盾着的因素互相斗争所引起的。当着事物的运动在第一种状态的时候，它只有数量的变化，没有性质的变化，所以显出好似静止的面貌。当着事物的运动在第二种状态的时候，它已由第一种状态中的数量的变化达到了某一个最高点，引起了统一物的分解，发生了性质的变化，所以显出显著地变化的面貌。我们在日常生活中所看见的统一、团结、联合、调和、均势、相持、僵局、静止、有常、平衡、凝聚、吸引等等，都是事物处在量变状态中所显现的面貌。而统一物的分解，团结、联合、调和、均势、相持、僵局、静止、有常、平衡、凝聚、吸引等等状态的破坏，变到相反的状态，便都是事物在质变状态中、在一种过程过渡到他种过程的变化中所显现的面貌。事物总是不断地由第一种状态转化为第二种状态，而矛盾的斗争则存在于两种状态中，并经过第二种状态而达到矛盾的解决。所以说，对立的统一是有条件的、暂时的、相对的，而对立的互相排除的斗争则是绝对的。\n前面我们曾经说，两个相反的东西中间有同一性，所以二者能够共处于一个统一体中，又能够互相转化，这是说的条件性，即是说在一定条件之下，矛盾的东西能够统一起来，又能够互相转化；无此一定条件，就不能成为矛盾，不能共居，也不能转化。由于一定的条件才构成了矛盾的同一性，所以说同一性是有条件的、相对的。这里我们又说，矛盾的斗争贯串于过程的始终，并使一过程向着他过程转化，矛盾的斗争无所不在，所以说矛盾的斗争性是无条件的、绝对的。\n有条件的相对的同一性和无条件的绝对的斗争性相结合，构成了一切事物的矛盾运动。\n我们中国人常说：“相反相成。”（34）就是说相反的东西有同一性。这句话是辩证法的，是违反形而上学的。“相反”就是说两个矛盾方面的互相排斥，或互相斗争。“相成”就是说在一定条件之下两个矛盾方面互相联结起来，获得了同一性。而斗争性即寓于同一性之中，没有斗争性就没有同一性。\n在同一性中存在着斗争性，在特殊性中存在着普遍性，在个性中存在着共性。拿列宁的话来说，叫做“在相对的东西里面有着绝对的东西”（35）。\n六　对抗在矛盾中的地位 #  　在矛盾的斗争性的问题中，包含着对抗是什么的问题。我们回答道：对抗是矛盾斗争的一种形式，而不是矛盾斗争的一切形式。\n在人类历史中，存在着阶级的对抗，这是矛盾斗争的一种特殊的表现。剥削阶级和被剥削阶级之间的矛盾，无论在奴隶社会也好，封建社会也好，资本主义社会也好，互相矛盾着的两阶级，长期地并存于一个社会中，它们互相斗争着，但要待两阶级的矛盾发展到了一定的阶段的时候，双方才取外部对抗的形式，发展为革命。阶级社会中，由和平向战争的转化，也是如此。\n炸弹在未爆炸的时候，是矛盾物因一定条件共居于一个统一体中的时候。待至新的条件（发火）出现，才发生了爆炸。自然界中一切到了最后要采取外部冲突形式去解决旧矛盾产生新事物的现象，都有与此相仿佛的情形。\n认识这种情形，极为重要。它使我们懂得，在阶级社会中，革命和革命战争是不可避免的，舍此不能完成社会发展的飞跃，不能推翻反动的统治阶级，而使人民获得政权。共产党人必须揭露反动派所谓社会革命是不必要的和不可能的等等欺骗的宣传，坚持马克思列宁主义的社会革命论，使人民懂得，这不但是完全必要的，而且是完全可能的，整个人类的历史和苏联的胜利，都证明了这个科学的真理。\n但是我们必须具体地研究各种矛盾斗争的情况，不应当将上面所说的公式不适当地套在一切事物的身上。矛盾和斗争是普遍的、绝对的，但是解决矛盾的方法，即斗争的形式，则因矛盾的性质不同而不相同。有些矛盾具有公开的对抗性，有些矛盾则不是这样。根据事物的具体发展，有些矛盾是由原来还非对抗性的，而发展成为对抗性的；也有些矛盾则由原来是对抗性的，而发展成为非对抗性的。\n共产党内正确思想和错误思想的矛盾，如前所说，在阶级存在的时候，这是阶级矛盾对于党内的反映。这种矛盾，在开始的时候，或在个别的问题上，并不一定马上表现为对抗性的。但随着阶级斗争的发展，这种矛盾也就可能发展为对抗性的。苏联共产党的历史告诉我们：列宁、斯大林的正确思想和托洛茨基、布哈林等人的错误思想的矛盾，在开始的时候还没有表现为对抗的形式，但随后就发展为对抗的了。中国共产党的历史也有过这样的情形。我们党内许多同志的正确思想和陈独秀、张国焘（36）等人的错误思想的矛盾，在开始的时候也没有表现为对抗的形式，但随后就发展为对抗的了。目前我们党内的正确思想和错误思想的矛盾，没有表现为对抗的形式，如果犯错误的同志能够改正自己的错误，那就不会发展为对抗性的东西。因此，党一方面必须对于错误思想进行严肃的斗争，另方面又必须充分地给犯错误的同志留有自己觉悟的机会。在这样的情况下，过火的斗争，显然是不适当的。但如果犯错误的人坚持错误，并扩大下去，这种矛盾也就存在着发展为对抗性的东西的可能性。\n经济上城市和乡村的矛盾，在资本主义社会里面（那里资产阶级统治的城市残酷地掠夺乡村），在中国的国民党统治区域里面（那里外国帝国主义和本国买办大资产阶级所统治的城市极野蛮地掠夺乡村），那是极其对抗的矛盾。但在社会主义国家里面，在我们的革命根据地里面，这种对抗的矛盾就变为非对抗的矛盾，而当到达共产主义社会的时候，这种矛盾就会消灭。\n列宁说：“对抗和矛盾断然不同。在社会主义下，对抗消灭了，矛盾存在着。”（37）这就是说，对抗只是矛盾斗争的一种形式，而不是它的一切形式，不能到处套用这个公式。\n七　结　论 #  　说到这里，我们可以总起来说几句。事物矛盾的法则，即对立统一的法则，是自然和社会的根本法则，因而也是思维的根本法则。它是和形而上学的宇宙观相反的。它对于人类的认识史是一个大革命。按照辩证唯物论的观点看来，矛盾存在于一切客观事物和主观思维的过程中，矛盾贯串于一切过程的始终，这是矛盾的普遍性和绝对性。矛盾着的事物及其每一个侧面各有其特点，这是矛盾的特殊性和相对性。矛盾着的事物依一定的条件有同一性，因此能够共居于一个统一体中，又能够互相转化到相反的方面去，这又是矛盾的特殊性和相对性。然而矛盾的斗争则是不断的，不管在它们共居的时候，或者在它们互相转化的时候，都有斗争的存在，尤其是在它们互相转化的时候，斗争的表现更为显著，这又是矛盾的普遍性和绝对性。当着我们研究矛盾的特殊性和相对性的时候，要注意矛盾和矛盾方面的主要的和非主要的区别；当着我们研究矛盾的普遍性和斗争性的时候，要注意矛盾的各种不同的斗争形式的区别。否则就要犯错误。如果我们经过研究真正懂得了上述这些要点，我们就能够击破违反马克思列宁主义基本原则的不利于我们的革命事业的那些教条主义的思想；也能够使有经验的同志们整理自己的经验，使之带上原则性，而避免重复经验主义的错误。这些，就是我们研究矛盾法则的一些简单的结论。\n 　注　释\n〔1〕 见列宁《黑格尔〈哲学史讲演录〉一书摘要》（《列宁全集》第55卷，人民出版社1990年版，第213页）。\n〔2〕参见列宁《谈谈辩证法问题》：“统一物之分为两个部分以及对它的矛盾着的部分的认识……，是辩证法的实质（是辩证法的‘本质’之一，是它的基本的特点或特征之一，甚至可说是它的最基本的特点或特征）。”并参见《黑格尔〈逻辑学〉一书摘要》中关于“辩证法的要素”部分：“可以把辩证法简要地规定为关于对立面的统一的学说。这样就会抓住辩证法的核心，可是这需要说明和发挥。”（《列宁全集》第55卷，人民出版社1990年版，第305、192页）\n〔3〕德波林（一八八一——一九六三），苏联哲学家。一九二九年当选为苏联科学院院士。三十年代初，苏联哲学界发动对德波林学派的批判，认为他们犯了理论脱离实践、哲学脱离政治等唯心主义性质的错误。\n〔4〕见列宁《谈谈辩证法问题》。新的译文是：“有两种基本的（或两种可能的？或两种在历史上常见的？）发展（进化）观点：认为发展是减少和增加，是重复；以及认为发展是对立面的统一（统一物之分为两个互相排斥的对立面以及它们之间的相互关系）。”（《列宁全集》第55卷，人民出版社1990年版，第306页）\n〔5〕见《汉书·董仲舒传》。董仲舒（公元前一七九——前一○四）是孔子学派在西汉的主要代表，他曾经对汉武帝说：“道之大原出于天，天不变，道亦不变。”“道”是中国古代哲学家的通用语，它的意义是“道路”或“道理”，可作“法则”或“规律”解说。\n〔6〕 见恩格斯《反杜林论》第一编第十二节《辩证法。量和质》（《马克思恩格斯选集》第3卷，人民出版社1972年版，第160页）。\n〔7〕见列宁《谈谈辩证法问题》。新的译文是：“承认（发现）自然界的（也包括精神的和社会的）一切现象和过程具有矛盾着的、相互排斥的、对立的倾向。”（《列宁全集》第55卷，人民出版社1990年版，第306页）\n〔8〕以上所引恩格斯的三段话，均见恩格斯《反杜林论》第一编第十二节《辩证法。量和质》。其中第二段“高等数学的主要基础之一，就是矛盾……”，《反杜林论》中的原文是：“我们已经提到，高等数学的主要基础之一是这样一个矛盾：在一定条件下直线和曲线应当是一回事。高等数学还有另一个矛盾：在我们眼前相交的线，只要离开交点五六厘米，就应当认为是平行的、即使无限延长也不会相交的线。可是，高等数学利用这些和其他一些更加尖锐的矛盾获得了不仅是正确的、而且是初等数学所完全不能达到的成果。”（《马克思恩格斯选集》第3卷，人民出版社1972年版，第160—161页）\n〔9〕 见列宁《谈谈辩证法问题》（《列宁全集》第55卷，人民出版社1990年版，第305—306页）。\n〔10〕见列宁《谈谈辩证法问题》（《列宁全集》第55卷，人民出版社1990年版，第307页）。\n〔11〕 参见本卷《中国革命战争的战略问题》注〔11〕。\n〔12〕 见《孙子·谋攻》。\n〔13〕 魏徵（五八○——六四三），唐代初期的政治活动家和历史学家。本文引语见《资治通鉴》卷一百九十二。\n〔14〕《水浒传》是中国描写农民战争的著名小说。宋江是这部小说中农民武装的主要领袖。祝家庄在农民武装根据地梁山泊的附近，这个庄的统治者祝朝奉，是一个大恶霸地主。\n〔15〕木马计是希腊神话中的一个著名故事。据传说，古希腊人攻打特洛伊城，很久打不下来。后来，他们伪装撤退，在城下营房中留下了一匹腹内藏有一批勇士的大木马。特洛伊人不知道这是敌人的计策，把木马作为战利品拉进城去。深夜，勇士们走出木马，利用特洛伊人毫无戒备的时机，配合城外的军队，迅速地夺取了特洛伊城。\n〔16〕见列宁《再论工会、目前局势及托洛茨基同志和布哈林同志的错误》。新的译文是：“要真正地认识事物，就必须把握住、研究清楚它的一切方面、一切联系和‘中介’。我们永远也不会完全做到这一点，但是，全面性这一要求可以使我们防止犯错误和防止僵化。”（《列宁全集》第40卷，人民出版社1986年版，第291页）\n〔17〕 见本卷《湖南农民运动考察报告》注〔3〕。\n〔18〕 见本卷《论反对日本帝国主义的策略》注〔5〕。\n〔19〕参见本卷《关于蒋介石声明的声明》注〔1〕。\n〔20〕 见本卷《中国革命战争的战略问题》注〔4〕。\n〔21〕见本卷《论反对日本帝国主义的策略》注〔35〕。\n〔22〕一八九四年（甲午年）发生的中日战争，也称甲午战争。这次战争是日本军国主义者蓄意挑起的。日本军队先向朝鲜发动侵略并对中国的陆海军进行挑衅，继即大举侵入中国的东北。在战争中，中国军队曾经英勇作战，但是由于清朝政府的腐败以及缺乏坚决反对侵略的准备，中国方面遭到了失败。一八九五年，清朝政府和日本订立了可耻的马关条约，这个条约的主要内容是：中国割让台湾全岛及所有附属各岛屿、澎湖列岛和辽东半岛（后来在俄、德、法三国干涉下，日本同意由清政府偿付白银三千万两“赎还”该半岛），赔偿军费银二万万两，允许日本人在中国通商口岸开设工厂，开辟沙市、重庆、苏州、杭州等地为商埠。\n〔23〕 见本卷《论反对日本帝国主义的策略》注〔37〕。\n〔24〕 参见本卷《论反对日本帝国主义的策略》注〔22〕。\n〔25〕见列宁《俄国社会民主党人的任务》（《列宁全集》第2卷，人民出版社1984年版，第443页）；并见列宁《怎么办？》第一章第四节（《列宁全集》第6卷，人民出版社1986年版，第23页）。\n〔26〕见列宁《黑格尔〈逻辑学〉一书摘要》。新的译文是：“辩证法是一种学说，它研究对立面怎样才能够同一，是怎样（怎样成为）同一的——在什么条件下它们是相互转化而同一的，——为什么人的头脑不应该把这些对立面看作僵死的、凝固的东西，而应该看作活生生的、有条件的、活动的、彼此转化的东西。”（《列宁全集》第55卷，人民出版社1990年版，第90页）\n〔27〕《山海经》是一部中国古代地理著作，其中记载了不少远古的神话传说。夸父是《山海经·海外北经》上记载的一个神人。据说：“夸父与日逐走。入日，渴欲得饮，饮于河渭。河渭不足，北饮大泽。未至，道渴而死。弃其杖，化为邓林。”\n〔28〕羿是中国古代传说中的英雄，“射日”是关于他善射的著名故事。据西汉淮南王刘安（公元前二世纪人）及其门客所著《淮南子》一书说：“尧之时，十日并出，焦禾稼，杀草木，而民无所食。猰豸、凿齿、九婴、大风、封狶、修蛇，皆为民害。尧乃使羿……上射十日而下杀猰豸。……万民皆喜。”东汉著作家王逸（公元二世纪人）关于屈原诗篇《天问》的注释说：“淮南言，尧时十日并出，草木焦枯。尧命羿仰射十日，中其九日……留其一日。”\n〔29〕《西游记》是明代作家吴承恩著的一部神话小说。孙悟空是书中的主角。他是一个神猴，有七十二变的法术，能够随意变成各式各样的鸟兽虫鱼草木器物或者人形。\n〔30〕 《聊斋志异》是清代文学家蒲松龄著的短篇小说集，大部分是叙述神仙狐鬼的故事。\n〔31〕见马克思《〈政治经济学批判〉导言》（《马克思恩格斯选集》第2卷，人民出版社1972年版，第113页）。\n〔32〕见马克思《〈政治经济学批判〉导言》（《马克思恩格斯选集》第2卷，人民出版社1972年版，第114页）。\n〔33〕见列宁《谈谈辩证法问题》。新的译文是：“对立面的统一（一致、同一、均势）是有条件的、暂时的、易逝的、相对的。相互排斥的对立面的斗争是绝对的，正如发展、运动是绝对的一样。”（《列宁全集》第55卷，人民出版社1990年版，第306页）\n〔34〕见东汉著名史学家班固（三二——九二）所著《汉书·艺文志》，原文是：“诸子十家，其可观者，九家而已。皆起于王道既微，诸侯力政，时君世主，好恶殊方。是以九家之术，蜂出并作，各引一端，崇其所善，以此驰说，取合诸侯。其言虽殊，辟犹水火，相灭亦相生也。仁之与义，敬之与和，相反而皆相成也。”\n〔35〕 见列宁《谈谈辩证法问题》。新的译文是：“相对中有绝对。”（《列宁全集》第55卷，人民出版社1990年版，第307页）\n〔36〕见本卷《论反对日本帝国主义的策略》注〔24〕。\n〔37〕见列宁《在尼·布哈林〈过渡时期经济学〉一书上作的批注和评论》（《列宁全集》第60卷，人民出版社1990年版，第282页）。\n"});index.add({'id':77,'href':'/notes/docs/technology/program/advanced/algorithm/','title':"算法",'section':"编程进阶",'content':"算法 #   冒泡排序  对于一个无序的序列，每次对比两个相邻数的大小，若第i个数大于第i+1个数，两个数进行位置互换。每组排序可以选出一个最大的数，然后继续从第一个数开始进行对比，直到完成排序\n// golang func bubbleSort(nums []int) { for i := 0; i \u0026lt; len(nums)-1; i++ { for j := 0; j \u0026lt; len(nums)-1-i; j++ { if nums[j] \u0026gt; nums[j+1] { nums[j], nums[j+1] = nums[j+1], nums[j] } } } fmt.Println(nums) }  选择排序  对于一个无序的序列，从第一个数开始，每次跟接下去的数对比，若第1个数小于第i个数，两个数位置互换，每次选出最小的数，然后开始对比第二个数，直到完成排序。\n// golang func selectSort(nums []int) { for i := 0; i \u0026lt; len(nums)-1; i++ { min := i for j := i + 1; j \u0026lt; len(nums); j++ { if nums[j] \u0026lt; nums[min] { min = j } } if min != i { nums[i], nums[min] = nums[min], nums[i] } } fmt.Println(nums) }  归并排序  对于一个无序的序列，将序列用递归的方式划分成左右两个序列，然后依次排序合并序列。\n#伪代码 func sorted(int num[]){ if(num.length\u0026lt;=1){ return num[0] } leftnum = xxx rightnum = xxx sorted(leftnum[]) sorted(rightnum[]) merge(leftnum,rightnum) }  "});index.add({'id':78,'href':'/notes/docs/technology/network/','title':"网络",'section':"技术相关",'content':"网络 #  "});index.add({'id':79,'href':'/notes/docs/technology/network/protocol/','title':"网络协议",'section':"网络",'content':"网络协议 #  "});index.add({'id':80,'href':'/notes/docs/other/life/career/','title':"职业思考",'section':"人生",'content':"职业思考 #  履历 #    网络工程\n操作系统，数据库系统，软件工程，网络工程等知识学习。\n  网络工程师\n移动代维，桌面运维，布线，交换路由，网络管理\n  应用运维\n硬件，web系统，linux系统，sql server，mysql，阿里云服务\n  平台运维\n硬件，运维系统，大数据系统，内部系统，安全\n  运维开发\n运维系统开发，监控系统开发，aws、阿里云服务\n   技能 #    系统\ncentos、ubuntu，cpu、内存、磁盘\n  网络\ntcp/ip，http，dns，tls，snmp\n  数据库\nmysql、pgsql\n  开发\ngolang、python、lua、shell\n  云服务\naws，aliyun\n  k8s\n   发展方向 #   DevOps SRE 管理层   优势与未来发展 #   行业专家  "});index.add({'id':81,'href':'/notes/docs/technology/system/application/nginx/config/','title':"配置",'section':"Nginx",'content':"配置 #  user www-data; worker_processes auto; worker_rlimit_nofile 650000; pid /run/nginx.pid; events { worker_connections 76800; # multi_accept on; } http { sendfile on; tcp_nopush on; tcp_nodelay on; #keepalive_timeout 1000;  keepalive_timeout 120s 120s; keepalive_requests 1500; types_hash_max_size 2048; server_tokens off; #define request limit zone  limit_req_zone $limit zone=req_limit:1024m rate=30r/s ; limit_req_zone $limit zone=auth_limit:1024m rate=10r/s ; limit_req_status 466; #limit_req_zone $binary_remote_addr zone=testreq:800m rate=1r/s;  #define connection limit zone per ip  limit_conn_zone $limit zone=conn_limit:100m; # Gzip Settings  ##  gzip on; gzip_http_version 1.0; gzip_comp_level 2; gzip_min_length 1100; gzip_buffers 4 8k; gzip_proxied any; gzip_types # text/html is always compressed by HttpGzipModule  text/css text/javascript text/xml text/plain text/x-component application/javascript application/x-javascript application/json application/xml application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml image/jpeg image/gif image/png; #gzip_static on;  gzip_proxied expired no-cache no-store private auth; gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; gzip_vary on; # proxy config  client_max_body_size 10m; client_body_buffer_size 128k; client_header_buffer_size 10k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; server { proxy_http_version 1.1; proxy_set_header Connection \u0026#34;\u0026#34;; } } # 传输优化 # sendfile on; 一个正常的文件发送过程 1. malloc(3): 分配用于存储对象数据的本地缓冲区 2. read(2): 检索对象并将其复制到本地缓冲区 3. write(2): 将对象从本地缓冲区复制到套接字缓冲区 打开sendfile,该调用将一个对象检索到文件高速缓存，并将指针（不复制整个对象）直接传递给套接字描述符 # tcp_nodelay on; 为了避免网络拥塞，TCP协议栈通过Nagle算法实现了一种机制，该机制可以等待数据长达0.2秒，因此不会发送太小的数据包。(Nagle 算法原理是：在发出去的数据还未被确认之前，新生成的小数据先存起来，凑满一个 MSS 或者等到收到确认后再发送) tcp_nodelay在HTTP keepalive状态中使用。 # tcp_nopush on; 与nodelay相反，它优化了一次发送的数据量，而不是优化延迟。一把在高延迟的网络中使用，增加一次发送的数据量。只有在启用了 sendfile 之后才生效。 # keepalive_timeout 120s 120s; 用于客户端不发送数据后保持连接的超时时间，第二个选项为header Keep-Alive: timeout=time的时间 # 数据压缩 gzip on; gzip_http_version 1.0; gzip_comp_level 2; gzip_min_length 1100; gzip_buffers 4 8k; gzip_types text/css text/javascript text/xml text/plain text/x-component application/javascript application/x-javascript application/json application/xml application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml image/jpeg image/gif image/png; gzip_proxied expired no-cache no-store private auth; gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; gzip_vary on; # 代理优化 client_max_body_size 10m; client_body_buffer_size 128k; client_header_buffer_size 10k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; # buffer_size "});index.add({'id':82,'href':'/notes/docs/technology/leetcode/learn/linklist/','title':"链表",'section':"学习",'content':"链表 #  单向链表 #   Each node in a singly-linked list contains not only the value but also a reference field to link to the next node. By this way, the singly-linked list organizes all the nodes in a sequence.\n  CRUD #  创建一个单向链表 #  type List struct { Value {}interface Next *List } import \u0026#34;container/list\u0026#34; func list() { l := list.New() }  添加元素 #  func Append() { }  删除元素 #  func Remove() { } "});index.add({'id':83,'href':'/notes/docs/technology/other/solution/','title':"问题集锦",'section':"其他",'content':"问题集锦 #     时间同步相关\n   ssh连接相关\n   PGSQL相关\n  "});index.add({'id':84,'href':'/notes/docs/technology/security/firewall/','title':"防火墙",'section':"安全",'content':"防火墙 #  工作在主机或网络边缘，对进出的报文按事先定义的规则进行检查，并且由匹配到的规则进行处理的一组硬件或软件，甚至可能是二者的结合。\n 底层技术 #  数据包过滤 #    netfilter bpfilter nfilter   Linux防火墙 #     iptables\n   firewalld\n  "});index.add({'id':85,'href':'/notes/docs/other/','title':"非技术相关",'section':"Docs",'content':"非技术相关 #  "});index.add({'id':86,'href':'/notes/docs/technology/other/interview/other/','title':"非技术相关",'section':"面试相关",'content':"非技术相关 #  1. z #  1. 难题 #  2. 成长 #  3. 方向 #  "});index.add({'id':87,'href':'/notes/docs/technology/cloud/container/kubernetes/network/cilium/','title':"Cilium",'section':"Kubernetes 网络",'content':"Cilium #  "});index.add({'id':88,'href':'/notes/docs/technology/network/protocol/dns/','title':"DNS",'section':"网络协议",'content':"DNS #  "});index.add({'id':89,'href':'/notes/docs/technology/cloud/devops/elk/','title':"ELK",'section':"DevOps",'content':"ELK Stack #  ELK是一个实现可靠，安全地从任何来源，任何格式和 实时搜索，分析和可视化的工具\n 架构 #  ELK Stack主要由四个组件组成：\n  Filebeat: 从客户端收集日志并传送给Logstash\n  Logstash: 用于处理传入日志并传送给ElasticSearch\n  ElasticSearch: 存储日志并供Kibana查询\n  Kibana: 用于搜索和可视化日志的Web界面\n    使用 #     安装\n  日志解析\n   "});index.add({'id':90,'href':'/notes/docs/technology/cloud/container/kubernetes/','title':"Kubernetes",'section':"容器技术",'content':"Kubernetes #  What #   Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。\n  Why #  部署变化 #   传统部署时代： 早期，组织在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展，并且组织维护许多物理服务器的成本很高。\n虚拟化部署时代： 作为解决方案，引入了虚拟化功能，它允许您在单个物理服务器的 CPU 上运行多个虚拟机（VM）。虚拟化功能允许应用程序在 VM 之间隔离，并提供安全级别，因为一个应用程序的信息不能被另一应用程序自由地访问。\n因为虚拟化可以轻松地添加或更新应用程序、降低硬件成本等等，所以虚拟化可以更好地利用物理服务器中的资源，并可以实现更好的可伸缩性。\n每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。\n容器部署时代： 容器类似于 VM，但是它们具有轻量级的隔离属性，可以在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云和 OS 分发进行移植。\n容器因具有许多优势而变得流行起来。下面列出了容器的一些好处：\n 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚(由于镜像不可变性)，提供可靠且频繁的容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离。 可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 云和操作系统分发的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。   Kubernetes能做什么 #  容器是打包和运行应用程序的好方式。在生产环境中，您需要管理运行应用程序的容器，并确保不会停机。例如，如果一个容器发生故障，则需要启动另一个容器。如果系统处理此行为，会不会更容易？\n这就是 Kubernetes 的救援方法！Kubernetes 为您提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足您的扩展要求、故障转移、部署模式等。\nKubernetes 提供：\n  服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果到容器的流量很大，Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。\n  存储编排 Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。\n  自动部署和回滚 您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 来为您的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。\n  自动二进制打包 Kubernetes 允许您指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。\n  自我修复 Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。\n  密钥与配置管理 Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。您可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。\n   How #  Kubernetes架构 #    官方文档 #  "});index.add({'id':91,'href':'/notes/docs/technology/cloud/container/kubernetes/api/','title':"Kubernetes API",'section':"Kubernetes",'content':"Kubernetes API #   API协议文档描述了主系统和API概念。\n API参考文档描述了API整体规范。\n 访问文档讨论了通过远程访问API的相关问题。\nKubernetes API是系统描述性配置的基础。 Kubectl 命令行工具被用于创建、更新、删除、获取API对象。\nKubernetes 通过API资源存储自己序列化状态(现在存储在 etcd)。\nKubernetes 被分成多个组件，各部分通过API相互交互。\nAPI 变更 #  根据经验，任何成功的系统都需要随着新的用例出现或现有用例发生变化的情况下，进行相应的进化与调整。因此，我们希望Kubernetes API也可以保持持续的进化和调整。同时，在较长一段时间内，我们也希望与现有客户端版本保持良好的向下兼容性。一般情况下，增加新的API资源和资源字段不会导致向下兼容性问题发生；但如果是需要删除一个已有的资源或者字段，那么必须通过 API废弃流程来进行。\n参考 API变更文档，了解兼容性变更的要素以及如何变更API的流程。\nOpenAPI 和 API Swagger 定义 #  完整的 API 详细文档使用 OpenAPI生成.\n随着 Kubernetes 1.10 版本的正式启用，Kubernetes API 服务通过 /openapi/v2 接口提供 OpenAPI 规范。 通过设置 HTTP 标头的规定了请求的结构。\n   Header Possible Values     Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for */* or not passing this header)   Accept-Encoding gzip (not passing this header is acceptable)    在1.14版本之前，区分结构的接口通过(/swagger.json, /swagger-2.0.0.json, /swagger-2.0.0.pb-v1, /swagger-2.0.0.pb-v1.gz) 提供不同格式的 OpenAPI 规范。但是这些接口已经被废弃，并且已经在 Kubernetes 1.14 中被删除。\n获取 OpenAPI 规范的例子:\n   1.10 之前 从 1.10 开始     GET /swagger.json GET /openapi/v2 Accept: application/json   GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf   GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip    Kubernetes实现了另一种基于Protobuf的序列化格式，该格式主要用于集群内通信，并在 设计方案中进行了说明，每个模式的IDL文件位于定义API对象的Go软件包中。 在 1.14 版本之前， Kubernetes apiserver 也提供 API 服务用于返回 Swagger v1.2 Kubernetes API 规范通过 /swaggerapi 接口. 但是这个接口已经被废弃，并且在 Kubernetes 1.14 中已经被移除。\nAPI 版本 #  为了使删除字段或者重构资源表示更加容易，Kubernetes 支持 多个API版本。每一个版本都在不同API路径下，例如 /api/v1 或者 /apis/extensions/v1beta1。\n我们选择在API级别进行版本化，而不是在资源或字段级别进行版本化，以确保API提供清晰，一致的系统资源和行为视图，并控制对已废止的API和/或实验性API的访问。 JSON和Protobuf序列化模式遵循架构更改的相同准则 - 下面的所有描述都同时适用于这两种格式。\n请注意，API版本控制和软件版本控制只有间接相关性。 API和发行版本建议 描述了API版本与软件版本之间的关系。\n不同的API版本名称意味着不同级别的软件稳定性和支持程度。 每个级别的标准在 API变更文档中有更详细的描述。 内容主要概括如下：\n Alpha 测试版本：  版本名称包含了 alpha (例如：v1alpha1)。 可能是有缺陷的。启用该功能可能会带来隐含的问题，默认情况是关闭的。 支持的功能可能在没有通知的情况下随时删除。 API的更改可能会带来兼容性问题，但是在后续的软件发布中不会有任何通知。 由于bugs风险的增加和缺乏长期的支持，推荐在短暂的集群测试中使用。   Beta 测试版本：  版本名称包含了 beta (例如: v2beta3)。 代码已经测试过。启用该功能被认为是安全的，功能默认已启用。 所有已支持的功能不会被删除，细节可能会发生变化。 对象的模式和/或语义可能会在后续的beta测试版或稳定版中以不兼容的方式进行更改。 发生这种情况时，我们将提供迁移到下一个版本的说明。 这可能需要删除、编辑和重新创建API对象。执行编辑操作时需要谨慎行事，这可能需要停用依赖该功能的应用程序。 建议仅用于非业务关键型用途，因为后续版本中可能存在不兼容的更改。 如果您有多个可以独立升级的集群，则可以放宽此限制。 请尝试我们的 beta 版本功能并且给出反馈！一旦他们退出 beta 测试版，我们可能不会做出更多的改变。   稳定版本：  版本名称是 vX，其中 X 是整数。 功能的稳定版本将出现在许多后续版本的发行软件中。    API 组 #  为了更容易地扩展Kubernetes API，我们实现了 API组。 API组在REST路径和序列化对象的 apiVersion 字段中指定。\n目前有几个API组正在使用中：\n 核心组（通常被称为遗留组）位于REST路径 /api/v1 并使用 apiVersion：v1。 指定的组位于REST路径 /apis/$GROUP_NAME/$VERSION，并使用 apiVersion：$GROUP_NAME/$VERSION （例如 apiVersion：batch/v1）。 在 Kubernetes API参考中可以看到支持的API组的完整列表。  社区支持使用以下两种方式来提供自定义资源对API进行扩展 自定义资源：\n  CustomResourceDefinition 适用于具有非常基本的CRUD需求的用户。 需要全套Kubernetes API语义的用户可以实现自己的apiserver， 并使用 聚合器 为客户提供无缝的服务。  启用 API 组 #  某些资源和API组默认情况下处于启用状态。 可以通过在apiserver上设置 --runtime-config 来启用或禁用它们。 --runtime-config 接受逗号分隔的值。 例如：要禁用batch/v1，请设置 --runtime-config=batch/v1=false，以启用batch/v2alpha1，请设置--runtime-config=batch/v2alpha1。 该标志接受描述apiserver的运行时配置的逗号分隔的一组键值对。\n 说明： 启用或禁用组或资源需要重新启动apiserver和控制器管理器来使得 --runtime-config 更改生效。\n 启用 extensions/v1beta1 组中资源 #  在 extensions/v1beta1 API 组中，DaemonSets，Deployments，StatefulSet, NetworkPolicies, PodSecurityPolicies 和 ReplicaSets 是默认禁用的。 例如：要启用 deployments 和 daemonsets，请设置 --runtime-config=extensions/v1beta1/deployments=true,extensions/v1beta1/daemonsets=true。\n 说明： 出于遗留原因，仅在 extensions / v1beta1 API 组中支持各个资源的启用/禁用。\n "});index.add({'id':92,'href':'/notes/docs/technology/database/nosql/','title':"NoSQL",'section':"数据库",'content':"NoSQL #  "});index.add({'id':93,'href':'/notes/docs/technology/program/language/python/','title':"Python",'section':"编程语言",'content':"Python #  基础语法 #    数据类型\n  流控\n  函数\n  模块\n   常用库 #   CookBook #     数据和算法\n   字符串和文本\n   框架 #     Flask\n   Scrapy\n   Django\n  "});index.add({'id':94,'href':'/notes/docs/technology/leetcode/learn/bintree/','title':"二叉树",'section':"学习",'content':"二叉树 #   树是模拟分层树结构的常用数据结构。\n树的每个节点将具有一个根值和对其他称为子节点的节点的引用列表。从图的角度看，树也可以定义为有向无环图，它具有N个节点和N-1个边。\n二叉树是最典型的树结构之一。顾名思义，二叉树是一种树数据结构，其中每个节点最多具有两个子节点，分别称为左子节点和右子节点。\n  遍历 #  前序遍历 #  根结点 \u0026mdash;\u0026gt; 左子树 \u0026mdash;\u0026gt; 右子树\n中序遍历 #  左子树\u0026mdash;\u0026gt; 根结点 \u0026mdash;\u0026gt; 右子树\n后序遍历 #  左子树 \u0026mdash;\u0026gt; 右子树 \u0026mdash;\u0026gt; 根结点\n层次遍历 #  广度优先 #  深度优先 #  "});index.add({'id':95,'href':'/notes/docs/technology/security/ids/','title':"入侵检测",'section':"安全",'content':"IDS #  入侵检测系统\n HIDS #  OSSEC\nNIDS #  snort\nFiresystem #  tripware\n"});index.add({'id':96,'href':'/notes/docs/technology/program/language/golang/memory/','title':"内存模型",'section':"Golang",'content':"内存模型 #  "});index.add({'id':97,'href':'/notes/docs/technology/system/linux/kernel/','title':"内核",'section':"Linux系统",'content':"内核编译 #  概念 #  内核指的是一个提供硬件抽象层、磁盘及文件系统控制、多任务等功能的系统软件。\n一般保存在/boot目录中，格式为/boot/vmlinuz-XXX\n 为什么要编译内核 #    需要新功能支持\n  原核心过于臃肿\n  与硬件搭配的稳定性\n  其他特殊需求\n   编译内核 #    下载源码包， https://www.kernel.org/\n  解压内核包，一般放在/usr/src/kernels目录下\n tar -Jxf /root/linux-3.16.39.tar.xz -C /usr/src/kernels/    进入内核目录\n cd /usr/src/kernels/linux-3.16.39    查看内核目录( 目录说明)\n ls -d ./*/ ./arch/ ./crypto/ ./drivers/ ./fs/ ./init/ ./kernel/ ./mm/ ./samples/ ./security/ ./tools/ ./virt/ ./block/ ./Documentation/ ./firmware/ ./include/ ./ipc/ ./lib/ ./net/ ./scripts/ ./sound/ ./usr/    清空源代码的其他信息\n下载下来的源码包一般情况下不确定是否已经编译过，或者还残留有生成的一起文件，为了编译时不会出现未知的错误，进行清理。\n make mrproper    核心功能挑选(生成.config文件)( 选择界面说明)\n yum install ncurses-devel -y make menuconfig    生成bzImage内核 arch/x86/boot/bzImage\n make -j 4 clean make -j 4 bzImage ll arch/x86/boot/bzImage    编译安装模块\n make -j 4 modules make modules_install    手动添加内核\n #拷贝内核文件到/boot目录底下 cp arch/x86/boot/bzImage /boot/vmlinuz-`basename /lib/modules/3.16.39/` #备份.config文件 cp .config /boot/config-`basename /lib/modules/3.16.39/` #添加可执行权限 chmod a+x /boot/vmlinuz-3.16.39 #拷贝系统内核映射文件 cp System.map /boot/System.map-`basename /lib/modules/3.16.39/` #拷贝内核模块列表 gzip -c Module.symvers \u0026gt; /boot/symvers-`basename /lib/modules/3.16.39/`.gz    配置grub\n#生成对应版本的initramfs文件 dracut -v /boot/initramfs-`basename /lib/modules/3.16.39/` 3.16.39 #更新grub.cfg配置，加入新内核记录 grub2-mkconfig -o /boot/grub2/grub.cfg    查看grub配置/boot/grub2/grub.conf\n   重启机器，选择新内核启动\n   目录说明   arch：与硬件平台有关的项目，大部分指的是CPU的类型，例如x86,x86_64,Xen虚拟支持等。\n  block：与成组设备较相关的设定数据，区块数据通常指一些大量存储媒体，还包括类似ext3等文件系统的支持是否允许等。\n  crypto：核心所支持的加密技术，如md5、des、sha512等。\n  Documentation：与核心有关的一堆说明文件，其中包括了对上面所有目录里的说明。\n  firmware：一些旧式硬件的微脚步数据。\n  fs：内核所支持的filesystems（文件系统），例如ext系列、ntfs、reisefs等。\n  include：一些可让其它过程调用的标头(header)定义数据。\n  init：一些初始化的定义功能，包括挂载和init 程序的呼叫等。\n  ipc：定义Linux操作系统内各程序进程间的通信。\n  kernel：定义核心的程序、核心状态、线程、程序的排程(schedule)、程序的讯号(signle)等。\n  lib：一些函数库。\n  mm：与内存单元有关的各项数据，包括swap与虚拟内存等。\n  net：与网络有关的各项协议数据，还有防火墙模块(net/ipv4/netfilter/*) 等。\n  security：包括selinux等在内的安全性设定。\n  sound：与音效有关的各项模块。\n  virt：与虚拟化机器有关的信息，目前核心支持的是KVM( Kernel base Vitual Machine )。\n   选择界面说明   make help： 支持“更新模式进行配置”。\n  make menuconfig： 基于curses的文本窗口界面\n  make gconfig： 基于GTK(GOME)环境窗口界面\n  make xconfig： 基于QT(KDE) 环境的窗口界面\n  make config： 老旧的命令行遍历方式逐一配置每个可配置的选项\n  make oldconfig： 透过已经存在的./.config文件内容，并使用该文件内设定值为默认值，只将新版本核心的新功能列出让用户选择，可以简化核心功能挑选过程。对与升级内核很好选择。\n  make defconfig： 基于内核为目标平台执行提供的“默认”配置进行配置\n  make allyesconfig： 所有选项均回答为”yes”\n  make allnoconfig： 所有选项均回答为”no”\n  "});index.add({'id':98,'href':'/notes/docs/technology/system/application/','title':"应用",'section':"系统",'content':"应用 #  "});index.add({'id':99,'href':'/notes/docs/technology/cloud/container/kubernetes/object/extension/','title':"扩展与插件",'section':"Kubernetes 对象",'content':"扩展与插件 #  "});index.add({'id':100,'href':'/notes/docs/technology/system/basic/os/','title':"操作系统",'section':"计算机基础",'content':"操作系统 #  操作系统(operating system)：是管理计算机硬件与软件资源的计算机程序，同时也是计算机系统的内核与基石。操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。\n 结构 #    驱动程序：最底层的、直接控制和监视各类硬件的部分，它们的职责是隐藏硬件的具体细节，并向其他部分提供一个抽象的、通用的接口。\n  内核：操作系统之最内核部分，通常运行在最高特权级，负责提供基础性、结构性的功能。\n  函数库(接口库)：是一系列特殊的程序库，它们职责在于把系统所提供的基本服务包装成应用程序所能够使用的编程接口（API），是最靠近应用程序的部分。\n  外围：所谓外围，是指操作系统中除以上三类以外的所有其他部分，通常是用于提供特定高级服务的部件。\n  图示：\n  Linux系统架构： #    功能 #  操作系统位于底层硬件与用户之间，是两者沟通的桥梁。用户可以通过操作系统的用户界面，输入命令。操作系统则对命令进行解释，驱动硬件设备，实现用户要求。以现代标准而言，一个标准PC的操作系统应该提供以下的功能：\n  进程管理（Processing management）\n  内存管理（Memory management）\n  文件系统（File system）\n  网络通信（Networking）\n  安全机制（Security）\n  用户界面（User interface）\n  驱动程序（Device drivers）\n  "});index.add({'id':101,'href':'/notes/docs/technology/cloud/service_mesh/','title':"服务网格",'section':"云原生",'content':"服务网格 #  "});index.add({'id':102,'href':'/notes/docs/technology/other/interview/classic/','title':"经典问题",'section':"面试相关",'content':"经典问题 #  1. 当输入google.com时，发生了什么？ #  "});index.add({'id':103,'href':'/notes/docs/technology/program/','title':"编程",'section':"技术相关",'content':"编程 #  "});index.add({'id':104,'href':'/notes/docs/technology/program/language/','title':"编程语言",'section':"编程",'content':"编程语言 #  "});index.add({'id':105,'href':'/notes/docs/technology/program/advanced/design/','title':"设计模式",'section':"编程进阶",'content':"设计模式 #  设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。\n 分类 #  创建型模式 #  创建型模式(Creational Pattern)对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。\n创建型模式隐藏了类的实例的创建细节，通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的。\n   简单工厂模式\n   工厂方法模式\n   抽象工厂模式\n   建造者模式\n   原型模式\n   单例模式\n   结构型模式 #   行为型模式 #  "});index.add({'id':106,'href':'/notes/docs/other/read/','title':"阅读",'section':"非技术相关",'content':"阅读 #  "});index.add({'id':107,'href':'/notes/docs/technology/other/interview/learn/','title':"面试学习",'section':"面试相关",'content':"#  考察点 #   工作经验 文化契合度 编程技能 分析能力   常见错误 #   只在计算机上练习 不做行为面试题演练 不做模拟面试训练 试图死记硬背答案 不大声说出你的解题思路 过于仓促 代码不够严谨 不做测试 修正错误漫不经心 轻言放弃   技术必备 #     数据结构 算法 概念     链表 广度优先 位操作   二叉树 深度优先 单例设计模式   单词查找树 二分查找 工厂设计模式   栈 归并排序 内存(栈和堆)   队列 快速排序 递归   向量|数组列表 树的查找、插入等 大O   散列表       技术考察点 #   基础知识 高质量代码 清晰的思路 效率优化 综合能力(沟通、学习、发散思维)   "});index.add({'id':108,'href':'/notes/docs/technology/other/interview/','title':"面试相关",'section':"其他",'content':"面试相关 #  面试学习 #  工作总结 #  技术知识点 #  非技术相关 #  经典问题 #  针对性 #  面试总结 #  100个问题 #  岗位要求 #  "});index.add({'id':109,'href':'/notes/docs/technology/cloud/container/kubernetes/network/aws/','title':"AWS VPC CNI",'section':"Kubernetes 网络",'content':"AWS VPC CNI #  Goal #  K8S网络需求 #   Pod之间的通信不需要通过NAT转换 Node和Pod通信不需要通过NAT转换 Pod所看到的IP地址与其他人所看到的IP地址相同   K8S运行在AWS VPC上的目标 #   Pod联网必须支持与用户从EC2联网中获得的特性相当的高吞吐量和可用性，低延迟和最小抖动 可以使用跟EC2一样的网络安全组 网络操作必须简单安全。用户必须能够应用现有的AWS VPC网络和安全最佳实践，以通过AWS VPC构建Kubernetes集群 只需几秒钟即可设置Pod网络 管理员应能够将群集扩展到2000个节点   方案 #   为每个Node(ec2)创建多个弹性网络接口(ENIs)，并分配secondary IP 对于每个Pod，选择一个可用的secondary IP，将其分配给Pod，并实现以下功能：  在单个主机上进行Pod到Pod的通信 在不同主机上进行Pod到Pod的通信 允许在Pod和AWS服务进行通信 允许Pod和本地数据中心进行通信 允许Pod和Internet进行通信     在EC2-VPC里，每个实例可以创建多个ENI，每个ENI可以分配多个IP地址。 任何发往这些IP地址之一的数据包，EC2-VPC都会将该数据包传递到实例。\nENI是虚拟网络接口，您可以将其附加到VPC中的实例。 将ENI附加到实例后，将创建一个对应的接口。 主ENI IP地址会自动分配给该接口。 所有辅助地址均未分配，并且由主机所有者决定如何配置它们。\n  架构 #  Pod To Pod #    Inside a Pod #  IP address\n# ip addr show 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3: eth0@if173: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc noqueue state UP group default link/ether 6a:f3:a1:ff:38:a8 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.31.176.184/32 scope global eth0 valid_lft forever preferred_lft forever route\n# ip route show default via 169.254.1.1 dev eth0 169.254.1.1 dev eth0 scope link static arp\n# arp -a 172-31-177-243.node-exporter.monitoring.svc.cluster.local (172.31.177.243) at 8e:6b:e1:80:7c:de [ether] on eth0 _gateway (169.254.1.1) at 8e:6b:e1:80:7c:de [ether] PERM on eth0 On Host side #  ip address\n# ip addr show 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc mq state UP group default qlen 1000 link/ether 02:b1:bf:9a:b2:cb brd ff:ff:ff:ff:ff:ff inet 172.31.177.243/23 brd 172.31.177.255 scope global dynamic eth0 valid_lft 2539sec preferred_lft 2539sec inet6 fe80::b1:bfff:fe9a:b2cb/64 scope link valid_lft forever preferred_lft forever 8: eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc mq state UP group default qlen 1000 link/ether 02:cd:2d:55:75:29 brd ff:ff:ff:ff:ff:ff inet 172.31.177.128/23 brd 172.31.177.255 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::cd:2dff:fe55:7529/64 scope link valid_lft forever preferred_lft forever 173: enic614534eb15@if3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc noqueue state UP group default link/ether 8e:6b:e1:80:7c:de brd ff:ff:ff:ff:ff:ff link-netnsid 3 inet6 fe80::8c6b:e1ff:fe80:7cde/64 scope link valid_lft forever preferred_lft forever 通过路由表控制Pod的出入流量\n  main route控制进入pod的流量\n# ip route show default via 172.31.176.1 dev eth0 169.254.169.254 dev eth0 172.31.176.0/23 dev eth0 proto kernel scope link src 172.31.177.243 172.31.176.184 dev enic614534eb15 scope link # \u0026lt;----- Pod\u0026#39;s IP   每个ENI都有自己的路由表，该路由表用于路由Pod的传出流量。\n# ip route show table 2 default via 172.31.176.1 dev eth1 172.31.176.1 dev eth1 scope link   需要给pod ip配置策略路由，否则流量无法走到ENI的路由表\n# ip rule list 0:\tfrom all lookup local 512:\tfrom all to 172.31.176.184 lookup main --\u0026gt; 到Pod的流量走默认路由表 1024:\tfrom all fwmark 0x80/0x80 lookup main 1536:\tfrom 172.31.176.184 lookup 2 --\u0026gt; 从Pod出来的流量走ENI自己的路由表 32766:\tfrom all lookup main 32767:\tfrom all lookup default   CNI插件执行的操作 #    创建veth pair，一个放到主机的namespace，一个放到Pod\u0026rsquo;s namespace\nip link add veth-1 type veth peer name veth-1c /* on host namespace */ ip link set veth-1c netns ns1 /* move veth-1c to Pod\u0026#39;s namespace ns1 */ ip link set veth-1 up /* bring up veth-1 */ ip netns exec ns1 ip link set veth-1c up /* bring up veth-1c */   获取分配给实例的secondary IP地址，并在Pod的namespace中执行以下操作：\n 分配IP给Pod的eth0 添加默认网关和默认路由到Pod的路由表 给默认网关添加静态ARP条目  /* To assign IP address 172.31.176.184 to Pod\u0026#39;s namespace ns1 */ ip netns exec ns1 ip addr add 172.31.176.184/32 dev veth-1c /* assign a IP address to veth-1c */ ip netns exec ns1 ip route add 169.254.1.1 dev veth-1c /* add default gateway */ ip netns exec ns1 ip route add default via 169.254.1.1 dev veth-1c /* add default route */ ip netns exec ns1 arp -i veth-1c -s 169.254.1.1 \u0026lt;veth-1\u0026#39;s mac\u0026gt; /* add static ARP entry for default gateway */   在主机上添加到Pod的路由\n/* Pod\u0026#39;s IP address is 172.31.176.184 */ ip route add 172.31.176.184/32 dev veth-1 /* add host route */   流量过程 #  #以172.31.176.184为例说明node1\u0026#39;s pod1 to node2\u0026#39;s pod2的流量发出过程 1. pod1的默认出口为169.254.1.1(mac地址为veth pair的另一端) 2. 匹配策略路由from 172.31.176.184 lookup 2 3. 匹配路由表2 default via 172.31.176.1 dev eth1，流量从node1的eth1出口出去 4. EC2-VPC流量转发到node2的ethX #通过172.31.176.184为例解释node2\u0026#39;s pod2的接收过程 5. 流量进入node2的eth1接口 6. 匹配策略路由from all to 172.31.176.184 lookup main 7. 匹配路由表main 172.31.176.184 dev enic614534eb15 scope link,流量发往enic614534eb15接口 8. 通过veth pair传输给pod2   Pod To External #   AWS_VPC_K8S_CNI_EXTERNALSNAT = False #  使用iptables SNAT规则，将pod ip转换成主ENI的主IP地址\n-A POSTROUTING ! -d \u0026lt;VPC-CIDR\u0026gt; -m comment --comment \u0026quot;kubenetes: SNAT for outbound traffic from cluster\u0026quot; -m addrtype ! --dst-typ AWS_VPC_K8S_CNI_EXTERNALSNAT = True #  当将SNAT功能关闭后，无法通过主ENI的主IP地址做外网映射，此时需要给对应的ENI的主IP地址配置对应的外网IP，或者给子网配置默认网关\n https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md\n"});index.add({'id':110,'href':'/notes/docs/technology/program/language/javascript/','title':"Javascript",'section':"编程语言",'content':"Javascript #  "});index.add({'id':111,'href':'/notes/docs/technology/cloud/container/kubernetes/object/','title':"Kubernetes 对象",'section':"Kubernetes",'content':"Kubernetes 对象 #  在 Kubernetes 系统中，Kubernetes 对象 是持久化的实体。Kubernetes 使用这些实体去表示整个集群的状态。特别地，它们描述了如下信息：\n 哪些容器化应用在运行（以及在哪个 Node 上） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略  Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态（Desired State）。\n操作 Kubernetes 对象 —— 无论是创建、修改，或者删除 —— 需要使用 Kubernetes API。比如，当使用 kubectl 命令行接口时，CLI 会执行必要的 Kubernetes API 调用，也可以在程序中使用 客户端库 直接调用 Kubernetes API。\n 对象Spec与Status #  每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置：对象 spec 和 对象 status 。 spec 是必需的，它描述了对象的 期望状态（Desired State） —— 希望对象所具有的特征。 status 描述了对象的 实际状态（Actual State） ，它是由 Kubernetes 系统提供和更新的。在任何时刻，Kubernetes 控制面一直努力地管理着对象的实际状态以与期望状态相匹配。\n 描述 Kubernetes 对象 #  当创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态，以及关于对象的一些基本信息（例如名称）。 当使用 Kubernetes API 创建对象时（或者直接创建，或者基于kubectl），API 请求必须在请求体中包含 JSON 格式的信息。 大多数情况下，需要在 .yaml 文件中为 kubectl 提供这些信息。 kubectl 在发起 API 请求时，将这些信息转换成 JSON 格式。\n这里有一个 .yaml 示例文件，展示了 Kubernetes Deployment 的必需字段和对象规约：\napiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 使用类似于上面的 .yaml 文件来创建 Deployment，一种方式是使用 kubectl 命令行接口（CLI）中的 kubectl apply 命令， 将 .yaml 文件作为参数。下面是一个示例：\nkubectl apply -f https://k8s.io/examples/application/deployment.yaml --record 输出类似如下这样：\ndeployment.apps/nginx-deployment created 必需字段 #  在想要创建的 Kubernetes 对象对应的 .yaml 文件中，需要配置如下的字段：\n apiVersion - 创建该对象所使用的 Kubernetes API 的版本 kind - 想要创建的对象的类型 metadata - 帮助识别对象唯一性的数据，包括一个 name 字符串、UID 和可选的 namespace  您也需要提供对象的 spec 字段。对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。 Kubernetes API 参考能够帮助我们找到任何我们想创建的对象的 spec 格式。\n"});index.add({'id':112,'href':'/notes/docs/technology/cloud/microservice/','title':"微服务",'section':"云原生",'content':"微服务 #  "});index.add({'id':113,'href':'/notes/docs/technology/database/','title':"数据库",'section':"技术相关",'content':"数据库 #  "});index.add({'id':114,'href':'/notes/docs/technology/program/language/golang/framework/','title':"框架",'section':"Golang",'content':"框架 #  "});index.add({'id':115,'href':'/notes/docs/other/financial/','title':"理财",'section':"非技术相关",'content':"理财 #  "});index.add({'id':116,'href':'/notes/docs/technology/system/linux/programming/','title':"系统编程",'section':"Linux系统",'content':"系统编程 #  "});index.add({'id':117,'href':'/notes/docs/technology/program/advanced/','title':"编程进阶",'section':"编程",'content':"编程进阶 #  "});index.add({'id':118,'href':'/notes/docs/technology/other/book_notes/','title':"读书笔记",'section':"其他",'content':"读书笔记 #     操作系统思考\n   CS50\n   codecademy\n  "});index.add({'id':119,'href':'/notes/docs/technology/other/interview/target/','title':"针对性",'section':"面试相关",'content':"针对性 #  公司 + 岗位\n"});index.add({'id':120,'href':'/notes/docs/technology/cloud/container/kubernetes/network/','title':"Kubernetes 网络",'section':"Kubernetes",'content':"Kubernetes 网络 #  集群网络系统是 Kubernetes 的核心部分，但是想要准确了解它的工作原理可是个不小的挑战。下面列出的是网络系统的的四个主要问题：\n 高度耦合的容器间通信：这个已经被 pods 和 localhost 通信解决了。 Pod 间通信：这个是本文档的重点要讲述的。 Pod 和 Service 间通信：这个已经在 services 里讲述过了。 外部和 Service 间通信：这个也已经在 services 讲述过了。  Kubernetes 的宗旨就是在应用之间共享机器。通常来说，共享机器需要两个应用之间不能使用相同的端口，但是在多个应用开发者之间去大规模地协调端口是件很困难的事情，尤其是还要让用户暴露在他们控制范围之外的集群级别的问题上。\n动态分配端口也会给系统带来很多复杂度 - 每个应用都需要设置一个端口的参数，而 API 服务器还需要知道如何将动态端口数值插入到配置模块中，服务也需要知道如何找到对方等等。与其去解决这些问题，Kubernetes 选择了其他不同的方法。\nKubernetes 网络模型 #  每一个 Pod 都有它自己的IP地址，这就意味着你不需要显式地在每个 Pod 之间创建链接，你几乎不需要处理容器端口到主机端口之间的映射。这将创建一个干净的、向后兼容的模型，在这个模型里，从端口分配、命名、服务发现、负载均衡、应用配置和迁移的角度来看，Pod 可以被视作虚拟机或者物理主机。\nKubernetes 对所有网络设施的实施，都需要满足以下的基本要求（除非有设置一些特定的网络分段策略）：\n 节点上的 pods 可以不通过 NAT 和其他任何节点上的 pods 通信 节点上的代理（比如：系统守护进程、kubelet） 可以和节点上的所有pods通信  备注：仅针对那些支持 Pods 在主机网络中运行的平台(比如：Linux) ：\n 那些运行在节点的主机网络里的 pods 可以不通过 NAT 和所有节点上的 pods 通信  这个模型不仅不复杂，而且还和 Kubernetes 的实现廉价的从虚拟机向容器迁移的初衷相兼容，如果你的工作开始是在虚拟机中运行的，你的虚拟机有一个 IP ，这样就可以和其他的虚拟机进行通信，这是基本相同的模型。\nKubernetes 的 IP 地址存在于 Pod 范围内 - 容器分享他们的网络命名空间 - 包括他们的 IP 地址。这就意味着 Pod 内的容器都可以通过 localhost 到达各个端口。这也意味着 Pod 内的容器都需要相互协调端口的使用，但是这和虚拟机中的进程似乎没有什么不同，这也被称为“一个 pod 一个 IP” 模型。\n如何实现这一点是正在使用的容器运行时的特定信息。\n也可以在 node 本身通过端口去请求你的 Pod （称之为主机端口），但这是一个很特殊的操作。转发方式如何实现也是容器运行时的细节。Pod 自己并不知道这些主机端口是否存在。\n如何实现 Kubernetes 的网络模型 #  有很多种方式可以实现这种网络模型，本文档并不是对各种实现技术的详细研究，但是希望可以作为对各种技术的详细介绍，并且成为你研究的起点。\n接下来的网络技术是按照首字母排序，并无其他任何含义。\nACI #   Cisco Application Centric Infrastructure 提供了一个集成覆盖和底层 SDN 解决方案来支持容器、虚拟机和其他裸机服务器。 ACI 为ACI提供了容器网络集成。点击 这里查看概述\nAntrea #   Antrea 项目是一个开源的，旨在成为 Kubernetes 原生的网络解决方案。它利用 Open vSwitch 作为网络数据平面。Open vSwitch 是一个高性能可编程的虚拟交换机，支持 Linux 和 Windows 平台。Open vSwitch 使 Antrea 能够以高性能和高效的方式实现 Kubernetes 的网络策略。借助 Open vSwitch 可编程的特性， Antrea 能够在 Open vSwitch 之上实现广泛的网络，安全功能和服务。\nApstra 中的 AOS #   AOS 是一个基于意图的网络系统，可以通过一个简单的集成平台创建和管理复杂的数据中心环境。AOS 利用高度可扩展的分布式设计来消除网络中断，同时将成本降至最低。\nAOS 参考设计当前支持三层连接的主机，这些主机消除了旧的两层连接的交换问题。这些三层连接的主机可以是 Linux（Debian、Ubuntu、CentOS）系统，它们直接在机架式交换机（TOR）的顶部创建 BGP 邻居关系。AOS 自动执行路由邻接，然后提供对 Kubernetes 部署中常见的路由运行状况注入（RHI）的精细控制。\nAOS 具有一组丰富的 REST API 端点，这些端点使 Kubernetes 能够根据应用程序需求快速更改网络策略。进一步的增强功能将用于网络设计的 AOS Graph 模型与工作负载供应集成在一起，从而为私有云和公共云提供端到端管理系统。\nAOS 支持使用包括 Cisco、Arista、Dell、Mellanox、HPE 在内的制造商提供的通用供应商设备，以及大量白盒系统和开放网络操作系统，例如 Microsoft SONiC、Dell OPX 和 Cumulus Linux 。\n想要更详细地了解 AOS 系统是如何工作的可以点击这里： http://www.apstra.com/products/how-it-works/\nKubernetes 的 AWS VPC CNI #   AWS VPC CNI 为 Kubernetes 集群提供了集成的 AWS 虚拟私有云（VPC）网络。该 CNI 插件提供了高吞吐量和可用性，低延迟以及最小的网络抖动。此外，用户可以使用现有的 AWS VPC 网络和安全最佳实践来构建 Kubernetes 集群。这包括使用 VPC 流日志，VPC 路由策略和安全组进行网络流量隔离的功能。\n使用该 CNI 插件，可使 Kubernetes Pods 在 Pod 中拥有与在 VPC 网络上相同的 IP 地址。CNI 将 AWS 弹性网络接口（ENI）分配给每个 Kubernetes 节点，并将每个 ENI 的辅助 IP 范围用于该节点上的 Pod 。CNI 包含用于 ENI 和 IP 地址的预分配的控件，以便加快 Pod 的启动时间，并且能够支持多达2000个节点的大型集群。\n此外，CNI可以与 用于执行网络策略的 Calico一起运行。 AWS VPC CNI项目是开源的，查看 GitHub 上的文档。\nKubernetes 的 Azure CNI #   Azure CNI 是一个 开源插件，将 Kubernetes Pods 和 Azure 虚拟网络（也称为 VNet）集成在一起，可提供与 VN 相当的网络性能。Pod 可以通过 Express Route 或者 站点到站点的 VPN 来连接到对等的 VNet ，也可以从这些网络来直接访问 Pod。Pod 可以访问受服务端点或者受保护链接的 Azure 服务，比如存储和 SQL。你可以使用 VNet 安全策略和路由来筛选 Pod 流量。该插件通过利用在 Kubernetes 节点的网络接口上预分配的辅助 IP 池将 VNet 分配给 Pod 。\nAzure CNI 可以在 Azure Kubernetes Service (AKS) 中获得。\nBig Switch Networks 的 Big Cloud Fabric #   Big Cloud Fabric 是一个基于云原生的网络架构，旨在在私有云或者本地环境中运行 Kubernetes。它使用统一的物理和虚拟 SDN，Big Cloud Fabric 解决了固有的容器网络问题，比如负载均衡、可见性、故障排除、安全策略和容器流量监控。\n在 Big Cloud Fabric 的虚拟 Pod 多租户架构的帮助下，容器编排系统（比如 Kubernetes、RedHat OpenShift、Mesosphere DC/OS 和 Docker Swarm）将于VM本地编排系统（比如 VMware、OpenStack 和 Nutanix）进行本地集成。客户将能够安全地互联任意数量的这些集群，并且在需要时启用他们之间的租户间通信。\n在最新的 Magic Quadrant 上，BCF 被 Gartner 认为是非常有远见的。而 BCF 的一条关于 Kubernetes 的本地部署（其中包括 Kubernetes、DC/OS 和在不同地理区域的多个 DC 上运行的 VMware）也在 这里被引用。\nCilium #   Cilium 是一个开源软件，用于提供并透明保护应用容器间的网络连接。Cilium 支持 L7/HTTP ，可以在 L3-L7 上通过使用与网络分离的基于身份的安全模型寻址来实施网络策略，并且可以与其他 CNI 插件结合使用。\n华为的 CNI-Genie #   CNI-Genie 是一个 CNI 插件，可以让 Kubernetes 在运行时允许不同的 Kubernetes 的网络模型的 实现同时被访问。这包括以 CNI 插件运行的任何实现，比如 Flannel、 Calico、 Romana、 Weave-net。\nCNI-Genie 还支持 将多个 IP 地址分配给 Pod，每个都来自不同的 CNI 插件。\ncni-ipvlan-vpc-k8s #   cni-ipvlan-vpc-k8s 包含了一组 CNI 和 IPAM 插件来提供一个简单的、本地主机、低延迟、高吞吐量以及通过使用 Amazon 弹性网络接口（ENI）并使用 Linux 内核的 IPv2 驱动程序以 L2 模式将 AWS 管理的 IP 绑定到 Pod 中，在 Amazon Virtual Private Cloud（VPC）环境中为 Kubernetes 兼容的网络堆栈。\n这些插件旨在直接在 VPC 中进行配置和部署，Kubelets 先启动，然后根据需要进行自我配置和扩展它们的 IP 使用率，而无需经常建议复杂的管理覆盖网络， BGP ，禁用源/目标检查，或调整 VPC 路由表以向每个主机提供每个实例子网的复杂性（每个 VPC 限制为50-100个条目）。简而言之， cni-ipvlan-vpc-k8s 大大降低了在 AWS 中大规模部署 Kubernetes 所需的网络复杂性。\nContiv #   Contiv 为各种使用情况提供了一个可配置网络（使用了 BGP 的本地 l3 ，使用 vxlan 的覆盖，经典 l2 或 Cisco-SDN/ACI）。 Contiv 是完全开源的。\nContrail / Tungsten Fabric #   Contrail 是基于 Tungsten Fabric 的，真正开放的，多云网络虚拟化和策略管理平台。Contrail 和 Tungsten Fabric 与各种编排系统集成在一起，例如 Kubernetes，OpenShift，OpenStack 和 Mesos，并为虚拟机、容器或 Pods 以及裸机工作负载提供了不同的隔离模式。\nDANM #   DANM 是一个针对在 Kubernetes 集群中运行的电信工作负载的网络解决方案。它由以下几个组件构成：\n* 能够配置具有高级功能的 IPVLAN 接口的 CNI 插件 * 一个内置的 IPAM 模块，能够管理多个、群集内的、不连续的 L3 网络，并按请求提供动态、静态或无 IP 分配方案 * CNI 元插件能够通过自己的 CNI 或通过将任务授权给其他任何流行的 CNI 解决方案（例如 SRI-OV 或 Flannel）来实现将多个网络接口连接到容器 * Kubernetes 控制器能够集中管理所有 Kubernetes 主机的 VxLAN 和 VLAN 接口 * 另一个 Kubernetes 控制器扩展了 Kubernetes 的基于服务的服务发现概念，以在 Pod 的所有网络接口上工作 通过这个工具集，DANM 可以提供多个分离的网络接口，可以为 pods 使用不同的网络后端和高级 IPAM 功能。\nFlannel #   Flannel 是一个非常简单的能够满足 Kubernetes 所需要的重叠网络。已经有许多人报告了使用 Flannel 和 Kubernetes 的成功案例。\nGoogle Compute Engine (GCE) #  对于 Google Compute Engine 的集群配置脚本， advanced routing 用于为每个虚机分配一个子网（默认是 /24 - 254个 IP），绑定到该子网的任何流量都将通过 GCE 网络结构直接路由到虚机。这是除了分配给虚机的“主要” IP 地址之外的一个补充，该 IP 地址经过 NAT 转换以用于访问外网。linux网桥（称为“cbr0”）被配置为存在于该子网中，并被传递到 docker 的 \u0026ndash;bridge 参数上。\nDocker 会以这样的参数启动：\nDOCKER_OPTS=\u0026#34;--bridge=cbr0 --iptables=false --ip-masq=false\u0026#34; 这个网桥是由 Kubelet（由 \u0026ndash;network-plugin=kubenet 参数控制）根据节点的 .spec.podCIDR 参数创建的。\nDocker 将会从 cbr-cidr 块分配 IP 。容器之间可以通过 cbr0 网桥相互访问，也可以访问节点。这些 IP 都可以在 GCE 的网络中被路由。\n而 GCE 本身并不知道这些 IP，所以不会对访问外网的流量进行 NAT，为了实现此目的，使用了 iptables 规则来伪装（又称为 SNAT，使数据包看起来好像是来自“节点”本身），将通信绑定到 GCE 项目网络（10.0.0.0/8）之外的 IP。\niptables -t nat -A POSTROUTING ! -d 10.0.0.0/8 -o eth0 -j MASQUERADE 最后，在内核中启用了 IP 转发（因此内核将处理桥接容器的数据包）：\nsysctl net.ipv4.ip_forward=1 所有这些的结果是所有 Pods 都可以互相访问，并且可以将流量发送到互联网。\nJaguar #   Jaguar 是一个基于 OpenDaylight 的 Kubernetes 网络开源解决方案。Jaguar 使用 vxlan 提供覆盖网络，而 Jaguar CNIPlugin 为每个 Pod 提供一个 IP 地址。\nk-vswitch #   k-vswitch 是一个基于 Open vSwitch 的简易 Kubernetes 网络插件。它利用 Open vSwitch 中现有的功能来提供强大的网络插件，该插件易于操作，高效且安全。\nKnitter #   Knitter 是一个支持 Kubernetes 中实现多个网络系统的解决方案。它提供了租户管理和网络管理的功能。除了多个网络平面外，Knitter 还包括一组端到端的 NFV 容器网络解决方案，例如为应用程序保留 IP 地址，IP 地址迁移等。\nKube-OVN #   Kube-OVN 是一个基于 OVN 的用于企业的 Kubernetes 网络架构。借助于 OVN/OVS ，它提供了一些高级覆盖网络功能，例如子网、QoS、静态 IP 分配、流量镜像、网关、基于开放流的网络策略和服务代理。\nKube-router #   Kube-router 是 Kubernetes 的专用网络解决方案，旨在提供高性能和易操作性。 Kube-router 提供了一个基于 Linux LVS/IPVS 的服务代理，一个基于 Linux 内核转发的无覆盖 Pod-to-Pod 网络解决方案，和基于 iptables/ipset 的网络策略执行器。\nL2 networks and linux bridging #  如果你具有一个“哑”的L2网络，例如“裸机”环境中的简单交换机，则应该能够执行与上述 GCE 设置类似的操作。请注意，这些说明仅是非常简单的尝试过-似乎可行，但尚未经过全面测试。如果您使用此技术并完善了流程，请告诉我们。\n根据 Lars Kellogg-Stedman 的这份非常不错的“Linux 网桥设备” 使用说明来进行操作。\nMultus (a Multi Network plugin) #   Multus 是一个多 CNI 插件，使用 Kubernetes 中基于 CRD 的网络对象来支持实现 Kubernetes 多网络系统。\nMultus 支持所有[参考插件]（https://github.com/containernetworking/plugins）（比如： Flannel、 DHCP、 Macvlan ），来实现 CNI 规范和第三方插件（比如： Calico、 Weave、 Cilium、 Contiv）。除此之外， Multus 还支持 SRIOV、 DPDK、 OVS-DPDK \u0026amp; VPP 的工作负载，以及 Kubernetes 中基于云的本机应用程序和基于 NFV 的应用程序。\nNSX-T #   VMware NSX-T 是一个网络虚拟化的安全平台。 NSX-T 可以为多云及多系统管理程序环境提供网络虚拟化，并专注于具有异构端点和技术堆栈的新兴应用程序框架和体系结构。除了 vSphere 管理程序之外，这些环境还包括其他虚拟机管理程序，例如 KVM，容器和裸机。\n NSX-T Container Plug-in (NCP) 提供了 NSX-T 与容器协调器（例如 Kubernetes）之间的结合， 以及 NSX-T 与基于容器的 CaaS/PaaS 平台（例如 Pivotal Container Service（PKS） 和 OpenShift ）之间的集成。\nNuage Networks VCS (Virtualized Cloud Services) #   Nuage 提供了一个高度可扩展的基于策略的软件定义网络（SDN）平台，Nuage 使用开源的 Open vSwitch 作为数据平面，以及基于开放标准构建具有丰富功能的 SDN 控制器。\nNuage 平台使用覆盖层在 Kubernetes Pod 和非 Kubernetes 环境（VM 和裸机服务器）之间提供基于策略的无缝联网。Nuage 的策略抽象模型在设计时就考虑到了应用程序，并且可以轻松声明应用程序的细粒度策略。该平台的实时分析引擎可为 Kubernetes 应用程序提供可见性和安全性监控。\nOpenVSwitch #   OpenVSwitch 是一个较为成熟的解决方案，但同时也增加了构建覆盖网络的复杂性，这也得到了几个网络系统的“大商店”的拥护。\nOVN (开放式虚拟网络) #  OVN 是一个由 Open vSwitch 社区开发的开源的网络虚拟化解决方案。它允许创建逻辑交换器，逻辑路由，状态 ACL，负载均衡等等来建立不同的虚拟网络拓扑。该项目有一个特定的Kubernetes插件和文档 ovn-kubernetes。\nProject Calico #   Project Calico 是一个开源的容器网络提供者和网络策略引擎。\nCalico 提供了高度可扩展的网络和网络解决方案，使用基于与 Internet 相同的 IP 网络原理来连接 Kubernetes Pod，适用于 Linux （开放源代码）和 Windows（专有-可从 Tigera 获得。可以无需封装或覆盖即可部署 Calico，以提供高性能，高可扩的数据中心网络。Calico 还通过其分布式防火墙为 Kubernetes Pod 提供了基于意图的细粒度网络安全策略。\nCalico 还可以和其他的网络解决方案（比如 Flannel、 canal 或本机 GCE、AWS、Azure 等）一起以策略实施模式运行。\nRomana #   Romana 是一个开源网络和安全自动化解决方案。它可以让你在没有覆盖网络的情况下部署 Kubernetes。Romana 支持 Kubernetes 网络策略，来提供跨网络命名空间的隔离。\nWeaveworks 的 Weave Net #   Weave Net 是 Kubernetes 及其托管应用程序的弹性和易于使用的网络系统。Weave Net 可以作为 CNI plug-in 运行或者独立运行。在这两种运行方式里，都不需要任何配置或额外的代码即可运行，并且在两种情况下，网络都为每个 Pod 提供一个 IP 地址-这是 Kubernetes 的标准配置。\n接下来 #  网络模型的早期设计、运行原理以及未来的一些计划，都在 networking design document 文档里进行了更详细的描述。\n"});index.add({'id':121,'href':'/notes/docs/technology/program/web/','title':"WEB编程",'section':"编程",'content':"WEB编程 #  "});index.add({'id':122,'href':'/notes/docs/technology/cloud/api/','title':"声明式API",'section':"云原生",'content':"声明式API #  "});index.add({'id':123,'href':'/notes/docs/technology/program/language/golang/practical/','title':"实用GO",'section':"Golang",'content':"实用GO #   《Go语言最佳实践》\n 指导原则 #  1. 简单性 #  2. 可读性 #  3. 生产力 #   "});index.add({'id':124,'href':'/notes/docs/technology/other/interview/history/','title':"总结",'section':"面试相关",'content':"总结 #  "});index.add({'id':125,'href':'/notes/docs/technology/other/translate/','title':"技术文章翻译",'section':"其他",'content':"翻译技术文章 #  "});index.add({'id':126,'href':'/notes/docs/technology/architecture/','title':"架构",'section':"技术相关",'content':"架构 #  "});index.add({'id':127,'href':'/notes/docs/technology/other/interview/100/','title':"100个问题",'section':"面试相关",'content':"100个问题 #  1. What is a skill you have that most people don’t acknowledge?\n​\t优势：网络知识，TCP，路由\n2. How would your best friend describe you?\n​\t脾气好，头脑灵活\n3. What is the first complex problem you can remember solving as a kid?\n​\t暂无\n4. What’s your least favorite time of day and why?\n​\t暂无\n5. Do you work better as an individual or as part of a team?\n​\t个人\n6. Do you prefer working in an office setting or remotely?\n​\toffice\n7. Can you tell me about a challenge you overcame in a previous role?\n​\taws vpc问题\n8. What is something new you hope to learn in this position?\n​\t容器技术\n9. What are three words you’d use to define yourself?\n​\t好学，效率，悲观|乐观\n10. What’s one instance of failure in past, and how did you respond to it?\n​\n11. How do you measure success?\n​\n12. What is your favorite quote?\n​\t人生如逆旅，我亦是行人\n13. What is your favorite book?\n​\t暂无\n14. What is your favorite song?\n​\t转眼\n15. How do you like to spend your free time?\n​\t看书、发呆、刷剧\n16. How would you describe your type of intelligence—as serious or fluid?\n​\n17. What TV character best resembles your professional persona?\n​\t不知道\n18. How did you hear about this position?\n​\t官网招聘\n19. What does your ideal work culture look like?\n​\t自由发挥\n20. What’s the difference between a job and a career in your opinion, and which one are you looking for here?\n​\t工作是谋生手段，职业是理想的现实路线，职业\n21. In what way did you add the most value in your last position?\n​\t自动化，提升效率和节省成本\n22. What is your most valuable skill?\n​\t解决问题的能力\n23. If you were given a million dollars how would you spend it and what would you do with your time?\n​\t暂无\n24. What mantra best reflects your approach to life?\n​\t随缘，尽人事，听天命\n25. What film, tv show, or book has been most meaningful to you and why?\n​\t暂无\n26. What are your hobbies?\n​\t徒步，发呆\n27. If there was no limit for growth potential in this position, where would you want it to take you?\n​\t世界的尽头\n28. Can you tell me a good joke?\n​\n29. If you were an animal what animal would you be and why?\n​\n30. What’s the last book you read?\n​\tGoogle SRE\n31. What would you do if the zombie apocalypse began today?\n​\n32. What is your definition of work-life balance?\n​\t有时间陪伴家人\n33. How do you deal with negative outside opinions about you and/or your work?\n​\t看哪种意见，\n34. What is your work process like?\n​\t网管 \u0026ndash;\u0026gt; 运维 (系统) \u0026ndash;\u0026gt; 运维开发(编程)\n35. How do you organize your workload?\n​\n36. What would you do if you caught someone stealing?\n​\t报警吧\n37. What is your approach to forming friendships with your coworkers?\n​\t聊天\n38. How do you manage conflict in the workplace?\n​\t看有没有折中方案，或者考虑优先级，\n39. In your opinion, were Ross and Rachel on a break?\n40. What are your current boss’ best and worst qualities?\n​\n41. What websites do you read regularly?\n​\tinfoq\n42. What is something you’d like to improve about yourself?\n​\t总结能力\n43. What is one thing you would change about your past position(s)?\n​\n44. What do you know about our company?\n​\n45. Where do you see yourself in five years? Ten years? Twenty?\n​\n46. In what ways have you grown in the last five years?\n​\n47. Can you sell me this [insert random object]?\n48. What are your greatest strengths?\n49. What are your biggest weaknesses?\n50. Why should we hire you?\n​\t合适\n51. Can you describe yourself in exactly five words?\n52. What’s the most interesting thing about you that’s not on your resume?\n​\n53. What interests you about this job?\n​\t量级\n54. Why do you want this role?\n​\n55. What are your short-term career goals?\n​\n56. What are your long-term career goals\n57. What challenges are you looking for in a position?\n​\n58. What has to happen during the course of the day to make it a good one for you at work?\n​\n59. Why do you think you will be successful at this job?\n​\t履历适合\n60. What’s one of your greatest accomplishments inside or outside of the workplace?\n61. Tell me about a time when you were faced with conflicting priorities. How did you determine the top priority?\n62. Can you describe a difficult work situation or project and how you overcame it?\n63. How do you handle stress and pressure?\n64. What are your pet peeves?\n65. What type of work environment do you prefer?\n66. What is your greatest professional achievement?\n67. Why would you hire yourself?\n68. What’s your management style?\n69. Can you describe an instance in which you demonstrated leadership skills?\n70. Can you describe a time when you disagreed with a decision made from above at work and explain how you handled it?\n71. Have you ever pivoted in your career path and if so, why?\n72. How would your last boss describe you?\n73. If you were at a work lunch or dinner and you ordered a medium rare steak and they brought it to you well done, how would you handle the situation?\n74. What would you do if you discovered that one of your superiors was doing something questionable?\n75. What’s the most difficult thing you’ve been through?\n76. Do you have any professional regrets?\n77. What has been the highlight of your career so far?\n78. Can you describe a time when you went above and beyond at work?\n79. What inspires you?\n80. What hampers your inspiration?\n81. What is your leadership style?\n82. Have you ever had to work with someone who wasn’t pulling their weight, and, if so, how did you handle it?\n83. Has your work ever been criticized and if so, how did you respond?\n84. What is your approach to working with people who annoy you?\n85. What is your approach to working with people who are more accomplished than you are professionally?\n86. What are your most defining personality traits?\n87. What is your Myers-Briggs personality type?\n88. If you learned that your company was doing something illegal, how would you proceed?\n89. How do you handle yourself when assigned a task you’re not excited about?\n90. What is your tolerance level for tedium?\n91. How do you handle a massive workload?\n92. Have you ever missed a deadline?\n93. Have you ever had to come to terms that you were just not the right fit for a given task?\n94. Why did you choose this career path?\n95. What did you want to be when you were a kid?\n96. How have you changed as a person since entering the workforce?\n97. Do you rely on your occupation for fulfillment?\n98. What do you need from your everyday routine in order to feel content and fulfilled?\n99. What’s the strangest question you’ve been asked in an interview?\n100. Do you have any questions for me?\n"});index.add({'id':128,'href':'/notes/docs/technology/cloud/devops/','title':"DevOps",'section':"云原生",'content':"DevOps #  What #  wiki\n DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。\n 亚马逊\n DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes. This speed enables organizations to better serve their customers and compete more effectively in the market.\n 微软\n DevOps is the union of people, process, and products to enable continuous delivery of value to our end users. The contraction of “Dev” and “Ops” refers to replacing siloed Development and Operations to create multidisciplinary teams that now work together with shared and efficient practices and tools. Essential DevOps practices include agile planning, continuous integration, continuous delivery, and monitoring of applications.\n 红帽\n DevOps describes approaches to speeding up the processes by which an idea (like a new software feature, a request for enhancement, or a bug fix) goes from development to deployment in a production environment where it can provide value to the user. These approaches require that development teams and operations teams communicate frequently and approach their work with empathy for their teammates. Scalability and flexible provisioning are also necessary. With DevOps, those that need power the most, get it—through self service and automation. Developers, usually coding in a standard development environment, work closely with IT operations to speed software builds, tests, and releases—without sacrificing reliability.\n    How #  DevOps的首要目标是创建一个支持持续集成和持续交付的开发环境。\n实际上，DevOps的四个关键原则将其注入到框架中：\n Continuous integration (持续集成) Continuous delivery (持续交付) Continuous testing(持续测试) Continuous monitoring(持续监控)   "});index.add({'id':129,'href':'/notes/docs/technology/cloud/container/kubernetes/storage/','title':"Kubernetes 存储",'section':"Kubernetes",'content':"Kubernetes 存储 #  Ways to provide both long-term and temporary storage to Pods in your cluster.\n Volumes #  Persistent Volumes #  Storage Classes #  "});index.add({'id':130,'href':'/notes/docs/technology/cloud/devops/monitor/prometheus/','title':"Prometheus",'section':"监控",'content':"Prometheus #    AlertManager #  webhook #  doraemon #   Prometheus #   Discovery #  consul #  registrtor #  exporter #   UI #  Grafana #   K8s-Operator #  "});index.add({'id':131,'href':'/notes/docs/technology/cloud/devops/test/','title':"Test",'section':"DevOps",'content':"Test #   testcafe  "});index.add({'id':132,'href':'/notes/docs/technology/cloud/','title':"云原生",'section':"技术相关",'content':"云原生 #  What #  CNCF定义 #   Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.\nThese techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.\n Pivotal定义 #   Cloud native is an approach to building and running applications that exploits the advantages of the cloud computing delivery model. Cloud native is about how applications are created and deployed, not where\nOrganizations require a platform for building and operating cloud native applications and services that automates and integrates the concepts of DevOps, continuous delivery, microservices, and containers\n  阿里云原生课堂 #  定义 #   云原生是一条使用户能低心智负担的、敏捷的、以可扩展、可复制的方式， 最大化的利用”云“的能力、发挥”云“的价值的最佳路径\n  发展历程 #    技术范畴 #  云应用定义与开发流程 #   应用定义与镜像制作 CI/CD 消息和 Streaming 数据库  云应用编排与管理 #   应用编排与调度 服务发现与治理 远程调用 API 网关 Service Mesh  监控与可观测性 #   监控 日志 Tracing 混沌工程  云原生底层技术 #   容器运行时 云原生存储技术 云原生网络技术  云原生工具集 #   流程自动化与配置管理 容器镜像仓库 云原生安全技术 云端密码管理  Serverless #   FaaS BaaS Serverless 计费   理论基础 #    不可变基础设施\n目前实现：容器镜像\n  云应用编排理论\n目前实现：容器设计模式\n   关键技术点 #   "});index.add({'id':133,'href':'/notes/docs/technology/other/book_notes/system_performance/','title':"性能之巅",'section':"读书笔记",'content':"性能之巅 #    事件 #   设置性能目标和建立性能模型 基于软硬件原型进行性能特征归纳 对开发代码进行性能分析（软件整合之前） 执行软件非回归性测试（软件发布前或发布后） 针对软件发布版本的基准测试 目标环境中的概念验证测试 生产环境部署的配置优化 监控生产环境中运行的软件 特定问题的性能分析   视角 #   性能需要进行多视角分析，图中包括负载分析和资源分析\n 方法 #  术语 #   IOPS： 每秒发生的输入/输出操作的次数，是数据传输的一个度量方法。 吞吐量(Throughput)：工作执行的速率，在数据传输中，用于描述数据传输的数独(bytes/s或者bits/s)，在数据库中，则表示操作的速度(操作数/秒或者事务数/秒) 响应时间：一次操作完成的时间。包含用于等待和服务的时间，也包括用来返回结果的时间 延时：描述操作里用来等待服务的时间。在某些情况下，它可以指的是整个操作时间，等同于响应时间。 使用率：对于服务所请求的资源，使用率描述在所给定的时间区间内资源的繁忙程度。对于存储资源，指的是所消耗的存储容量 饱和度：指的是某一个资源无法满足服务的排队工作量 瓶颈：在系统性能里，瓶颈指的是限制系统性能的那个资源。 工作负载：系统的输入或者对系统所施加的负载叫做工作负载。对于数据库来说，工作负载就是客户端发出的数据库请求和命令。 缓存：用于复制或者缓冲一定量数据的高速存储区域   系统性能概念 #  时延 #  时间量级\n Latency Number:\n   Event Latency     L1 cache reference 1ns   Branch mispredict 3ns   L2 cache reference 4ns   Mutex lock/unlock 16ns   Main memory reference 100ns   Compress 1KB with Snappy 2us   Send 2,000 bytes over commodity network 31ns   SSD random read 16us   Read 1,000,000 bytes sequentially from memory 2.355us   Round trip in same datacenter 500us   Read 1,000,000 bytes sequentially from SSD 38.876us   Disk seek 2.332582ms   Read 1,000,000 bytes sequentially from disk 717.936us   Packet roundtrip CA to Netherlands 150ms         权衡与调整 #   去权衡相伴的通常是可调参数。\n性能调整发生在越高进工作执行的地方效果越显著。\n  指标 #  性能指标是由系统、应用程序或者其他工具产生的度量感兴趣活动的统计数据。性能指标用于性能分析和监控，由命令行提供数据或者由可视化工具提供图表。\n常见系统性能指标：\n IOPS 吞吐量 使用率 延时  开销\n性能指标不是免费的，在某些时候，会消耗CPU周期来收集和保存指标信息。\n问题\n指标可能会是混淆的、复杂的、不可靠的、不精确的，甚至是错误的。\n 资源分析 #  资源分析以对系统资源的分析为起点，涉及的系统资源有：CPU、内存、磁盘、网卡、总线以及直接的互联。\n 性能问题研究，看是否某特定类型资源的责任。 容量规划，为设计新系统提供信息，或者对系统资源何时会耗尽做预测。  相关指标：\n IOPS 吞吐量 使用率 饱和度   工作负载分析 #  工作负载分析检查应用程序的性能：所施加的工作负载和应用程序是如何响应的。\n分析对象：\n 请求，所施加的工作负载 延时：应用程序的响应时间 完成度：查找错误  相关指标：\n 吞吐量 延时   USE方法 #  USE方法(utilization、saturation、errors)应用于性能研究，对所有的资源，查看它的使用率、饱和度和错误。\n 资源：所有物理资源和部分软件资源 使用率：在规定时间间隔内，资源用于服务工作的时间百分比。 饱和度：资源不能再服务更多额外工作的程度，通常有等待队列。 错误：错误事件的个数。  物理资源列表：\n CPU 内存 网络接口 存储设备 控制器 互联：CPU、内存、I/O  软件资源列表：\n 互斥锁：锁被持有的时间是使用时间，饱和度指的有线程排队在等锁 线程池：线程忙于处理工作的时间是使用时间，饱和度指的是等待线程池服务的请求数目 进程/线程容量：系统的进程或线程的总数是有上限的，当前的使用数目是使用率，等待分配任务是饱和度，错误是分配失败 文件描述符容量：同进程/线程容量一样，只不过针对的是文件描述符  使用建议\n 使用率：100%的使用率通常是瓶颈的信号。使用率超过60%可能会是问题。 饱和度：任何程度的饱和度都是问题 错误：错误都是值得研究的   建模 #   可视化识别 Amdahl扩展定律 通用扩展定律 排队理论   容量规划 #  资源极限\n该方法研究在负载之下会成为系统瓶颈的资源。\n 测量服务器请求的频率，并监视请求频率随时间的变化 测量硬件和软件的使用。监视使用率随时间的变化 用资源的使用来表示服务器的请求情况。 根据每个资源来推断服务器请求的极限  因素分析\n基于对系统最大配置的了解方法\n 测试所有因素都设置为最大时的性能 逐一改变因素，测试性能 基于测量的结果，对每个因素的变化引起性能下降的百分比以及所节省的成本做统计 将最高的性能和成本作为起始点，选择能节省成本的因素，同时确保组合后的性能下降仍满足所需的每秒请求量。 重新测试改变过的配置，确认所交付的性能   扩展方案 #   垂直扩展，建立更大的系统 水平扩展，把负载分散给多个同样系统，在这些系统前面添加负载均衡器   统计 #  量化性能\n 基于观测 基于实现   监控 #  系统性能监控记录一段时间内的性能统计数据，过去的记录可以现在的做比较\n 可视化 #  可视化用看得见的方式来对数据做检查。这让我们能够识别规律并对规律做匹配。\n 操作系统 #  "});index.add({'id':134,'href':'/notes/docs/technology/cloud/devops/monitor/','title':"监控",'section':"DevOps",'content':"Monitor #  Collect #  做什么 #   收到有意义的自动化警报，以解决潜在问题。 快速调查并深入了解性能问题。   Collecting data is cheap, but not having it when you need it can be expensive, so you should instrument everything, and collect all the useful data you reasonably can.\n Metric #  Metric在特定时间点捕获与您的系统有关的值,\n  Work Metric #  Work metrics 通过衡量有用的输出来指示系统的顶级运行状况。\n 吞吐量 成功率 错误 性能(延迟)  Example work metrics: Web server\n   Subtype Description Value     throughput requests per second 312   success percentage of responses that are 2xx since last measurement 99.1   error percentage of responses that are 5xx since last measurement 0.1   performance 90th percentile response time in seconds 0.4     Resource Metric #   利用率 饱和度 错误 可用性  Here are example metrics for a handful of common resource types:\n   Resource Utilization Saturation Errors Availability     Disk IO % time that device was busy wait queue length # device errors % time writable   Memory % of total memory capacity in use swap usage N/A (not usually observable) N/A   Microservice average % time each request-servicing thread was busy # enqueued requests # internal errors such as caught exceptions % time service is reachable   Database average % time each connection was busy # enqueued queries # internal errors, e.g. replication errors % time database is reachable     四大特征 #   清晰，保持指标和事件尽可能简单，并明确命名 粒状， 按范围标记，保留与数据关联的多个作用域非常重要，这样您就可以警告任何作用域的问题，并快速调查中断，而不受固定主机层次结构的限制 保留时长   总结 #   记录一切，并尽可能收集尽可能多的工作指标，资源指标和事件。复杂系统的可观察性要求全面的测量。 以足够的粒度收集指标，以使重要的峰值和下降可见。 为了最大程度地发挥数据的价值，请在多个范围内标记指标和事件，并将其完整粒度保留至少15个月。   Alert #  告警等级 #   记录(低等级) 通知(中等) 页面、电话等(紧急)  总结 #  仅在系统出现紧急问题的症状时发送页面 检测到工作，或者是否存在关键且有限的资源限制 即将达到\n设置您的监视系统以在检测到警报时记录警报 基础架构中的实际问题，即使这些问题没有 尚未影响整体表现\n 恢复 #   查看work指标 查看资源指标 是否做过变更 修复并不忘记它   总结 #  遵循标准化的监视框架，您可以更系统地调查问题：\n 对于基础架构中的每个系统，请提前设置一个仪表板，以显示其所有关键指标并覆盖相关事件 通过从显示症状的最高级别系统开始，调查其原因，审查其工作和资源指标以及任何相关事件，以调查问题的原因 如果检测到有问题的资源，则对资源（及其组成资源）应用相同的调查模式，直到发现并纠正根本问题为止  "});index.add({'id':135,'href':'/notes/docs/technology/cloud/container/kubernetes/security/','title':"Kubernetes 安全",'section':"Kubernetes",'content':"Kubernetes 安全 #  "});index.add({'id':136,'href':'/notes/docs/technology/cloud/container/kubernetes/operation/install/','title':"Kubernetes 安装配置",'section':"Kubernetes 操作",'content':"安装 #  kubeadm快速部署kubernetes #  环境搭建 #    环境准备\n#放开防火墙限制 systemctl stop firewalld systemctl disable firewalld #更改内核参数 echo 1 \u0026gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables echo 1 \u0026gt; /proc/sys/net/bridge/bridge-nf-call-iptables #禁用SELINUX setenforce 0    Docker安装\n参考 Docker安装\n#开启iptables filter表中FOWARD链(Docker1.3开始已被禁用) iptables -P FORWARD ACCEPT #/etc/docker/daemon.json增加配置 { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=systemd\u0026quot;] } #重启Docker systemctl restart docker.service    Kubeadm安装\n#添加repo配置 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF #安装kubeadm,kubelet,kubectl yum install -y kubelet kubeadm kubectl systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet     Master node 初始化 #    init\nkubeadm init --pod-network-cidr=10.244.0.0/16 #记录join值 kubeadm join --token \u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt;:\u0026lt;master-port\u0026gt; #配置KUBECONFIG环境参数 export KUBECONFIG=/etc/kubernetes/admin.conf    Pod Network安装\nmkdir -p ~/k8s/ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl create -f kube-flannel-rbac.yml kubectl apply -f kube-flannel.yml     Node 加入 Master #  kubeadm join --token \u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt;:\u0026lt;master-port\u0026gt;   kubectl操作 #  #获取组件状态 kubectl get cs #查看pod状态 kubectl get pod --all-namespaces -o wide #部署应用   手动部署kubernetes高可用集群 #  环境准备 #  软件 #    etcd\n  docker\n  kubernetes\n  kubelet\n  kube-proxy\n  kube-apiserver\n  kube-controller-manager\n  kube-scheduler\n     软件准备 #     Docker安装\n  软件下载\nwget https://storage.googleapis.com/kubernetes-release/release/v1.6.9/kubernetes.tar.gz tar -zxvf kubernetes.tar.gz ./kubernetes/cluster/get-kube-binaries.sh wget https://github.com/coreos/etcd/releases/download/v3.2.6/etcd-v3.2.6-linux-amd64.tar.gz     etcd高可用集群搭建 #  安装cfssl #  go get -u github.com/cloudflare/cfssl/cmd/...  将在$GOPATH/bin下安装cfssl, cfssjosn, mkbundle等工具\nCA证书和私钥 #  创建ca-config.json:\n{ \u0026quot;signing\u0026quot;: { \u0026quot;default\u0026quot;: { \u0026quot;expiry\u0026quot;: \u0026quot;87600h\u0026quot; }, \u0026quot;profiles\u0026quot;: { \u0026quot;frognew\u0026quot;: { \u0026quot;usages\u0026quot;: [ \u0026quot;signing\u0026quot;, \u0026quot;key encipherment\u0026quot;, \u0026quot;server auth\u0026quot;, \u0026quot;client auth\u0026quot; ], \u0026quot;expiry\u0026quot;: \u0026quot;87600h\u0026quot; } } } }  创建CA证书签名请求配置ca-csr.json:\n{ \u0026quot;CN\u0026quot;: \u0026quot;frognew\u0026quot;, \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 2048 }, \u0026quot;names\u0026quot;: [ { \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;O\u0026quot;: \u0026quot;frognew\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;cloudnative\u0026quot; } ] }  使用cfssl生成CA证书和私钥：\ncfssl gencert -initca ca-csr.json | cfssljson -bare ca  ca-key.pem和ca.pem需要保存，后边会用到\netcd证书和私钥 #  创建etcd证书签名请求配置etcd-csr.json:\n{ \u0026quot;CN\u0026quot;: \u0026quot;cctest\u0026quot;, \u0026quot;hosts\u0026quot;: [ \u0026quot;127.0.0.1\u0026quot;, \u0026quot;192.168.19.11\u0026quot;, \u0026quot;192.168.19.12\u0026quot;, \u0026quot;192.168.19.13\u0026quot;, \u0026quot;node1\u0026quot;, \u0026quot;node2\u0026quot;, \u0026quot;node3\u0026quot; ], \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 2048 }, \u0026quot;names\u0026quot;: [ { \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;O\u0026quot;: \u0026quot;cctest\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;cloudnative\u0026quot; } ] }  生成etcd的证书和私钥\ncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=frognew etcd-csr.json | cfssljson -bare etcd  etcd安装 #  将ca.pem, etcd-key.pem, etcd.pem拷贝到各节点的/etc/etcd/ssl目录中\ncp ca.pem /etc/etcd/ssl cp etcd*.pem /etc/etcd/ssl  解压缩etcd-v3.2.6-linux-amd64.tar.gz，拷贝可执行文件\ntar -zxvf etcd-v3.2.6-linux-amd64.tar.gz cp etcd-v3.2.6-linux-amd64/etcd* /usr/bin/  创建etcd的systemd unit文件\nexport ETCD_NAME=node1 export INTERNAL_IP=192.168.19.11 cat \u0026gt; /usr/lib/systemd/system/etcd.service \u0026lt;\u0026lt;EOF [Unit] Description=etcd server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ EnvironmentFile=-/etc/etcd/etcd.conf ExecStart=/usr/bin/etcd \\ --name ${ETCD_NAME} \\ --cert-file=/etc/etcd/ssl/etcd.pem \\ --key-file=/etc/etcd/ssl/etcd-key.pem \\ --peer-cert-file=/etc/etcd/ssl/etcd.pem \\ --peer-key-file=/etc/etcd/ssl/etcd-key.pem \\ --trusted-ca-file=/etc/etcd/ssl/ca.pem \\ --peer-trusted-ca-file=/etc/etcd/ssl/ca.pem \\ --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\ --listen-peer-urls https://${INTERNAL_IP}:2380 \\ --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\ --advertise-client-urls https://${INTERNAL_IP}:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster node1=https://192.168.19.11:2380,node2=https://192.168.19.12:2380,node3=https://192.168.19.13:2380 \\ --initial-cluster-state new \\ --data-dir=/var/lib/etcd Restart=on-failure RestartSec=5 LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF  启动etcd #  各节点启动etcd服务\nsystemctl daemon-reload systemctl enable etcd systemctl start etcd systemctl status etcd  集群检查：\netcdctl \\ --ca-file=/etc/etcd/ssl/ca.pem \\ --cert-file=/etc/etcd/ssl/etcd.pem \\ --key-file=/etc/etcd/ssl/etcd-key.pem \\ --endpoints=https://node1:2379,https://node2:2379,https://node3:2379 \\ cluster-health   Kubernetes Master 集群搭建 #  "});index.add({'id':137,'href':'/notes/docs/technology/bigdata/','title':"大数据",'section':"技术相关",'content':"大数据 #  "});index.add({'id':138,'href':'/notes/docs/technology/other/interview/request/','title':"目标",'section':"面试相关",'content':"目标 #  Ali #    阿里云智能事业群-监控运维平台技术专家-杭州/北京  #运维方向 运维方向：百万服务器运维管理规模的技术挑战，衔接监控与安全平台能力，为客户提供资源授权、可靠变更以及运维产品和解决方案 岗位要求： 全岗位通用要求 1. 对创新有发自内心的热爱和激情，学习能力强，认真负责，有团队合作精神并乐于分享 2. 熟悉互联网应用架构，云计算，具备互联网架构设计经验，应用软件研发/运维工作背景 3. 善于总结和思考，正视技术挑战、有技术愿景，期望从事对业界有影响力的工作 运维方向：熟悉DevOps/PEOps以及运维、AIOps平台研发经验优先 岗位关键词 1. 通用要求：Java | Go 3. 运维方向：Kubernetes | K8S | Cloud Native | ServerLess | ServiceMesh | SRE | DevOps   蚂蚁金服-容器调度SRE  岗位描述： 全方面参与云原生的资源调度系统的设计，开发，优化与维护。蚂蚁金服在线和实时业务的容器调度，调度节点单集群规模超过万台服务器，为蚂蚁上层业务提供设施标准容器服务和全局资源动态分配调度。具体职责包括但不限于： 1. 设计调度系统高可用体系，用以保障双十一等大型活动的平稳进行 2. 标准化调度系统监控，日志采集，包括SLA的制定与故障定位 3. 建立统一额度管控，弹性伸缩调度，提升系统资源利用率 4. 建设自动化及工程化的解决方式，以减少在传统运维层面的人力投入，做到无人值守。 岗位要求： 1. 至少精通一门编程语言，有软件开发背景，Java/Golang优先 2. 熟悉Linux系统和 Shell，对网络及基础设施层有一定的了解和知识储备 3. 有Docker、k8s 、微服务治理及资源调度经验者优先 4. 熟悉监控及自动化部署平台研发，具有大规模集群调度和架构设计经验优先 5. 有良好的沟通，团队协作能力 6. 熟悉DevOps流程，理解传统运维痛点   蚂蚁集团-云原生基础设施 SRE  二、中间件 SRE 蚂蚁金服中间件团队使用 Service Mesh、SofaStack、Serverless 等技术，上层业务提供统一高效的服务注册、消息、定时任务、限流等能力。中间件SRE团队致力于打造新一代中间件云原生系统的SLA体系，建设各种场景下的高可用能力，推进新的云原生技术在蚂蚁快速落地的同时，为上游业务提供5个9的可用率。加入我们，你将 1. 设计中间件系统的高可用技术风险体系，用以保障双十一等大型活动的平稳进行； 2. 设计并支撑 Service Mesh、Serverless 在蚂蚁大规模场景下的接入、部署和升级方案； 3. 建设中间件系统的监控和SLA规范，能够利用算法对监控进行持续降噪； 4. 建设中间件变更防御、异常定位和自愈系统，能够快速定位和处理故障。 五、接入层 SRE 蚂蚁统一接入层是蚂蚁所有业务的入口，在云原生的基础设施里承担者流量接入转发以及负载均衡的重要角色。接入层的SRE的职能要求包括 1. 负责接入层在向云原生转型过程中的规划、设计、部署、以及业务性能调优； 2. 负责接入层管控层面的整体方案设计和推进，结合云原生的容器调度体系（K8S），在业务高稳定性同时，做到docker镜像化，自动化运维，探索研究新的技术方向，例如infra as code，不断提升运维工作效率； 3. 负责接入层在各项大促（例如双十一）期间的稳定性、规模化以及性能保障，确保峰值时期的平稳运行。 4. 负责接入层技术支持和日常运维工作，对突发事件的快速响应、定位及处理，排除故障，保障系统稳定性。 岗位要求： 二、中间件 SRE 1. 有强烈的技术热情，工作责任感。 2. 至少精通一门编程语言，Java/Golang优先 3. 熟悉Linux系统和Shell，对网络、存储等基础设施领域有一定的了解和知识储备 4. 有Docker、k8s 、微服务治理经验者优先 5. 熟悉运维自动化部署平台研发，具有大规模集群架构设计经验优先 6. 有良好的沟通，团队协作能力，熟悉DevOps流程 五、接入层 SRE 1. 精通TCP/HTTP(2)/DNS协议原理； 2. 熟悉golang/C/Java/Python/Shell中的任意一种以上； 3. 熟悉常见的配置管理和运维工具，如：Ansible、Puppet、SaltStack、Fabric、Kubenetes、Docker等； 4. 熟悉nginx、lvs、envoy、service mesh等技术，对ngx_lua有实践者优先 5. 熟悉阿里云ECS、OSS、SLB、CDN等云产品优先； 6. 熟悉云计算平台OpenStack、Kubernetes、Mesos、Swram及docker/kvm/xen等虚拟化技术优先； 7. 热爱技术，自我驱动，主动思考，不断钻研和探索新领域，有较好的技术敏感度、风险识别能力和全局意识； 8. 高度的责任心，良好的沟通能力和团队协作精神，有较强的跨团队协调能力且抗压能力强。  "});index.add({'id':139,'href':'/notes/docs/technology/cloud/container/kubernetes/operation/use/','title':"Kubernetes 使用",'section':"Kubernetes 操作",'content':"Kubernetes 使用 #  工具 #  "});index.add({'id':140,'href':'/notes/docs/technology/cloud/container/kubernetes/operation/','title':"Kubernetes 操作",'section':"Kubernetes",'content':"Kubernetes 操作 #  工具 #  安装 #   minikube kubeadm kops  kubespray   操作 #   kubectl   包管理 #   helm   维护 #  更新 #  排障 #  "});index.add({'id':141,'href':'/notes/docs/technology/security/','title':"安全",'section':"技术相关",'content':"安全 #  "});index.add({'id':142,'href':'/notes/docs/technology/tool/','title':"工具",'section':"技术相关",'content':"工具 #  "});index.add({'id':143,'href':'/notes/docs/technology/network/protocol/http/tls/','title':"SSL协议",'section':"HTTP",'content':"SSL协议 #  SSL是一种安全协议，目的是为互联网通信提供安全及数据完整性保障。\n   SSL介绍\n   工作机制\n   工具使用\n   SSL介绍 一个简单的工作流程: #    浏览器请求一个安全页面(https://)。\n  Web服务器返回公钥及其证书。\n  浏览器检查该证书是否由可信任的机构颁发，并且是与站点相关的有效证书。\n  浏览器使用公钥加密随即对称加密密钥，和通过随即加密密钥加密的http数据一同发送给Web服务器。\n  Web服务器通过私钥解密随即对称加密密钥，并使用它解密http数据。\n  Web服务器返回通过随即对称加密密钥加密的请求html文本和http数据。\n  浏览器通过随即对称加密密钥解密html文本和http数据并展示信息。\n   公私钥: #  非对称加密，使用私钥/公钥对加密，数据可以被一个密钥加密，但只能被另一个密钥对解密。该密钥对自己保留一个私钥，并将公钥分配给每个人。\nMessage --\u0026gt; [Public Key] --\u0026gt; Encrypted Message --\u0026gt; [Private Key] --\u0026gt; Message   证书: #  证书加载在浏览器或者其他客户端党当中，证书包含了证书所有者的信息。一个例子:\nCertificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: md5WithRSAEncryption Issuer: C=FJ, ST=Fiji, L=Suva, O=SOPAC, OU=ICT, CN=SOPAC Root CA/Email=administrator@sopac.org Validity Not Before: Nov 20 05:47:44 2001 GMT Not After : Nov 20 05:47:44 2002 GMT Subject: C=FJ, ST=Fiji, L=Suva, O=SOPAC, OU=ICT, CN=www.sopac.org/Email=administrator@sopac.org Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (1024 bit) Modulus (1024 bit): 00:ba:54:2c:ab:88:74:aa:6b:35:a5:a9:c1:d0:5a: 9b:fb:6b:b5:71:bc:ef:d3:ab:15:cc:5b:75:73:36: b8:01:d1:59:3f:c1:88:c0:33:91:04:f1:bf:1a:b4: 7a:c8:39:c2:89:1f:87:0f:91:19:81:09:46:0c:86: 08:d8:75:c4:6f:5a:98:4a:f9:f8:f7:38:24:fc:bd: 94:24:37:ab:f1:1c:d8:91:ee:fb:1b:9f:88:ba:25: da:f6:21:7f:04:32:35:17:3d:36:1c:fb:b7:32:9e: 42:af:77:b6:25:1c:59:69:af:be:00:a1:f8:b0:1a: 6c:14:e2:ae:62:e7:6b:30:e9 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: FE:04:46:ED:A0:15:BE:C1:4B:59:03:F8:2D:0D:ED:2A:E0:ED:F9:2F X509v3 Authority Key Identifier: keyid:E6:12:7C:3D:A1:02:E5:BA:1F:DA:9E:37:BE:E3:45:3E:9B:AE:E5:A6 DirName:/C=FJ/ST=Fiji/L=Suva/O=SOPAC/OU=ICT/CN=SOPAC Root CA/Email=administrator@sopac.org serial:00 Signature Algorithm: md5WithRSAEncryption 34:8d:fb:65:0b:85:5b:e2:44:09:f0:55:31:3b:29:2b:f4:fd: aa:5f:db:b8:11:1a:c6:ab:33:67:59:c1:04:de:34:df:08:57: 2e:c6:60:dc:f7:d4:e2:f1:73:97:57:23:50:02:63:fc:78:96: 34:b3:ca:c4:1b:c5:4c:c8:16:69:bb:9c:4a:7e:00:19:48:62: e2:51:ab:3a:fa:fd:88:cd:e0:9d:ef:67:50:da:fe:4b:13:c5: 0c:8c:fc:ad:6e:b5:ee:40:e3:fd:34:10:9f:ad:34:bd:db:06: ed:09:3d:f2:a6:81:22:63:16:dc:ae:33:0c:70:fd:0a:6c:af: bc:5a -----BEGIN CERTIFICATE----- MIIDoTCCAwqgAwIBAgIBATANBgkqhkiG9w0BAQQFADCBiTELMAkGA1UEBhMCRkox DTALBgNVBAgTBEZpamkxDTALBgNVBAcTBFN1dmExDjAMBgNVBAoTBVNPUEFDMQww CgYDVQQLEwNJQ1QxFjAUBgNVBAMTDVNPUEFDIFJvb3QgQ0ExJjAkBgkqhkiG9w0B CQEWF2FkbWluaXN0cmF0b3JAc29wYWMub3JnMB4XDTAxMTEyMDA1NDc0NFoXDTAy MTEyMDA1NDc0NFowgYkxCzAJBgNVBAYTAkZKMQ0wCwYDVQQIEwRGaWppMQ0wCwYD VQQHEwRTdXZhMQ4wDAYDVQQKEwVTT1BBQzEMMAoGA1UECxMDSUNUMRYwFAYDVQQD Ew13d3cuc29wYWMub3JnMSYwJAYJKoZIhvcNAQkBFhdhZG1pbmlzdHJhdG9yQHNv cGFjLm9yZzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAulQsq4h0qms1panB 0Fqb+2u1cbzv06sVzFt1cza4AdFZP8GIwDORBPG/GrR6yDnCiR+HD5EZgQlGDIYI 2HXEb1qYSvn49zgk/L2UJDer8RzYke77G5+IuiXa9iF/BDI1Fz02HPu3Mp5Cr3e2 JRxZaa++AKH4sBpsFOKuYudrMOkCAwEAAaOCARUwggERMAkGA1UdEwQCMAAwLAYJ YIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0GA1Ud DgQWBBT+BEbtoBW+wUtZA/gtDe0q4O35LzCBtgYDVR0jBIGuMIGrgBTmEnw9oQLl uh/anje+40U+m67lpqGBj6SBjDCBiTELMAkGA1UEBhMCRkoxDTALBgNVBAgTBEZp amkxDTALBgNVBAcTBFN1dmExDjAMBgNVBAoTBVNPUEFDMQwwCgYDVQQLEwNJQ1Qx FjAUBgNVBAMTDVNPUEFDIFJvb3QgQ0ExJjAkBgkqhkiG9w0BCQEWF2FkbWluaXN0 cmF0b3JAc29wYWMub3JnggEAMA0GCSqGSIb3DQEBBAUAA4GBADSN+2ULhVviRAnw VTE7KSv0/apf27gRGsarM2dZwQTeNN8IVy7GYNz31OLxc5dXI1ACY/x4ljSzysQb xUzIFmm7nEp+ABlIYuJRqzr6/YjN4J3vZ1Da/ksTxQyM/K1ute5A4/00EJ+tNL3b Bu0JPfKmgSJjFtyuMwxw/Qpsr7xa -----END CERTIFICATE-----  该证书包含对发行人的引用，该证书的所有者的公钥，该证书的有效期和证书的签名，以确保该证书没有被篡改。\n 对称密钥: #  对称加密，使用相同密钥进行加密和解密。对称加密在处理速度上比非对称加密快，但安全性低。综合考虑，使用公私钥加解密对称密钥，在每次事务都选择不同的对称密钥是更安全和高效的方案。\nSymetric Key --\u0026gt; [Public Key] --\u0026gt; Encrypted Symetric Key --\u0026gt; [Private Key] --\u0026gt; Symetric Key   加密算法: #  加密算法有对称和非对称方法，使用不同长度的密钥。\n Hash #  哈希是由消息中的哈希函数给出的数字。 这是一个单向函数，这意味着不可能得到原始消息知道哈希。 然而，即使消息中最轻微的修改，哈希也会发生巨大变化。 因此，在保持其原始散列的同时修改消息是非常困难的。它也被成为消息摘要。哈希函数用于密码机制，用于证明应用程序是原始的（MD5总和），确保任何消息未被篡改。\n 签名 #  签署信息意味着验证您已经确定了邮件的真实性。要签署消息，需要创建其Hash，然后使用私钥加密Hash，然后添加加密Hash和签名的证书与消息。 收件人将重新创建消息hash，使用签名的证书中存储的公钥解密加密Hash，检查两个Hash是否相等，最后检查证书。\n PassPhrase #  PassPhrase就像一个密码，除了它更长。\n PKI #  Public Key Infrastructure（PKI）是软件管理系统和数据库系统，允许签署证书，保留撤销证书清单，分发公钥。\n CSRs #  要从CA获取SSL证书，就要生成一个certificate signing request (CSR)。CSR由密钥对的公钥和一些附加信息组成。这两个组件在签名时都会插入证书。\n生成CSR需要填入的信息：\n--- Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:New York Locality Name (eg, city) []:Brooklyn Organization Name (eg, company) [Internet Widgits Pty Ltd]:Example Brooklyn Company Organizational Unit Name (eg, section) []:Technology Division Common Name (e.g. server FQDN or YOUR name) []:examplebrooklyn.com Email Address []:   工作机制 TLS协议由两部分组成，包括（TLS Record Layer,TLS handshake protocol）\n  Record Layer:\n为每条信息提供一个header和在尾部生成一个从Message Authentication Code (MAC) 得到的hash值，其中header由5 bytes组成，分别是协议说明(1bytes),协议版本(2bytes)和长度(2bytes)，跟在header后面的协议信息长度不得超过16384bytes。\n  Handshake Protocol:\nTLS握手:\n    OpenSSl工具 OpenSSL是一个通用的命令行工具，可用于与公钥基础设施（PKI）和HTTPS（TLS over HTTP）相关的各种任务。\n生成CSRs #  #生成一个私钥和一个CSR openssl req -newkey rsa:2048 -nodes -keyout domain.key -out domain.csr #使用已存在的私钥生成CSR openssl req -key domain.key -new -out domain.csr   生成SSL证书 #  #生成一个私钥和自签名证书 openssl req -newkey ras:2048 -keyout domain.key -x509 -days 365 -out domain.crt #使用已存在的私钥生成自签名证书 openssl req -key domain.key -x509 -days 365 -out domain.crt #使用已存在的私钥和CSR生成自签名证书 openssl x509 -signkey domain.key -in domain.csr -req -days 365 -out domain.crt   查看证书 #  #查看CSR信息 openssl req -text -noout -verify -in domain.csr #查看证书信息 openssl x509 -text -noout -in domain.crt #验证证书是呦CA签署的 openssl verify -verbose -CAFile ca.crt domain.crt   生成私钥 #  #创建私钥文件 openssl genrsa -des3 -out domain.key 2048 #查看私钥信息 openssl rsa -check -in domain.key   证书格式转换 #  #PEM转DER openssl x509 -in domain.crt -outform der -out domain.der #DER转PEM openssl x509 -inform der -in domain.der -out domain.crt #PEM转PKCS7 openssl crl2pkcs7 -nocrl -certfile domain.crt -certfile ca-chain.crt -out domain.p7b #PKCS7转PEM openssl pkcs7 -in domain.p7b -print_certs -out domain.crt #PEM转PKCS12 openssl pkcs12 -inkey domain.key -in domain.crt -export -out domain.pfx #PKCS12转PEM openssl pkcs12 -in domain.pfx -nodes -out domain.combined.crt   抓包 #  process #   client_hello #    server_hello #    server_key_exchange #    client_key_exchange #    new session #    链接 #    "});index.add({'id':144,'href':'/notes/docs/technology/other/','title':"其他",'section':"技术相关",'content':"其他 #  "});index.add({'id':145,'href':'/notes/docs/technology/howto/','title':"How To",'section':"技术相关",'content':"How To #    LVS  "});index.add({'id':146,'href':'/notes/docs/technology/leetcode/','title':"LeetCode",'section':"技术相关",'content':"LeetCode #    学习  "});index.add({'id':147,'href':'/notes/docs/technology/other/language/','title':"英语学习",'section':"其他",'content':"英语学习 #  "});index.add({'id':148,'href':'/notes/docs/technology/bigdata/application/kafka/architecture/','title':"Architecture",'section':"Kafka",'content':"kafka架构 #  "});index.add({'id':149,'href':'/notes/docs/technology/bigdata/application/zookeeper/architecture/','title':"Architecture",'section':"Zookeeper",'content':"Zookeeper架构 #  "});index.add({'id':150,'href':'/notes/docs/technology/bigdata/application/zookeeper/deploy/','title':"Deploy",'section':"Zookeeper",'content':"Zookeeper部署 #  单机环境搭建 #    下载安装包\n wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 zookeeper    修改配置文件\n #vim zookeeper/conf/zoo.cfg tickTime=2000 initLimit=5 syncLimit=2 dataDir=/cache1/zookeeper/data #数据目录 clientPort=2181 #服务端口    配置日志保存目录\n #修改zookeeper/conf/log4j.properties文件 zookeeper.root.logger=INFO, ROLLINGFILE zookeeper.log.dir=/cache1/zookeeper/logs zookeeper.log.file=zookeeper.log #修改zookeeper/bin/zkEnv.sh if [ \u0026quot;x${ZOO_LOG_DIR}\u0026quot; = \u0026quot;x\u0026quot; ] then ZOO_LOG_DIR=\u0026quot;/cache1/zookeeper/logs/\u0026quot; fi if [ \u0026quot;x${ZOO_LOG4J_PROP}\u0026quot; = \u0026quot;x\u0026quot; ] then ZOO_LOG4J_PROP=\u0026quot;INFO,ROLLINGFILE\u0026quot; fi    启动服务\n cd zookeeper/bin \u0026amp;\u0026amp; ./zkServer.sh start     集群环境搭建 #    机器准备\n #3台设备 192.168.1.21 192.168.1.22 192.168.1.33    系统环境准备\n #/etc/hosts文件增加以下内容 192.168.1.21 zoo1 192.168.1.22 zoo2 192.168.1.33 zoo3    下载安装包\n wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 zookeeper    修改配置文件\n #vim zookeeper/conf/zoo.cfg tickTime=2000 initLimit=5 syncLimit=2 dataDir=/cache1/zookeeper/data #数据目录 clientPort=2181 #服务端口 server.1=zoo1:2888:3888 #server.x的x与myid文件的值匹配 server.2=zoo2:2888:3888 #zoo1表示hostname server.3=zoo3:2888:3888 #2888是followers用来连接leader，3888用于leader的选举    各机器创建myid文件\n #zoo1 echo 1 \u0026gt; /cache1/zookeeper/data/myid #zoo2 echo 2 \u0026gt; /cache1/zookeeper/data/myid #zoo3 echo 3 \u0026gt; /cache1/zookeeper/data/myid    各机器启动服务\n cd zookeeper/bin \u0026amp;\u0026amp; ./zkServer.sh start    "});index.add({'id':151,'href':'/notes/docs/technology/bigdata/application/zookeeper/optimization/','title':"Optimization",'section':"Zookeeper",'content':"Zookeeper优化 #  "});index.add({'id':152,'href':'/notes/docs/technology/cloud/devops/elk/elkinstall/','title':"Elkinstall",'section':"ELK",'content':"ELK安装 #  环境准备 #    CentOS 7\n  Java 8\n   ELK安装 #    配置ELK的repo文件\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch #vim /etc/yum.repo.d/elk.repo [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md    ElasticSearch\n#install yum install elasticsearch /bin/systemctl daemon-reload /bin/systemctl enable elasticsearch.service systemctl start elasticsearch.service #Test curl http://localhost:9200/    Kibana\n#install yum install kibana /bin/systemctl daemon-reload /bin/systemctl enable kibana.service #vim /etc/kibana/kibana.yml server.host: 0.0.0.0    LogStash\n#install yum install logstash /bin/systemctl start logstash.service    Filebeat\n#install yum -y install filebeat     配置 #    配置hosts\n#vim /etc/hosts 192.168.19.26 elk.cctest.com    生成SSL证书\ncd /etc/pki/tls openssl req -subj '/CN=elk.cctest.com/' -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt    logstash配置\n#vim /etc/logstash/conf.d/02-beats-input.conf input { beats { port =\u0026gt; 5044 ssl =\u0026gt; true ssl_certificate =\u0026gt; \u0026quot;/etc/pki/tls/certs/logstash-forwarder.crt\u0026quot; ssl_key =\u0026gt; \u0026quot;/etc/pki/tls/private/logstash-forwarder.key\u0026quot; } } #vim /etc/logstash/conf.d/10-log-filter.conf filter { grok { match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{COMBINEDAPACHELOG}\u0026quot; } } geoip { source =\u0026gt; \u0026quot;clientip\u0026quot; } } #vim /etc/logstash/conf.d/30-elasticsearch-output.conf output { elasticsearch { hosts =\u0026gt; [\u0026quot;localhost:9200\u0026quot;] } } #重启logstash /bin/systemctl restart logstash.service    filebeat配置\n#vim /etc/filebeat/filebeat.yml filebeat.prospectors: - type: log enabled: true paths: - /var/log/messages* filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 3 output.logstash: hosts: [\u0026quot;elk.cctest.com:5044\u0026quot;] ssl.certificate_authorities: [\u0026quot;/etc/pki/tls/certs/logstash-forwarder.crt\u0026quot;] # systemctl start filebeat    浏览器打开kibana\nhttp://localhost:5601/     "});index.add({'id':153,'href':'/notes/docs/technology/database/sql/mysql/cluster/','title':"Cluster",'section':"MySQL",'content':"MySQL Cluster #  Master-Slave #  Master配置 #  /etc/my.cnf 增加配置\n[mysqld] server-id=1 log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  Replication 帐号创建\nmysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY 'slave@2017';  导出数据到从库\nmysql\u0026gt; USE newdatabase; mysql\u0026gt; FLUSH TABLES WITH READ LOCK; mysql\u0026gt; SHOW MASTER STATUS; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000002 | 754 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec) shell\u0026gt; mysqldump -u root -p --opt newdatabase \u0026gt; newdatabase.sql mysql\u0026gt; UNLOCK TABLES;  Slave配置 #  /etc/my.cnf增加配置\n[mysqld] server-id=2 log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  导入数据\nmysql\u0026gt; CREATE DATABASE newdatabase; shell\u0026gt; mysql -u root -p newdatabase \u0026lt; /path/to/newdatabase.sql  配置主服务器\nmysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master_host_name',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=754; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;  从库切换成主库\nmysql\u0026gt; SHOW PROCESSLIST; mysql\u0026gt; RESET MASTER;   Master-Master #  Master1，Master2配置 #  /etc/my.cnf 增加配置\n[mysqld] server-id=1 (Master2配置成2) log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  Replication 帐号创建\nmysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY 'slave@2017';  Master1查看本机Master状态 #  mysql\u0026gt; SHOW MASTER STATUS; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000002 | 754 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec)  Master2查看本机Master状态 #  mysql\u0026gt; show master status; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000001 | 915 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec)  Master1配置成Master2的从库 #  mysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master2',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=915; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;  Master2配置成Master1的从库 #  mysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master_host_name',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=754; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;   "});index.add({'id':154,'href':'/notes/docs/technology/database/sql/mysql/install/','title':"Install",'section':"MySQL",'content':"Mysql 安装 #  源码编译安装 #  准备 #    CMake(build framework)\nyum -y install cmake    GNU make(make program)\nyum -y install make    GCC(ANSI C++ complier)\nyum -y install gcc gcc-c++    Boost C++ libraries\n  ncurses library\nyum -y install ncurses ncurses-devel    Perl(run test scripts)\nyum -y install perl     安装 #    创建用户组\nshell\u0026gt; groupadd mysql shell\u0026gt; useradd -r -g mysql -s /bin/false mysql    编译安装\nshell\u0026gt; tar -zxvf mysql-VERSION.tar.gz shell\u0026gt; cd mysql-VERSION shell\u0026gt; mkdir bld shell\u0026gt; cd bld shell\u0026gt; cmake .. -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/src -DCMAKE_INSTALL_PREFIX=/cache1/mysql -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci shell\u0026gt; make shell\u0026gt; make install    数据初始化\n  /etc/my.cnf文件配置\n[client] port=3306 socket=/tmp/mysql.sock [mysqld] bind-address=0.0.0.0 port=3306 socket=/tmp/mysql.sock datadir=/cache1/mysql/data symbolic-links=0 log-error=/cache1/mysql/log/mysqld.log pid-file=/cache1/mysql/log/mysqld.pid  数据初始化\nshell\u0026gt; cd /cache1/mysql shell\u0026gt; mkdir data log shell\u0026gt; chown -R mysql:mysql data shell\u0026gt; chown -R mysql:mysql log shell\u0026gt; bin/mysqld --initialize --user=mysql shell\u0026gt; cp support-files/mysql.service /etc/init.d/mysqld shell\u0026gt; /etc/init.d/mysqld start shell\u0026gt; mysql -uroot -p mysql\u0026gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'new_password'; mysql\u0026gt; SET PASSWORD = PASSWORD('your_new_password'); mysql\u0026gt; SELECT User, Host, HEX(authentication_string) FROM mysql.user;  "});index.add({'id':155,'href':'/notes/docs/technology/hidden/','title':"Hidden",'section':"技术相关",'content':"This page is hidden in menu #  Quondam non pater est dignior ille Eurotas #  Latent te facies #  Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona #  O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); }  Fronde cetera dextrae sequens pennis voce muneris #  Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "});index.add({'id':156,'href':'/notes/docs/technology/other/book_notes/codecademy/','title':"Codecademy",'section':"读书笔记",'content':"codecademy在线学习 #  HTML和CSS学习 #  HTML #  html基本机构 #  \u0026lt;!DOCTYPE html\u0026gt; //向浏览器声明类型 \u0026lt;html\u0026gt; //所有的html代码都要包含在该元素内 \u0026lt;head\u0026gt; //关于网页的信息，如标题 \u0026lt;title\u0026gt;First Web Page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; //可见的html代码内容都放在该元素内 \u0026lt;p\u0026gt;Hello,World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  可见内容 #    标题\nheading\n \u0026lt;h1\u0026gt;head\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt; \u0026lt;h3\u0026gt; \u0026lt;h4\u0026gt; \u0026lt;h5\u0026gt; \u0026lt;h6\u0026gt;    段落\nparagraph\n \u0026lt;p\u0026gt;content\u0026lt;/p\u0026gt;    无序列表\nunodered list, list item\n \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;sub\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;    有序列表\nordered list, list item\n \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;sub\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt;    链接\n链接, href属性，属性提供更多元素内容的有关信息,在元素的开头标签中，由名称和值组成\n \u0026lt;a href=\u0026quot;https://example.com\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;content\u0026lt;/a\u0026gt;  链接属性: target属性指定链接要在新的浏览器打开.\n  图片\nimage\n \u0026lt;img src=\u0026quot;https://example.com/example.jpg\u0026quot; alt=\u0026quot;example\u0026quot; /\u0026gt; alt属性: 描述图像信息    换行\nline breaks\n aaa?\u0026lt;br/\u0026gt;bbb    注释\n   CSS #  CSS是网页开发人员用来在网页上设计HTML内容的语言.\n在html文件中编写css代码\n在head元素中加入style元素\n \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; h2 { font-family: Arial; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt;  在css文件中编写css代码 在html文件链接css文件，放在html文件开头 使用link元素 * href属性 css文件地址 * type属性 描述文件类型 * rel属性 描述css和html文件的关系\n link href=\u0026quot;https://www.codecademy.com/stylesheets/style.css\u0026quot; type=\u0026quot;text/css\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt;  color #    foregroud\n前景色是元素出现的颜色，color属性表示前景色 \\\n  background\nbackground-color表示背景色。\n  named colors\n 147 named colors\ncolor: named colors\n  RGB colors\nRGB(Red,Green,Blue) color: rgb(123,20.233)\n  Hex colors\ncolor: #09AA34\n  HSL colors\nHSL(Hue, Saturation, Lightness) color: hsl(182, 20%, 50%)\n  font #    font-family\n更改字体系列，font-family: \u0026ldquo;Courier New\u0026rdquo;;\n  fallback fonts\n当指定的字体不存在时，使用系统预先安装的字体，font-family: fonts-name, serif;\n  font-size\n更改字体大小，font-size: 18px; 三种大小单位：px, em, %;\n  line height\n更改行高，font-height: 1.5em;\n  word spacing\n字间距，word-spacing: 0.3em;\n  letter spacing\n字母间距：letter-spacing: 0.3em;\n  font weight\n更改字体粗细，font-weight: bold;\n  font style\n字体风格，font-style: italic;\n  text transformation\n内容转型: text-transform: uppercase;\n  text alignment\n文本对齐: text-align: right;\n   "});index.add({'id':157,'href':'/notes/docs/technology/other/book_notes/CS50/','title':"C S50",'section':"读书笔记",'content':"CS50学习笔记 #  "});index.add({'id':158,'href':'/notes/docs/technology/other/book_notes/finacial/','title':"Finacial",'section':"读书笔记",'content':"Finanical #  Goal Setting #  Understand How Goals Are Used #    What is a goal?\n  Long term vs Intermediate vs Short term\n  Is a financial goal any different than other goals?\n  SMART Goals #    Specific\n  Measurable\n  Attainable\n  Realistic\n  Time\n  Finanical Goals #    Saving\n  Housing\n  Insurance\n  Retirement\n   Budgeting #  What is a budget #    What is a budget\n A budget is a spending plan Dollars designated for specific areas    Where do the numbers come from?\n Cash flow statement A budget can be changed Review your cash flow statement to find excess or unusual amounts    Types of Budgets #    Written\n  Envelope\n  Mental\n  Develop the Budget #    Take a look at the cash flow statement\n  List all income\n  List the expenses by category\n  Compare income to expenses\n  Fixed or Variable? #    Fixed expenses\n  Variable expenses\n  Adjust variable expenses to keep expenses less than your income\n  Or adjust income to make income cover expenses\n   Credit #  What is credit ? #    What is credit?\n  Consumer credit\n  cost of credit\n  What is the Credit bureau? #   The credit bureau collects and shares your credit information  Credit Score #    Five factors that are considered\n  Payment history\n  Debt\n  Length of credit history\n  Types of credit\n  Inquiries\n    Type of Credit #    Credit card\n  Convenience users vs borrower\n  Bank card or merchant card\n    Unsecured loan\n Depending on your credit, this may or may not be available    Secured loan\n The lender has collateral ,therefore less risk.    Mortgage\n Less risk, but larger amount.    Obtaining the Credit #    Credit card\n Apply for a credit card.    Unsecured loan\n Talk to your financial institution.    Secured loan\n Talk to your financial institution or the company selling the product    Mortgage\n Apply through your financial institution.    Evaluating Credit Worthiness #    Capacity\n  Character\n  Collateral\n  Capital\n  Conditions\n   Insurance #  What is insurance ? #    What is insurance?\n Insurance is all about risk management Insurance is available to prevent financial loss The insurance company assumes the risk for you The individual pays the company a premium    Where do the numbers come from?\n The likelihood of an individual experiencing a loss The potential cost of each loss Based on the concept of large numbers    Risk management terms #    Risk\n An unpredictable chance of loss or injury    Hazard\n Anything that increases the likelihood a loss    Peril\n Anything that causes a loss    Liability\n The legal responsibility for someone else\u0026rsquo;s loss    Areas of Insurance #    Property\n Automobile Home Personal possessions    Liability\n  Health\n  Life\n   Investing #  Common Types of Investments #    Money Market Securities\n  Stock\n  Bonds\n  Mutual Funds\n  Return on Investment #    Dividend or interest\n  Increase(or decrease) in value\n  Risk #    Inflation\n  Interest rate\n  Business failure\n  Market\n  Common Mistakes #    Unrealistic goals\n  Lose sight of the goal\n  Borrowing to invest\n  Taking additional risk to cover previous losses\n  Accepting advice from \u0026ldquo;the expert\u0026rdquo;\n   #  "});index.add({'id':159,'href':'/notes/docs/technology/other/book_notes/thinkOS/','title':"Think O S",'section':"读书笔记",'content':"操作系统思考 #  编译 #   编译语言和解释语言    编译语言\n程序被翻译成机器语言，之后由硬件执行。\n  解释语言\n程序被软件解释器读取并执行。\n  静态类型和动态类型    动态类型\n无需定义变量类型，直到运行时才直到变量类型，解释语言通常支持动态类型。\n  静态类型\n需定义变量类型，编译语言通常限制为静态类型。\n优点：\n  编译时检查，可以更快找到错误。\n  节省空间\n动态语言，变量的名称在程序运行时存储在内存中，并且它们通常可由程序访问。 编译语言，变量的名称只存在编译时，而不是运行时。 编译器为每个变量选择一个位置，并记录这些位置作为所编译程序的一部分。变量的位置被称为“地址”。在运行期间，每个变量的值都存储在它的地址处，但变量的名称完全不会存储。      编译过程    预处理\nC是包含\u0026quot;预处理指令\u0026quot;的几种语言之一，它生效于编译之前。例如，#include 指令使其他文件的源代码插入到指令所在的位置\n  解析\n编译器读取源代码，并构建程序的内部表示，称为\u0026quot;抽象语法树(AST)\u0026quot;。这一阶段的错误检查通常为语法错误。\n  静态检查\n编译器会检查变量和值得类型是否正确，函数调用是否带有正确数量和类型的参数，以及其他。这一阶段的错误检测通常为一些\u0026quot;静态语义\u0026quot;的错误\n  代码生成\n编译器读取程序的内部表示，并生成机器码或字节码\n  链接\n如果程序使用了定义在库中的值或函数，编译器需要找到合适的库并包含所需要的代码。\n  优化\n在这个过程的几个时间点上，编译器可以修改程序来生成运行更快或占用更少空间的代码。\n  目标代码  编译后的程序，目标代码并不是可执行代码，但是它可以链接到可执行文件中。\n汇编代码  编译后的程序，它通常为机器代码的可读形式。\n 预处理\n  理解错误\n   进程 #   抽象和虚拟化    抽象\n抽象是复杂事物的简单表示。\n  虚拟化\n一类非常重要的抽象就是虚拟化，它是创建可取的幻象的过程。\n  隔离  工程最重要的原则之一就是隔离(lsolation)。\n操作系统最重要的目标之一，就是将每个进程和其他进程隔离，使程序员不必考虑每个可能的交互情况。提供这种隔离的软件对象叫做进程(Porcess)。\n进程是表示运行中程序的软件对象。通常一个对象包含数据，并且提供用于操作数据的方法。\n进程正是包含以下数据的对象：\n 程序文本，通常是机器语言的指令序列。 程序相关的数据，包括静态数据（编译时分配）和动态数据，后者包括运行时的栈和堆。 任何等等中的IO状态。 程序的硬件状态，包括存储在寄存器中的数据，状态信息，以及程序计数器，它表示当前执行了哪个指令。  操作系统提供了隔离进程的基本功能：\n 多任务：大多数操作系统有能力在几乎任何时候中断一个进程，保存它的硬件状态，并且在以后恢复它。 虚拟内存：大多数操作系统会创建幻象，每个进程看似拥有独立内存片并且孤立于其他进程。 设备抽象：运行于同一台计算机的进程共享磁盘、网络接口、显卡和其他硬件。   虚拟内存 #   虚拟内存 #   简明信息理论  比特是二进制的数字，也是信息单位。 n个比特可以表示2 ** b个值，一个字节是8个比特，所以它可以存储256个值。\n内存(Memory)和存储器(Storage)  当进程处于运行期间，它的多数数据都放在内存中。内存中的数据容易丢失。单位为GiB代表\u0026quot;gibibyte\u0026rdquo;，相当于2 ** 30字节\n如果进程会读写文件，这些文件通常放在存储器中。存储器的数据可用于长时间存储。单位为GB代表\u0026quot;gigabyte\u0026rdquo;，相当于10 ** 30字节\n地址空间  内存中的每个字节都由一个\u0026quot;物理地址\u0026quot;整数所指定，物理地址的集合叫做物理\u0026quot;地址空间\u0026rdquo;。范围通常为0到N-1，N是内存大小。\n操作系统提供\u0026quot;虚拟内存\u0026rdquo;，程序处理虚拟地址，范围为0到M-1，M是有效虚拟地址的大小。虚拟地址空间的大小取决于操作系统和硬件。\n  32位系统\n虚拟地址是32位的，虚拟地址空间的大小是2 ** 32个字节，或者4GiB\n  64位系统\n虚拟地址是64位的，虚拟地址空间的大小是2 ** 64个字节，或者是4 * 1024 ** 6个字节，16EiB\n  当一个程序读写内存中的值时，它使用虚拟地址。硬件在操作系统的帮助下，在访问主存之前将物理地址翻译成虚拟地址。翻译过程在进程层级上完成，所以两个进程访问相同的虚拟地址，他们所映射的物理地址可能不同。\n虚拟内存是操作系统隔离进程的一种重要途径。\n内存段  一个运行中进程的数据组织为4个段：\n text段：包含程序文本，即程序所组成的机器语言指令。靠近内存\u0026quot;底部\u0026rdquo;，即接近0的地址 static段：包含由编译器所分配的变量，包含全局变量和使用static声明的局部变量。通常刚好在text段上面 stack段：包含运行时栈，它由栈帧组成。每个帧包含函数参数、本地变量以及其他。靠近内存顶部，即接近虚拟地址空间的最大地址。在扩张过程中，它向低地址的方向增长。 heap段：包含运行时分配的内存块，通常通过调用C标准库函数malloc来分配。通常在static段的上面，在扩张过程中，它向高地址的方向增长。  静态局部变量  栈上的局部变量有时称为\u0026quot;自动变量\u0026rdquo;，它们当函数创建时自动被分配，并且当函数返回时自动被释放。\nC中有另一种局部变量，叫做\u0026quot;静态变量\u0026rdquo;，它分配在static段上。它在程序启动时初始化，并且在函数调用之间保存它的值。\n地址翻译  虚拟地址(VA)翻译成物理地址(GA)\n大多数处理器提供了内存管理单元(MMU)，位于CPU和主存之间。MMU在VA和PA之间执行快速的翻译。\n 当程序读写变量时，CPU会得到VA。 MMU将VA分成两部分，称为页码和偏移。\u0026ldquo;页\u0026quot;是一个内存块，页的大小取决于操作系统和硬件，通常为1~4KiB MMU在\u0026quot;页表\u0026quot;里查找页码，然后获取相应的物理页码。之后将物理页码和偏移组合得到PA。 PA传递给主存，用于读写指定地址。   文件和文件系统 #  “文件系统”将每个文件的名称映射到它的内容。是一种键值对的数据库。 “文件”是一组字节序列。\n文件名通常是字符串，并且通常是分层的。这个字符串指定了顶级目录的路径，通过一系列子目录，到达特定的文件。\n文件是基于字节的，而持久化存储器是基于块的。操作系统将C标准库中基于字节的文件操作翻译成基于块的存储设备操作。\n 文件的读取和写入过程：    读取\n 程序使用文件名寻找顶级目录，子目录以及n级目录 找到名为xxx的文件，并且\u0026quot;打开\u0026quot;它以便读取。实际上是创建了一个数据结构料表示将要读取的文件。数据结构还跟踪了文件读取了多少字节，称为“文件位置”。 操作系统检查下个字节是否已经在内存中。如果是的话，读取下一个字节，向前移动文件位置，并返回结果。 如果不在内存中，操作系统产生IO请求来获取下一个块。 IO操作完成时，新的数据快回存储在内存中。 当进程关闭文件时，操作系统完成或取消任何等待中的操作，移除内存中的数据，并且释放OpenFileTableEntry    写入\n 程序使用文件名寻找文件。如果文件不存在，就会创建新的文件，并向父目录添加条目 操作系统创建OpenFileTableEntry，表示这个文件已打开等待写入，并将文件位置设置为0. 程序尝试写入文件的第一个字节。如果文件存在，操作系统需要将第一个块加载到内存中。否则它会在内存中分配新的块，并且在磁盘上请求新的块。 在内存中的块被修改后，可能不会立即复制回磁盘。通常，写到文件中的数据是“被缓冲的”，意思是它存储在内存中，只在至少有一个块需要写入时才写回磁盘。 文件关闭时，任何缓冲的数据都会写到磁盘，并且OpenFileTableEntry会被释放。    C标准库提供了文件系统的抽象，将文件名称映射到字节流。这个抽象建立在实际以块组织的存储设备之上。\n磁盘性能  操作系统和硬件提供了一些特性用于弥补主存和持久化存储器的性能间隔。\n 块的传输 预取 缓冲  磁盘元数据  块可以放在磁盘上的任意位置，使用各种数据结构来跟踪这些块。\n在UNIX文件系统中，这些数据结构叫做inode，它代表“索引节点”(index node)。也叫做“元数据”(数据的数据)\n块的分配  操作系统既要跟踪哪些块属于哪个文件，也需要跟踪哪些块可供使用。\n块分配系统的目标：\n 速度：块的分配和释放应该很快。 最小的空间开销 最少的碎片 最大的连续性   内存管理 #  动态内存分配函数：\n malloc， 接受表示字节单位的大小的整数，返回指向新分配的、(至少)为指定大小的内存块的指针。如果不满足，返回NULL指针 calloc， 和malloc一样，还会清空新分配的空间。 free， 它接受指向之前分配的内存块的指针，并会释放它 realloc，接受指向之前分配的内存块的指针，和一个新的大小    内存错误\n 访问任何没有分配的内存块 释放某个内存块之后再访问它 释放一个没有分配的内存块 释放多次相同的内存块 使用没有分配或者已经释放的内存块调用realloc    内存泄漏\n分配了一块内存，并且没有释放它，导致内存总量无限增长\n  实现\n   缓存 #   程序如何运行  操作系统创建新的进程来运行程序，之后\u0026quot;加载器\u0026quot;将代码从存储器复制到主存中，并且通过调用main来启动程序。\n在程序运行时，大部分数据存储在主存中，一些数据存储在寄存器中，它是CPU上的小型存储单元，包括：\n 程序计数器(PC)，含有程序下一条指令(在内存中)的地址 指令寄存器(IR)，含有当前执行的指令的机器码。 栈指针(SP)，含有当前函数栈帧的指针，其中包含函数参数和局部变量。 程序当前使用的存放数据的通用寄存器。 状态寄存器，含有当前计算的信息。  在程序运行时，CPU执行下列步骤，叫做\u0026quot;指令周期\u0026rdquo;：\n 取指(Fetch)：从内存中获取下一条指令，存储在指令寄存器中。 译码(Decode)：控制单元将指令译码，并向CPU的其他部分发送信号。 执行(Execute)：收到来自控制单元的信号后会执行合适的计算。  缓存性能  \u0026ldquo;缓存\u0026quot;是CPU上小型、快速的存储空间。\n当CPU从内存中读取数据时，它将一份副本存到缓存中。如果再次读取相同的数据，CPU就直接读取缓存。\n存储器层次结构     设备 访问时间 通常大小     寄存器 0.5 ns 256 B   缓存 1 ns 2 MiB   DRAM 10 ns 4 GiB   SSD 10 us 100 GiB   HDD 5 ms 500 GiB     缓存策略\n  页面调度\n  操作系统可以将页面在存储器和内存之间移动。这种机制叫做\u0026quot;页面调度\u0026rdquo;。\n工作流程:\n 进程A调用malloc来分配页面。如果堆中没有所请求大小的空闲空间，malloc会调用sbrk向操作系统请求更多内存。 如果物理内存中有空闲页，操作系统会将其加载到进程A的页表，创建新的虚拟内存范围。 如果没有空闲页面，调度系统会选择一个属于进程B的\u0026quot;牺牲页面\u0026rdquo;。它将页面内容从内存复制到磁盘，之后修改进程B的页表来表示这个页面\u0026quot;被换出\u0026rdquo; 一旦进程B的数据被写入，页面会重新分配给进程A。为了防止进程A读取进程B的数据，页面应被清空。 此时sbrk的调用可以返回，向malloc提供堆区额外的空间。之后malloc分配所请求的内存并返回。进程A可以继续执行。 当进程A执行完毕，或中断后，调度器可能会让进程B继续执行。当它访问到被换出的页面时，内存管理器单元注意到这个页面是\u0026quot;无效\u0026quot;的，并且会触发中断。 当操作系统处理中断时，它会看到页面被换出了，于是它将页面从磁盘传送到内存。 一旦页面被换入之后，进程B可以继续执行。  页面调度可以极大提升物理内存的利用水平，允许更多进程在更少的空间内执行。原因：\n 大多数进程不会用完所分配内存。这些页面被换出而不会引发任何问题。 如果程序泄漏了内存，它可能会丢掉所分配的空间。通过将这些页面换出，可以有效填补泄漏。 当进程闲置时，这些进程可以被换出 当多进程运行同一个程序时，进程可以共享相同的text段，避免在物理内存中保留过多副本。   多任务 #  CPU包含多个核心，也就是说可以运行多个进程。并且，每个核心都具有\u0026quot;多任务\u0026quot;的能力。也就是说它可以从一个进程快速切换到另一个进程，创造出同时运行许多进程的幻象。\n在操作系统中，多任务由内核实现。其本质就是处理中断。“中断”是一个事件，它会停止通常的指令周期，并且使执行流跳到称为“中断处理器”的特殊代码区域内。\n当一个设备向CPU发送信号时，会发生硬件中断。软件中断由运行中的程序所产生。\n当程序需要访问硬件设备时，会进行“系统调用”，它就像函数调用，除了并非跳到函数的起始位置，而是执行一条特殊的指令来触发中断，使执行流跳到内核中。内核读取系统调用的参数，执行所请求的操作，之后使被中断进程恢复运行。\n 硬件状态   当中断发生时，硬件将程序计数器保存到一个特殊的寄存器中，并且跳到合适的中断处理器。 中断处理器将程序计数器和位寄存器，以及任何打算使用的数据寄存器的内容储存到内存中。 中断处理器运行处理中断所需的代码。 之后它复原所保存寄存器的内容。最后，复原被中断进程的程序计数器，这会跳回到被中断的进程。  上下文切换  中断处理器非常快，因为它们不需要保存整个硬件状态。它们只需要保存打算使用的寄存器。\n但是当中断发生时，内核并不总会恢复被中断的进程。它可以选择切换到其它进程，这种机制叫做“上下文切换”。\n进程的生命周期  当进程被创建时，操作系统会为进程分配包含进程信息的数据结构，称为“进程控制块”（PCB）。在其它方面，PCB跟踪进程的状态，这包括：\n 运行（Running），如果进程正在运行于某个核心上。 就绪（Ready），如果进程可以但没有运行，通常由于就绪进程数量大于内核的数量。 阻塞（Blocked），如果进程由于正在等待未来的事件，例如网络通信或磁盘读取，而不能运行。 终止（Done）：如果进程运行完毕，但是带有没有读取的退出状态信息。  下面是一些可导致进程状态转换的事件：\n 一个进程在运行中的程序执行类似于fork的系统调用时诞生。在系统调用的末尾，新的进程通常就绪。之后调度器可能恢复原有的进程（“父进程”），或者启动新的进程（“子进程”）。 当一个进程由调度器启动或恢复时，它的状态从就绪变为运行。 当一个进程被中断，并且调度器没有选择使它恢复，它的状态从运行变成就绪。 如果一个进程执行不能立即完成的系统调用，例如磁盘请求，它会变为阻塞，并且调度器会选择另一个进程。 当类似于磁盘请求的操作完成时，会产生中断。中断处理器弄清楚哪个进程正在等待请求，并将它的状态从阻塞变为就绪。 当一个进程调用exit时，中断处理器在PCB中储存退出代码，并将进程的状态变为终止。  调度  大多数情况下，只有一小部分进程是就绪或者运行的。当中断发生时，调度器会决定那个进程应启动或恢复。\n大多数调度器使用一些基于优先级的调度形式，其中每个进程都有可以调上或调下的优先级。当调度器运行时，它会选择最高优先级的就绪进程。\n下面是决定进程优先级的一些因素：\n 具有较高优先级的进程通常运行较快。 如果一个进程在时间片结束之前发出请求并被阻塞，就可能是IO密集型程序或交互型程序，优先级应该升高。 如果一个进程在整个时间片中都运行，就可能是长时间运行的计算密集型程序，优先级应该降低。 如果一个任务长时间被阻塞，之后变为就绪，它应该提升为最高优先级，便于响应所等待的东西。 如果进程A在等待进程B的过程中被阻塞，例如，如果它们由管道连接，进程B的优先级应升高。 系统调用nice允许进程降低（但不能升高）自己的优先级，并允许程序员向调度器传递显式的信息。  实时调度  调度满足截止期限的任务叫做“实时调度”。对于一些应用，类似于Linux的通用操作系统可以被修改来处理实时调度。这些修改可能包括：\n 为控制任务的优先级提供更丰富的API。 修改调度器来确保最高优先级的进程在固定时间内运行。 重新组织中断处理器来保证最大完成时间。 修改锁和其它同步机制（下一章会讲到），允许高优先级的任务预先占用低优先级的任务。 选择保证最大完成时间的动态内存分配实现。   "});index.add({'id':160,'href':'/notes/docs/technology/other/interview/classic/browser/','title':"Browser",'section':"经典问题",'content':"经典问题 #  1. 当输入google.com时，发生了什么？ #  1.1 URL解析 #  当输入的URL不合法时，浏览器会将输入的字符传给默认搜索引擎，\n浏览器通过URL能知道以下信息：\nprotocol: http host: google.com resource: / 1.2 HTST #  1、浏览器检查自身的HTST列表，确认是否包含该主机。 2、若HTST存在该主机，使用https代替http，否则使用http。 1.3 DNS解析 #  1、浏览器检查自身的DNS缓存 2、查找本地hosts文件 3、发起DNS解析查询 4、查询 本地|ISP DNS服务器 5、本地|ISP DNS服务器像高层服务器发起递归查询直到查到该域名的解析IP 1.4 TCP连接建立 #  1、client端发送SYN请求到server端，声明自己的ISN为aaa (CLOSED--\u0026gt;SYN-SENT) 2、server端接收SYN包，声明自己的ISN为bbb，ACK信息为aaa+1，返回给client端 (LISTEN--\u0026gt;SYN-RECEIVED) 3、client端返回ACK为bbb+1为server端 (SYN-SENT--\u0026gt;ESTABLISHED) 4、数据交互 1.5 TLS连接建立 #  1.6 HTTP #   "});index.add({'id':161,'href':'/notes/docs/technology/other/interview/history/interview/','title':"Interview",'section':"总结",'content':"面试经历 #  CF #   如何部署 如何监控 部署怎么实现 docker的优势和劣势   RC #  一面 #  1、Docker部署\n2、nginx_lua的几个阶段\n3、TCP窗口滑动、慢启动\n4、LVS的几种模式实现原理\n5、nginx location的优先级\n6、监控系统架构\n7、网络7层的功能\n8、HTTP的同源策略\n9、算法题，开根号\n10、python题，[for i range xxx] 与 (for i range xxx)区别\n二面 #  1、浏览器输入网址后发生了什么？(客户端，服务端(框架里面的路由实现))\n2、k8s ci/cd 迁移怎么做的\n3、算法题，全排列\n4、自动化做了什么\n5、ansible做了什么\n6、Docker如何实现隔离，属于什么级别的隔离\n7、成本控制怎么做\n "});index.add({'id':162,'href':'/notes/docs/technology/other/interview/tech/technology/','title':"Technology",'section':"技术知识点",'content':"技术知识点 #  1. 计算机基础 #   硬件 #  1. 机器型号 #  dmidecode | awk -F\u0026#39;:\u0026#39; \u0026#39;/Product Name/{print $2}\u0026#39; 2. CPU信息 #  #获取逻辑CPU数 awk -F':' '/name/{print $2}' /proc/cpuinfo | wc -l #获取CPU型号 awk -F':' '/name/{print $2}' /proc/cpuinfo | uniq #获取物理cpu数 grep \u0026quot;physical id\u0026quot; /proc/cpuinfo | sort | uniq | wc -l 3. 内存信息 #  #获取内存大小 free -h #内存物理信息 dmidecode -t memory 4. 磁盘信息 #   5. 计算机组成 #  1. 控制器 2. 运算器 3. 存储器 4. 输入设备 5. 输出设备 系统 #   网络 #  1. TCP协议 #  1.1三次握手 #  1、server端开启端口监听。(CLOSED--\u0026gt;LISTEN) 2、client端发送SYN信息给server端。(CLOSED--\u0026gt;SYN-SENT) 3、server端接收SYN信息，返回ACK信息和SYN信息给client端。(LISTEN--\u0026gt;SYN-RECEIVED) 4、client端接收ACK和SYN信息，并返回一个ACK信息给server端.(SYN-SENT--\u0026gt;ESTABLISHED) 5、server端接收ACK信息。(SYN-RECEIVED--\u0026gt;ESTABLISHED) 6、连接建立  1.2四次挥手 #  1、client端主动发起关闭请求，发送FIN信息给server端(ESTABLISHED--\u0026gt;FIN-WAIT-1) 2、server端接收FIN信息，并返回一个ACK信息，等待应用确认关闭连接(ESTABLISHED--\u0026gt;CLOSE-WAIT) 3、client端接收ACK信息，等待server端的FIN信息(FIN-WAIT-1--\u0026gt;FIN-WAIT-2) 4、server端确认关闭，发送FIN信息给client端(CLOSE-WAIT--\u0026gt;LAST-ACK) 5、client端接收FIN信息，返回一个ACK信息。(FIN-WAIT-2--\u0026gt;TIME-WAIT) 6、server端接收ACK信息，关闭连接。(LASK-ACK--\u0026gt;CLOSED) 7、client端超时关闭连接。(TIME-WAIT--\u0026gt;CLOSED) 8、连接关闭 2. DNS #  1、查找本机缓存 2、查找本地hosts 3、查找路由器缓存 4、查找本地/ISP DNS服务器 5、查找根服务器 6、递归查询直到查到域名解析IP 7、本地DNS服务器缓存，返回给本机 3. HTTP #   WEB #  1. CDN #  1. client请求www.cctest.com 2. www.cctest.com CNAME 到 cctest.cdncache.com 3. CDN内部根据源IP得到离源IP最近的Cache服务器IP，并返回给client 4. client向Cache服务器发起请求 5. 请求内容存在，直接返回给client 6. 请求内容不存在，Cache服务器向RealServer请求内容 7. Cache服务器缓存RealServer的内容，并将内容返回给client 2.Lvs #  四层负载均衡\n1. client向LVS发起请求 2. LVS根据路由模式和调度算法分配realserver 3. client向realserver发起请求 路由模式:\n  NAT\n1. client request load balance 2. load balance 选择一台 realserver 3. 更改packet的dest ip port 为realserver的ip port 4. realserver接收并返回请求 5. load balance 更改packet的source ip port 为 loadbalance的ip port   DR\n1. client request load balance 2. load balance 选择一台 realserver 3. 更改目的mac地址，转发到realserver 4. realserver接受请求，返回给client   TUN\n1. client request load balance 2. load balance 选择一台 realserver 3. 通过tunnel将请求转发给realserver 4. realserver接受请求，返回给client   调度算法：\n1. rr 2. wrr 3. lc 4. wlc 5. lblc 6. lblcr 7. dh 8. sh 9. sed 10. nq 3.Nginx #  WEB服务器，七层负载，反向代理\n4.Tomcat #   编程 #  "});index.add({'id':163,'href':'/notes/docs/technology/other/myconfig/vim/vimconf/','title':"Vimconf",'section':"环境配置",'content':"Vim配置指南 #  Don\u0026rsquo;t put any lines in your vimrc that you don\u0026rsquo;t understand. #      Colors\n   Spaces And Tabs\n   UI Config\n   Searching\n   Folding\n   Custom Movements\n   Custom Leader\n   CtrlP Settings\n   Launch Config\n   Tmux Config\n   Autogroups\n   Backups\n   Custom Functions\n   Organization\n   Wrapping It Up\n   Colors colorscheme badwolf \u0026quot; 设置色彩方案 systax enable \u0026quot; 开启语法处理   Spaces \u0026 Tabs set tabstop=4 \u0026quot; 设置每个TAB的视觉空格数 set softtabstop=4 \u0026quot; 设置编辑时tab的空格数 set expandtab \u0026quot; 将\u0026lt;TAB\u0026gt;符号转换为空格   UI Config set number \u0026quot; 显示行号 set showcmd \u0026quot; 在vim右下方显示最后一个命令，在powerline插件内有效 set cursorline \u0026quot; 当前行高亮 "});index.add({'id':164,'href':'/notes/docs/technology/other/solution/aboutNtpdate/','title':"About Ntpdate",'section':"问题集锦",'content':"时间同步相关问题 #  ntpdate:no server suitable for synchronization found #  Question： #  　在使用ntpdate同步时间时，出现了no server suitable for synchronization found的报错。\n　通过ntpdate -d s2m.time.edu.cn 使用debug模式没有出现异常。\nAnswer： #  解决办法是，使用ntpdate -ubv s2m.time.edu.cn，可以正常同步了。\n主要是-u选项的作用\n-u：Direct ntpdate to use an unprivileged port for outgoing packets. This is most useful when behind a firewall that blocks incoming traffic to privileged ports, and you want to synchronize with hosts beyond the firewall. Note that the -d option always uses unprivileged ports.   "});index.add({'id':165,'href':'/notes/docs/technology/other/solution/aboutSsh/','title':"About Ssh",'section':"问题集锦",'content':"ssh连接相关问题 #  pam_tally2(sshd:auth): user root (0) has time limit [3s left] since last failure 日志 #  Question： #  工作中，碰到某服务器在批量ssh登陆操作时，出现大量的无法连接的情况。\nThinking： #  查看ssh日志(/var/log/secure)， 首先注意到的是，\u0026ldquo;Failed password for root from xxx.xxx.xxx.xxx port 51230 ssh2\u0026quot;错误，但发现密码并没有错误，并且只在批量操作时才会出现，故初步判断为连接数问题。\n查看ssh连接数限制\n/usr/sbin/sshd -T | grep -i max  调整参数，更改配置文件/etc/sshd/sshd_config\nmaxsessions 1000  重启服务后，依然没有效果。\n再次查看日志，发现在做批量操作时，有大量的\u0026quot;pam_tally2(sshd:auth): user root (0) has time limit [3s left] since last failure\u0026quot;日志。\n应该是pam模块做了相应的限制\n查看配置文件 /etc/pam.d/sshd 文件\nauth required pam_tally2.so deny=10 lock_time=3 unlock_time=30 even_deny_root root_unlock_time=30  Answer： #  更改配置文件：\n#auth required pam_tally2.so deny=10 lock_time=3 unlock_time=30 even_deny_root root_unlock_time=30   "});index.add({'id':166,'href':'/notes/docs/technology/program/advanced/design/factoryMethod/','title':"Factory Method",'section':"设计模式",'content':"工厂方法模式(Factory Method Pattern) #  模式定义 #  工厂方法模式(Factory Method Pattern)又称为工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。\n 模式结构 #    Product：抽象产品\n  ConcreteProduct：具体产品\n  Factory：抽象工厂\n  ConcreteFactory：具体工厂\n   "});index.add({'id':167,'href':'/notes/docs/technology/program/advanced/design/simpleFactory/','title':"Simple Factory",'section':"设计模式",'content':"简单工厂模式(Simple Factory Pattern) #  模式定义 #  简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。\n 模式结构 #    Factory：工厂角色\n工厂角色负责实现创建所有实例的内部逻辑\n  Product：抽象产品角色\n抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口\n  ConcreteProduct：具体产品角色\n具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。\n   "});index.add({'id':168,'href':'/notes/docs/technology/program/language/python/CookBook/DataStructuresAndAlgorithms/README/','title':"R E a D M E",'section':"Python",'content':"数据结构和算法 #    解压序列赋值给多个变量\n问题，现在有一个包含N个元素的元组或者是序列，怎样将它里面的值解压后同时赋值给N个变量？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; data = ['John',170,60,(1999,9,9)] \u0026gt;\u0026gt;\u0026gt; name, height, weight, birthday = data ### 另一种方式 \u0026gt;\u0026gt;\u0026gt; name, height, weight, (year, mon, day) = data    解压可迭代对象赋值给多个变量\n问题，如果一个可迭代对象的元素个数超过变量个数时，会抛出一个ValueError。那么怎样才能从这个可迭代对象中解压出N个元素出来？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212') \u0026gt;\u0026gt;\u0026gt; name, email, *phone_numbers = record    保留最后N个元素\n问题，在迭代操作或者其他操作的时候，怎样只保留最后有限几个元素的历史记录？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from collections import deque \u0026gt;\u0026gt;\u0026gt; q = deque(maxlen = 3) \u0026gt;\u0026gt;\u0026gt; q.append(1) \u0026gt;\u0026gt;\u0026gt; q.append(2) \u0026gt;\u0026gt;\u0026gt; q.append(3) \u0026gt;\u0026gt;\u0026gt; q deque([1, 2, 3], maxlen=3) \u0026gt;\u0026gt;\u0026gt; q.append(4) \u0026gt;\u0026gt;\u0026gt; q deque([2, 3, 4], maxlen=3)    查找最大或最小的N个元素\n问题，怎样从一个集合中获得最大或者最小的N个元素列表？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; import heapq \u0026gt;\u0026gt;\u0026gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2] \u0026gt;\u0026gt;\u0026gt; heapq.nlargest(3,nums) [42, 37, 23] \u0026gt;\u0026gt;\u0026gt; heapq.nsmallest(3,nums) [-4, 1, 2]    实现优先级队列\n问题，给定一个具有优先级的队列，每次pop操作取出优先级最高的Item\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from heapq import heappush, heappop \u0026gt;\u0026gt;\u0026gt; heap = [] \u0026gt;\u0026gt;\u0026gt; data = [(2,'A'),(7,'B'),(5,'C')] \u0026gt;\u0026gt;\u0026gt; for item in data: ... heappush(heap, item) ... \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) A \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) C \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) B    字典中将键映射到多个值\n问题，字典是每个键映射到单个值的映射。如果要将键映射到多个值，则需要将多个值存储在另一个容器中，例如列表或集合。\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; d = {'a':[1,2,3],'b':[4,5]} \u0026gt;\u0026gt;\u0026gt; d = {'a':{1,2,3},'b':{4.5}} #另一种实现 \u0026gt;\u0026gt;\u0026gt; from collections import defaultdict \u0026gt;\u0026gt;\u0026gt; d = defaultdict(list) \u0026gt;\u0026gt;\u0026gt; d['a'].append(1) \u0026gt;\u0026gt;\u0026gt; d['a'].append(2) \u0026gt;\u0026gt;\u0026gt; d['b'].append(4)    有序字典\n问题，想使用字典，并且想在迭代的时候控制输出顺序。\n实现,： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from collections import OrderedDict \u0026gt;\u0026gt;\u0026gt; d = OrderedDict()    用字典计算\n问题，想用字典内的数据做各种计算(最大值，最小值，排序等)\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; prices = {'APPLE':23.33,'ORANGE':33.55,'BANANA':11.23} \u0026gt;\u0026gt;\u0026gt; print(min(zip(prices.values(),prices.keys()))) (11.23, 'BANANA') \u0026gt;\u0026gt;\u0026gt; print(max(zip(prices.values(),prices.keys()))) (33.55, 'ORANGE') \u0026gt;\u0026gt;\u0026gt; print(sorted(zip(prices.values(),prices.keys()))) [(11.23, 'BANANA'), (23.33, 'APPLE'), (33.55, 'ORANGE')]    查找两个字典的共性\n问题，比对两个字典，返回两个字典的共性。\n实现， 详细代码\n \u0026gt;\u0026gt;\u0026gt; a = {'x':1,'y':2,'z':3} \u0026gt;\u0026gt;\u0026gt; b = {'w':10,'x':11,'y':2} \u0026gt;\u0026gt;\u0026gt; a.keys() \u0026amp; b.keys() {'x', 'y'} \u0026gt;\u0026gt;\u0026gt; a.keys() - b.keys() {'z'} \u0026gt;\u0026gt;\u0026gt; a.items() \u0026amp; b.items() {('y', 2)}    删除列表的重复项\n问题，排除列表中的重复项，并保留顺序。\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; seen = set() \u0026gt;\u0026gt;\u0026gt; for item in [1,3,5,9,1]: ... if item not in seen: ... seen.add(item) \u0026gt;\u0026gt;\u0026gt; list(seen) [1, 3, 5, 9]    命名一个分片\n问题，清除混乱的内容\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; record = '....................100 .......513.25 ..........' \u0026gt;\u0026gt;\u0026gt; SHARES = slice(20,32) \u0026gt;\u0026gt;\u0026gt; PRICE = slice(40,48) \u0026gt;\u0026gt;\u0026gt; cost = int(record[SHARES]) * float(record[PRICE]) \u0026gt;\u0026gt;\u0026gt; print(cost) 51325.0    查找队列中最常出现的item\n问题，有一个队列，想找出出现最频繁的item\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; from collections import Counter \u0026gt;\u0026gt;\u0026gt; words = ['look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes','look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',] \u0026gt;\u0026gt;\u0026gt; word_counts = Counter(words) \u0026gt;\u0026gt;\u0026gt; top_two = word_counts.most_common(2) \u0026gt;\u0026gt;\u0026gt; print(top_two) [('look', 4), ('into', 4)]    根据公共的key排序字典列表\n问题，你有一个字典的列表，你想根据一个或多个字典值排序条目。\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; rows = [ {'fname':'Brain','uid':1003}, ... {'fname':'Jhon','uid':1002}, ... {'fname':'Alin','uid':1005}] \u0026gt;\u0026gt;\u0026gt; from operator import itemgetter \u0026gt;\u0026gt;\u0026gt; rows_by_uid = sorted(rows,key=itemgetter('uid')) \u0026gt;\u0026gt;\u0026gt; print(rows_by_uid) [{'fname': 'Jhon', 'uid': 1002}, {'fname': 'Brain', 'uid': 1003}, {'fname': 'Alin', 'uid': 1005}]    排序不支持比较的对象\n问题，你想对同一类对象进行排序，但它本身并不支持比较\n实现， 详细代码\n  基于特定字段的值进行分组\n问题，有一系列字典或实例，希望根据特定字段的值来迭代数据，例如日期。\n实现， 详细代码\n  过滤队列中的元素\n问题，你有一个队列需要通过某些标准提取或者减少值\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; mylist = [1, 4, 3, -2, 5, 0] \u0026gt;\u0026gt;\u0026gt; [n for n in mylist if n \u0026gt; 0] [1, 4, 3, 5]    提取字典的子集\n问题，制作一个字典是另一个字典的一个子集\n实现， 详细代码\n  名称映射到序列中的元素\n问题，通过按名称访问元素，减少对结构中的位置的依赖\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Subscriber = namedtuple('Subscriber', ['addr', 'joined']) \u0026gt;\u0026gt;\u0026gt; sub = Subscriber('test@examole.com', '2017-07-31') \u0026gt;\u0026gt;\u0026gt; sub Subscriber(addr='test@examole.com', joined='2017-07-31') \u0026gt;\u0026gt;\u0026gt; sub.addr 'test@examole.com' \u0026gt;\u0026gt;\u0026gt; sub.joined '2017-07-31'    同时转换和减少数据\n问题，您需要执行缩减功能(例如sum(),min(),max()),但首先需要转换或过滤数据.\n实现， 详细代码 \u0026raquo;\u0026gt; nums = [1,2,3,4,5] \u0026raquo;\u0026gt; s = sum(x*x for x in nums) \u0026raquo;\u0026gt; print(s) 55\n  将多个映射组合成单个映射\n问题，您有多个字典或映射，您要逻辑组合成一个映射来执行某些操作，例如查找值或检查键的存在\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; a = {'x': 1, 'z': 3 } \u0026gt;\u0026gt;\u0026gt; b = {'y': 2, 'z': 4 } \u0026gt;\u0026gt;\u0026gt; from collections import ChainMap \u0026gt;\u0026gt;\u0026gt; c = ChainMap(a,b) \u0026gt;\u0026gt;\u0026gt; c ChainMap({'x': 1, 'z': 3}, {'y': 2, 'z': 4})   "});index.add({'id':169,'href':'/notes/docs/technology/program/language/python/CookBook/StringsAndText/README/','title':"R E a D M E",'section':"Python",'content':"#字符串和文本\n   "});index.add({'id':170,'href':'/notes/docs/technology/program/language/python/Framework/Django/django/','title':"Django",'section':"Python",'content':"Django #  环境初始化 #  python3 install virtualenv cd demosite mkdir py3env virtualenv ./py3env/ source py3env/bin/activate #install Django pip3 install Django  项目初始化 #  django-admin startproject demosite python manage.py runserver python manage.py startapp polls  项目结构 #  demosite/ manage.py demosite/ __init__.py settings.py urls.py wsgi.py polls/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py  "});index.add({'id':171,'href':'/notes/docs/technology/program/language/python/Framework/Flask/flask/','title':"Flask",'section':"Python",'content':"Flask #  安装 #  pip install flask   程序基本结构 #   初始化  所有 Flask 程序都必须创建一个程序实例。Web 服务器使用一种名为 Web 服务器网关接口（Web Server Gateway Interface，WSGI）的协议，把接收自客户端的所有请求都转交给这个对象处理。\nfrom flask import Flask app = Flask('__name__')  路由和函数  程序实例需要知道对每个URL请求运行哪些代码，所以保存了一个URL到Python函数的映射关系。处理URL和函数之间关系的程序称为路由。 在Flask程序中定义路由的最简便方式，是使用程序实例提供的app.route修饰器，把修饰的函数注册为路由。\n@app.route('/') def index(): return '\u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt;'   启动服务\nif name == \u0026lsquo;main\u0026rsquo; app.run(Debug=True)\n   模版 #  模板是一个包含响应文本的文件，其中包含用占位变量表示的动态部分，其具体值只在请求的上下文中才能知道。使用真实值替换变量，再返回最终得到的响应字符串，这一过程称为渲染。为了渲染模板，Flask 使用了一个名为 Jinja2 的强大模板引擎。\nJinja2模板引擎 #  templates/user.html：Jinja2 模板\n\u0026lt;h1\u0026gt;Hello {{ name }} !\u0026lt;/h1\u0026gt;   渲染模版  示例，使用render_template\n@app.route('/user/\u0026lt;name\u0026gt;') def user(name) return render_template('user.html',name=name)  变量  Jinja2 能识别所有类型的变量，甚至是一些复杂的类型，例如列表、字典和对象。\n\u0026lt;p\u0026gt;A value from a dictionary: {{ mydict['key'] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from a list: {{ mylist[3] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from a list, with a variable index: {{ mylist[myintvar] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from an object's method: {{ myobj.somemethod() }}.\u0026lt;/p\u0026gt;  可以使用过滤器修改变量，过滤器名添加在变量名之后，中间使用竖线分隔。\nHello, {{ name|capitalize }}  过滤器\nsafe 渲染值时不转义 capitalize 把值的首字母转换成大写，其他字母转换成小写 lower 把值转换成小写形式 upper 把值转换成大写形式 title 把值中每个单词的首字母都转换成大写 trim 把值的首尾空格去掉 striptags 渲染之前把值中所有的 HTML 标签都删掉  控制结构  Jinja2 提供了多种控制结构，可用来改变模板的渲染流程。\n{% 控制条件 %}   使用Flask-Bootstrap集成Twitter Bootstrap #  Bootstrap是Twitter开发的一个开源框架，它提供的用户界面组件可用于创建整洁且具有吸引力的网页，而且这些网页还能兼容所有现代 Web 浏览器。\npip install flask-bootstrap   初始化  示例\nfrom flask.ext.bootstrap import Bootstrap bootstrap = Bootstrap(app)   自定义错误页面 #  @app.errorhandler(404) def page_not_found(e): return render_template('404.html'), 404 @app.errorhandler(500) def internal_server_error(e): return render_template('500.html'), 500   链接 #  Flask 提供了 url_for() 辅助函数，它可以使用程序 URL 映射中保存的信息生成 URL。\n静态文件 #   使用Flask-Moment本地化日期和时间 #  示例\npip install flask-moment from flask.ext.moment import Moment moment = Moment(app) {% block scripts %} {{ super() }} {{ moment.include_moment() }} {% endblock %} \u0026lt;p\u0026gt;The local date and time is {{ moment(current_time).format('LLL') }}.\u0026lt;/p\u0026gt;   WEB表单 #  示例\npip install flask-wtf from flask.ext.wtf import Form from wtforms import StringField, SubmitField from wtforms.validators import Required class NameForm(Form): name = StringField('What is your name?', validators=[Required()]) submit = SubmitField('Submit')  表单渲染\n{% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {{ wtf.quick_form(form) }}  视图处理表单：\nform = NameForm() return render_template('index.html', form=form)   数据库 #  初始化\npip install flask-sqlalchemy from flask.ext.sqlalchemy import SQLAlchemy basedir = os.path.abspath(os.path.dirname(__file__)) app = Flask(__name__) app.config['SQLALCHEMY_DATABASE_URI'] =\\ 'sqlite:///' + os.path.join(basedir, 'data.sqlite') app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True db = SQLAlchemy(app)  模型定义\nclass Role(db.Model): __tablename__ = 'roles' id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) def __repr__(self): return '\u0026lt;Role %r\u0026gt;' % self.name  创建表\ndb.create_all()  插入行\nfrom hello import Role admin_role = Role(name='Admin') db.session.add(admin_role) db.session.commit()   电子邮件 #  pip install flask-mail   项目结构 #  多文件 Flask 程序的基本结构\nflasky\n app/  templates/ static/ main/  init.py errors.py forms.py views.py   init.py email.py models.py   migrations/ tests/  init.py test*.py   venv/ requirements.txt config.py manage.py  这种结构有 4 个顶级文件夹：\n Flask 程序一般都保存在名为 app 的包中； 和之前一样，migrations 文件夹包含数据库迁移脚本； 单元测试编写在 tests 包中； 和之前一样，venv 文件夹包含 Python 虚拟环境。 同时还创建了一些新文件： requirements.txt 列出了所有依赖包，便于在其他电脑中重新生成相同的虚拟环境； config.py 存储配置； manage.py 用于启动程序以及其他的程序任务。  "});index.add({'id':172,'href':'/notes/docs/technology/program/language/python/Framework/Scrapy/scrapy/','title':"Scrapy",'section':"Python",'content':"#Scrapy Scrapy是一个快速的高级Web爬网和Web抓取框架，用于抓取网站并从其页面提取结构化数据。\n安装 #  pip install scrapy scrapy startproject scrapytest   第一个爬虫 #  "});index.add({'id':173,'href':'/notes/docs/technology/security/firewall/firewalld/','title':"Firewalld",'section':"防火墙",'content':"Firewalld #  firewalld是CentOS7默认的防火墙服务，用于管理网络数据包的流动和转发。\n 基础命令 #    启动\n $ systemctl start firewalld.service    查看状态\n $ systemctl status firewalld.service    关闭\n $ systemctl stop firewalld.service    开启和关闭开机启动\n $ systemctl enable firewalld.service $ systemctl disable firewalld.service    Rule配置：firewall-cmd命令\n   Options Description     -h, \u0026ndash;help Prints a short help text and exists   -V, \u0026ndash;version Print the version string of firewalld   -q, \u0026ndash;quiet Do not print status messages   \u0026ndash;state Return and print firewalld state   \u0026ndash;reload Reload firewall and keep state information   \u0026ndash;complete-reload Reload firewall and loose state information   \u0026ndash;runtime-to-permanent Create permanent from runtime configuration   \u0026ndash;permanent Set an option permanently   \u0026ndash;zone=\u0026lt;zone\u0026gt; Use this zone to set or query options, else default zone   \u0026ndash;timeout=\u0026lt;timeval\u0026gt; Enable an option for timeval time, where timeval is,a number followed by one of letters \u0026rsquo;s\u0026rsquo; or \u0026rsquo;m\u0026rsquo; or \u0026lsquo;h\u0026rsquo;       概念 #  区域(Zones) #  一个规则管理群组的概念，定义了可信任级别。其中预先定义的zones有以下几个：\n  drop\n最低信任级别，任何流入网络的包都被丢弃，不作出任何响应。只允许流出的网络连接。\n  block\n任何进入的网络连接都被拒绝，并返回 IPv4 的 icmp-host-prohibited 报文或者 IPv6 的 icmp6-adm-prohibited 报文。只允许由该系统初始化的网络连接。\n  public\n用以可以公开的部分。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。\n  external\n用在路由器等启用伪装的外部网络。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。\n  internal\n用在内部网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  dmz\n用以允许隔离区（dmz）中的电脑有限地被外界网络访问。只接受被选中的连接。\n  work\n用在工作网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  home\n用在家庭网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  trusted\n允许所有网络连接。\n  服务(service) #  服务是端口和/或协议入口的组合。备选内容包括 netfilter 助手模块以及 IPv4、IPv6地址。\n端口和协议(port/protocol) #  定义了 tcp 或 udp 端口，端口可以是一个端口或者端口范围。\nICMP阻塞 #  可以选择 Internet 控制报文协议的报文。这些报文可以是信息请求亦可是对信息请求或错误条件创建的响应.\n伪装 #  私有网络地址可以被映射到公开的IP地址。这是一次正规的地址转换。\n端口转发 #  端口可以映射到另一个端口以及/或者其他主机。\n 配置文件 #    区域配置文件\n /usr/lib/firewalld/zones(原始文件目录)    配置文件目录\n /etc/firewalld/zones    配置文件格式\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;utf-8\u0026quot;?\u0026gt; \u0026lt;zone\u0026gt; \u0026lt;short\u0026gt;Public\u0026lt;/short\u0026gt; \u0026lt;!--区域名称--\u0026gt; \u0026lt;description\u0026gt;For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.\u0026lt;/description\u0026gt; \u0026lt;service name=\u0026quot;dhcpv6-client\u0026quot;/\u0026gt; \u0026lt;service name=\u0026quot;ssh\u0026quot;/\u0026gt; \u0026lt;!--服务名称,调用ssh服务配置文件--\u0026gt; \u0026lt;port protocol=\u0026quot;tcp\u0026quot; port=\u0026quot;2222\u0026quot;/\u0026gt; \u0026lt;!--协议、端口--\u0026gt; \u0026lt;/zone\u0026gt;      服务配置文件\n /usr/lib/firewalld/services (原始文件目录)    配置文件目录\n /etc/firewalld/zones (zones优先调用目录)    配置文件格式\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;utf-8\u0026quot;?\u0026gt; \u0026lt;service\u0026gt; \u0026lt;short\u0026gt;SSH\u0026lt;/short\u0026gt; \u0026lt;!--服务名称--\u0026gt; \u0026lt;description\u0026gt;Secure Shell (SSH) is a protocol for logging into and executing commands on remote machines. It provides secure encrypted communications. If you plan on accessing your machine remotely via SSH over a firewalled interface, enable this option. You need the openssh-server package installed for this option to be useful.\u0026lt;/description\u0026gt; \u0026lt;port protocol=\u0026quot;tcp\u0026quot; port=\u0026quot;22\u0026quot;/\u0026gt; \u0026lt;!--配置协议端口--\u0026gt; \u0026lt;/service\u0026gt;      "});index.add({'id':174,'href':'/notes/docs/technology/security/firewall/iptables/','title':"Iptables",'section':"防火墙",'content':"Iptables #  iptables：一个运行在用户空间的应用软件，通过控制Linux内核 netfilter模块，来管理网络数据包的流动与转送。\n 规则编写 #  命令格式：iptables -t TABLE command CHAIN parameter match -j TARGET\n    command 描述     -P \u0026ndash;policy 定义默认策略   -L \u0026ndash;list 查看iptables规则列表   -A \u0026ndash;append 在规则列表的最后增加1条规则   -I \u0026ndash;insert 在指定的位置插入1条规则   -D \u0026ndash;delete 从规则列表中删除1条规则   -R \u0026ndash;replace 替换规则列表中的某条规则   -F \u0026ndash;flush 删除表中所有规则   -Z \u0026ndash;zero 将表中数据包计数器和流量计数器归零   -X \u0026ndash;delete-chain 删除自定义链   -v \u0026ndash;verbose 与-L他命令一起使用显示更多更详细的信息   -nL 查看当前运行的防火墙规则列表       parameter match 描述     -i \u0026ndash;in-interface 网络接口名\u0026gt; 指定数据包从哪个网络接口进入，   -o \u0026ndash;out-interface 网络接口名\u0026gt; 指定数据包从哪个网络接口输出   -p \u0026mdash;proto 协议类型 指定数据包匹配的协议，如TCP、UDP和ICMP等   -s \u0026ndash;source 源地址或子网\u0026gt; 指定数据包匹配的源地址   \u0026ndash;sport 源端口号\u0026gt; 指定数据包匹配的源端口号   -d \u0026ndash;destination 目的地址或子网\u0026gt; 指定数据包匹配的目的地址   \u0026ndash;dport 目的端口号\u0026gt; 指定数据包匹配的目的端口号   -m \u0026ndash;match 匹配的模块 指定数据包规则所使用的过滤模块    -m：extend matches，这个选项用于提供更多的匹配参数，如：\n-m state –-state ESTABLISHED,RELATED -m tcp –-dport 22 -m multiport –-dports 80,8080 -m icmp –-icmp-type 8   "});index.add({'id':175,'href':'/notes/docs/technology/system/linux/guideBook/fileOperation/','title':"File Operation",'section':"操作指南",'content':"一切皆文件 #    列出文件列表\n ls [option] /PATH #不指定路径，默认为当前路径 option -l:长格式 文件类型: -:普通文件 d:目录文件 b:块设备文件（block） c：字符设备文件（character） l：符号链接文件（symbolic link file） p：命令管道（pipe） s：套接字文件（socket） 文件权限：9位，每三位一组(u-g-o),每一组：rwx（读、写、执行） 文件硬链接的次数 文件的属主(owner) 文件的属组(group) 文件的大小(size)，单位是字节 时间戳(timestamp)：最近一次被修改的时间 访问：access 修改：modify，文件内容发生改变 改变：change，metadata，元数据 文件名 -h:做单位转换，默认bit -a:显示以.开头的隐藏文件 . 表示当前目录 .. 表示父目录 -d：显示目录自身属性 -i：index node，inode -r：逆序显示文件 -R：递归(recursive)显示    进入目录\n cd /PATH cd ~USERNAME:进入指定用户的家目录 cd -:在当前目录和前一次所在目录之间来回切换    显示文件类型\n type /PATH/FILENAME    显示当前路径\n pwd    目录管理\n  创建空目录\n mkdir [option] /PATH option -p:若父目录不存在，则自动创建 -v:列出过程详细信息 -m:指定目录权限    删除空目录\n rmdir /PATH      文件管理\n  创建文件\n touch [option] /PATH option:若文件存在 -a:修改访问时间 -m:修改修改时间 -c:修改改变时间    查看文件状态\n stat /PATH    删除文件\n rm [option] /PATH option -i:提示 -f:强制删除，不提示 -r:递归删除    复制文件\n cp [option] SRC DEST option -r:递归 -i:提示是否覆盖 -p:保留属性 -a:归档复制，保留所有属性    移动文件\n mv SRC DEST      文本查看\n  连接并显示\n cat [option] /PATH/FILENAME option -n:显示行号 -E:显示行尾    分屏显示\n more /PATH/FILENAME less /PATH/FILENAME head [option] /PATH/FILENAME option -n number:显示前n行 tail [option] /PATH/FILENAME option -n number:显示后n行 -f:查看文件尾部，不退出，等待显示后续追加至此文件的新内容      文本处理\n  文本分割\n cut [option] /PATH/FILENAME option -d:指定分隔符，默认是空格 -f number:指定要显示的字段    文本排序\n sort [option] /PATH/FILENAME option -n:数值排序 -r:降序 #默认为升序 -t:字段分隔符 -k:以哪个字段为关键字进行排序 -u:排序后相同的行只显示一次    文本去重\n uniq [option] /PATH/FILENAME option -c:只显示文件中行重复的次数 -d:只显示重复的行    文本统计\n wc [option] /PATH/FILENAME option -l:统计行数 -w:统计单词数 -c:统计字符数 -L:打印最长的行    字符转换\n tr [option] SET1 [SET2] option -d:删除出现在字符集中的所有字符      "});index.add({'id':176,'href':'/notes/docs/technology/system/linux/guideBook/permissionsOperation/','title':"Permissions Operation",'section':"操作指南",'content':"权限操作 #  权限 #    可读(r)(4)\n  可写(w)(2)\n  可执行(x)(1)\n  特殊权限\n  SUID(u+s): 运行某程序时，相应进程的属主是程序文件自身的属主\n  SGID(g+s)：运行某程序时，相应进程的属组是程序文件自身的属组\n  Sticky(o+t)：在一个公共目录，每个用户都可以创建删除自己的文件，但不能删除别人的文件\n     用户和组 #    用户(UID)\n  类别\n  管理员：0\n  普通用户：1-65535\n  系统用户：1-499\n  一般用户：500-65535\n      配置文件\n  /etc/passwd\n字段详解(以\u0026rdquo;:\u0026ldquo;为分割符)\n用户名 : 密码 : UID : GID : 注释 : 家目录 : 默认shell\n  /etc/shadow\n字段详解(以\u0026rdquo;:\u0026ldquo;为分隔符)\n用户名 : 密码 : 最近一次修改密码时间 : 最短使用期限 : 最长使用期限 : 警告时间 : 非活动时间 : 过期时间\n      组(GID)\n  类别\n  私有组：创建用户时，没指定所组，则系统默认创建同名组\n  基本组：用户的默认组\n  附加组：\n    配置文件\n  /etc/group\n字段详解(以\u0026rdquo;:\u0026ldquo;为分隔符)\n组名 : 密码 : GID : 以此组为其附加组的用户列表\n  /etc/gshadow\n       用户管理 #    添加用户\n useradd [options] USERNAME option -u：UID -g：groupname 指定基本组 -G：groupname,... 指定附加组 -c：\u0026quot;COMMENT\u0026quot; -d：指定家目录 -s：指定SHELL路径 -m -k：若家目录不存在，则自动创建 -r：添加系统用户    删除用户\n userdel [options] USERNAME option -r：同时删除用户的家目录    查看用户的帐号属性信息\n id [options] USERNAME option -u：查看UID -g：查看GID -G: 查看所有的GID -n：查看组名 finger USERNAME    修改用户帐号属性\n usermod [options] USERNAME option -u：UID -g：GID -a -g GID：不使用-a选项，会覆盖此前的附加组 -d -m：指定新的家目录，并把之前家目录的文件拷贝到新的家目录中 -c： -s：指定SHELL路径 -L：锁定帐号 -U：解锁帐号    密码管理\n passwd [USERNAME] --stdin：标准输入 -d：删除用户密码    检查用户帐号完整性\n pwck     组管理 #    创建用户组：\n groupadd [option] GROUPNAME -g：GID -r：添加为系统组    修改组的相关属性\n groupmod [option] GROUPNAME -g：GID -n：GRPNAME    删除组\n groupdel GROUPNAME    更改组密码\n gpasswd GROUPNAME     权限管理 #    改变文件属主\n chown USERNAME file,... -R：修改目录及其内部文件的属主 --reference=/path/to/somefile file,... 指定属主与该文件相同 chown USERNAME:GROUPNAME file chown USERNAME.GROUPNAME file    改变属组\n chgrp GROUPNAME file,...    修改文件的权限\n chmod MODE file,... -R： --reference=/path/to/somefile 修改单个用户的权限：u,g,o,a chmod 用户类别+|-MODE file,...     "});})();